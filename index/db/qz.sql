-- phpMyAdmin SQL Dump
-- version 4.7.7
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: 2018-06-06 17:13:05
-- 服务器版本： 10.1.30-MariaDB
-- PHP Version: 7.2.2

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
SET AUTOCOMMIT = 0;
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `qz`
--

-- --------------------------------------------------------

--
-- 表的结构 `qz_answer`
--

CREATE TABLE `qz_answer` (
  `aid` int(11) NOT NULL,
  `mid` int(11) DEFAULT NULL,
  `ansTime` bigint(20) DEFAULT NULL,
  `ans` varchar(1024) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_answer`
--

INSERT INTO `qz_answer` (`aid`, `mid`, `ansTime`, `ans`) VALUES
(1, 1, 1526472244794, '请登录我们的官网www.xxxx.cn选择你喜欢的模板，购买后你可以直接下载源代码或一键安装'),
(2, 2, 1526472244794, '请登录我们的官网www.xxxx.cn选择你喜欢的模板，购买后你可以直接下载源代码或一键安装'),
(3, 3, 1526472244794, '请登录我们的官网www.xxxx.cn选择你喜欢的模板，购买后你可以直接下载源代码或一键安装');

-- --------------------------------------------------------

--
-- 表的结构 `qz_case`
--

CREATE TABLE `qz_case` (
  `cid` int(11) NOT NULL,
  `title` varchar(128) DEFAULT NULL,
  `updateTime` bigint(20) DEFAULT NULL,
  `click` int(11) DEFAULT NULL,
  `isRecommend` int(11) DEFAULT NULL,
  `content` varchar(128) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_case`
--

INSERT INTO `qz_case` (`cid`, `title`, `updateTime`, `click`, `isRecommend`, `content`) VALUES
(1, '多功能应用开发', 1526472244794, 20, 1, 'image/case/01_case_cot.jpg'),
(2, '超级音乐播放器', 1526472244794, 23, 1, 'image/case/02_case_cot.png'),
(3, '万能日历', 1526472244794, 45, 1, 'image/case/03_case_cot.png'),
(4, '数据监控应用', 1526472244794, 20, 1, 'image/case/04_case_cot.png'),
(5, '网速检查器', 1526472244794, 16, 1, 'image/case/05_case_cot.png'),
(6, '人肉搜索', 1526472244794, 78, 0, 'image/case/06_case_cot.png'),
(7, '定时提醒应用', 1526472244794, 20, 0, 'image/case/07_case_cot.png'),
(8, '远程聊天工具', 1526472244794, 220, 0, 'image/case/08_case_cot.png'),
(9, '用户界面设计', 1526472244794, 20, 0, 'image/case/09_case_cot.png'),
(10, '画册封面', 1526472244794, 10, 0, 'image/case/10_case_cot.png'),
(11, '时间轴介绍', 1526472244794, 20, 0, 'image/case/11_case_cot.png'),
(12, '音乐播放器', 1526472244794, 11, 0, 'image/case/12_case_cot.png');

-- --------------------------------------------------------

--
-- 表的结构 `qz_case_img`
--

CREATE TABLE `qz_case_img` (
  `mid` int(11) NOT NULL,
  `cid` int(11) DEFAULT NULL,
  `sm` varchar(128) DEFAULT NULL,
  `md` varchar(128) DEFAULT NULL,
  `lg` varchar(128) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_case_img`
--

INSERT INTO `qz_case_img` (`mid`, `cid`, `sm`, `md`, `lg`) VALUES
(1, 1, 'image/case/01_case_sm.jpg', 'image/case/01_case_md.jpg', ''),
(2, 2, 'image/case/02_case_sm.png', 'image/case/02_case_md.png', ''),
(3, 3, 'image/case/03_case_sm.png', 'image/case/03_case_md.png', ''),
(4, 4, 'image/case/04_case_sm.png', 'image/case/04_case_md.png', ''),
(5, 5, 'image/case/05_case_sm.png', 'image/case/05_case_md.png', ''),
(6, 6, 'image/case/06_case_sm.png', 'image/case/06_case_md.png', ''),
(7, 7, 'image/case/07_case_sm.png', 'image/case/07_case_md.png', ''),
(8, 8, 'image/case/08_case_sm.png', 'image/case/08_case_md.png', ''),
(9, 9, 'image/case/09_case_sm.png', 'image/case/09_case_md.png', ''),
(10, 10, 'image/case/10_case_sm.png', 'image/case/10_case_md.png', ''),
(11, 11, 'image/case/11_case_sm.png', 'image/case/11_case_md.png', ''),
(12, 12, 'image/case/12_case_sm.png', 'image/case/12_case_md.png', '');

-- --------------------------------------------------------

--
-- 表的结构 `qz_news`
--

CREATE TABLE `qz_news` (
  `nid` int(11) NOT NULL,
  `tid` int(11) DEFAULT NULL,
  `title` varchar(128) DEFAULT NULL,
  `author` varchar(32) DEFAULT NULL,
  `updateTime` bigint(20) DEFAULT NULL,
  `click` int(11) DEFAULT NULL,
  `isRecommend` int(11) DEFAULT NULL,
  `isTop` int(11) DEFAULT NULL,
  `content` text
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_news`
--

INSERT INTO `qz_news` (`nid`, `tid`, `title`, `author`, `updateTime`, `click`, `isRecommend`, `isTop`, `content`) VALUES
(1, 1, '是时候改变你对微服务的认知了！', 'qz', 1526472244794, 20, 1, 0, '大部分时候，微服务都是建立在一种基于请求和响应的协议之上。比如，REST等。这种方式是自然的。我们只需要调用另外一个模块就是了，然后等待响应返回，然后继续。这样的方式确实也满足了我们的很多的场景：用户通过点击页面的一个按钮然后希望发生一些事情。\r\n\r\n\r\n\r\n但是，当我们开始接触许多独立的service的时候，事情就发生改变了。随着service数量急速的增长，同步交互比例也随着service在急速增长。这时候，我们的service就会遇到很多的瓶颈。\r\n\r\n于是，不幸的ops工程师们就被我们坑了，他们疲惫的奔波于一个又一个的service，拼凑在一起的二手信息片段，谁说了什么，去往哪里，什么时候发生？等等。。。\r\n\r\n这是一个非常典型的问题。市面上也有一些解决方案。一种方案就是确保您的个人服务具有比您的系统更高的SLA。 Google提供了这样做的协议。另一种方法是简单地分解将服务绑定在一起的同步关系。\r\n\r\n\r\n\r\n上面的做法都没有从模式上根本解决问题。我们可以使用异步机制来解决这个问题。比如，电商网站中你会发现这样的同步接口，比如getImage()或者processOrder()，也许你感觉蛮正常。调用了然后希望马上有一个响应。但当用户点击了“购买”后，触发了一个复杂且异步的处理过程。这个过程涉及到购买、送货上门给用户，这一切都是发生在当初的那一次的按钮点击。所以把一个程序处理逻辑切分成多个异步的处理，是我们需要解决的问题。这也正符合我们的真实的世界，真实世界本来就是异步的，拥抱异步吧。\r\n\r\n\r\n\r\n在实际情况下，我们其实已经自动拥抱了异步了。我们发现自己会定时轮询数据库表来更改又或者通过cron定时job来实现一些更新。这些方法都是一些打破同步的方式，但是这种做法总让人感觉有种黑客范儿，感觉像是黑客行为，怪怪的。\r\n\r\n\r\n\r\n在本文中，我们将会讨论一种完全不同的架构：不是把service们通过命令链揉到一块，而是通过事件流（stream of events）来做。这是一个不错的方式。这种方式也是我们之后要讨论的一系列的一个基础。\r\n\r\n\r\n\r\n当我们进入正式的例子之前，我们需要先普及三个简单的概念。一个service与另外一个service有三种交互方式：命令（Commands）、事件（Events）以及查询（Queries）。\r\n\r\n\r\n\r\n事件的美妙之处在于“外部数据”可以被系统中的任何service所重用。\r\n\r\n\r\n\r\n而且从service的角度来说，事件要比命令和查询都要解耦。这个很重要。\r\n\r\n\r\n\r\n服务之间的交互有三种机制：\r\n\r\n\r\n\r\nCommands 。命令是一个操作。希望在另一个服务中执行某些操作的一个请求。 会改变系统状态的东西。 命令期待有响应。\r\n\r\nEvents 。事件既是一个事实也是一个触发器。 发生了一些事情，表示为通知。\r\n\r\nQueries 。查询是一个请求，是一个查找一些东西的请求（request）。重要的是，查询不会使得系统状态发生改变。\r\n\r\n\r\n\r\n一个简单事件驱动流程\r\n\r\n\r\n\r\n让我们开始一个简单的例子：用户购买一个小东西。那么接下来要发生两件事情：\r\n\r\n\r\n\r\n支付。\r\n\r\n系统检查是否还有更多的商品需要被订购。\r\n\r\n在请求驱动（request-approach）的架构中，这两个行为被表现为一个命令链条。交互就像下面这样：\r\n\r\n\r\n\r\n首先要注意的问题是“购买更多”的这个业务流程是随着订单服务（Order Service）一块被初始化的。这就使得责任不独立，责任跨了两个service。理想情况下，我们希望separation of concerns，也就是关注隔离。\r\n\r\n\r\n\r\n现在如果我们使用事件驱动，而不是请求驱动的方式的话，那么事情就会变得好一些。\r\n\r\n\r\n\r\n在返回给用户之前，UI service 发布一个OrderRequested事件，然后等待OrderConfirmed（或者Rejected）。\r\n\r\n订单服务（Orders Service）和库存服务（Stock Service） react这个事件。\r\n\r\n\r\n\r\n仔细看这里，UI service和Orders Service并没有改变很多，而是通过事件来通信，而不是直接调用另一个。\r\n\r\n\r\n\r\n这个Stock service（库存服务）很有趣。Order Service告诉他要做什么。然后StockService自己决定是否参与本次交互，这是事件驱动架构非常重要的属性，也就是：Reciver Driven Flow Control，接收者驱动流程控制。一下子控制反转了。\r\n\r\n\r\n\r\n这种控制反转给接收者，很好的解耦了服务之间的交互，这就为架构提供了可插拔性。组件们可以轻松的被插入和替换掉，优雅！\r\n\r\n\r\n\r\n随着架构变得越来越复杂，这种可插拔性的因素变得更加重要。举个例子，我们要添加一个实时管理定价的service，根据供需调整产品的价格。在一个命令驱动的世界里，我们就需要引入一个可以由库存服务（Stock Service）和订单服务（Orders Service）调用的类似updatePrice()这样的方法。\r\n\r\n\r\n\r\n但是在事件驱动（event-driven）世界更新价格的话，service只需要订阅共享的stream就是了，当相应的条件符合时，就去执行更新价格的操作。\r\n\r\n\r\n\r\n事件（Events）和查询（Queries）的混合\r\n\r\n\r\n\r\n上面的例子只是命令和事件。并没有说到查询。别忘了，我们之前可是说到了三个概念。现在我们开始说查询。我们扩展上面的例子，让订单服务（Orders Service）在支付之前检查是否有足够的库存。\r\n\r\n\r\n\r\n在请求驱动（request-driven）的架构中，我们可能会向库存服务（Stock Service）发送一个查询请求然后获取到当前的库存数量。这就导致了模型混合，事件流纯粹被用作通知，允许任何的service加入flow，但查询却是通过请求驱动的方式直接访问源。\r\n\r\n\r\n\r\n对于服务（service）需要独立发展的较大的生态系统，远程查询要涉及到很多关联，耦合很严重，要把很多服务捆绑在一起。我们可以通过“内部化”来避免这种涉及多个上下文交叉的查询。而事件流可以被用于在每个service中缓存数据集，这样我们就可以在本地来完成查询。\r\n\r\n\r\n\r\n所以，增加这个库存检查，订单服务（Order Service）可以订阅库存服务（Stock Service）的事件流，库存一有更新，订单服务就会收到通知，然后把更新存储到本地的数据库。这样接下来就可以查询本地这个“视图（view）”来检查是否有足够的库存。\r\n\r\n\r\n\r\n纯事件驱动系统没有远程查询的概念 - 事件将状态传播到本地查询的服务\r\n\r\n\r\n\r\n通过事件来传播（ “Queryby Event Propagation”）的查询有以下三个好处：\r\n\r\n\r\n\r\n1、更好的解耦：在本地查询。这样就不涉及跨上下文调用了。这种做法涉及到的服务们远远不及那种”请求驱动”所涉及到的服务数量多。\r\n\r\n2、更好的自治：订单服务（Order Service）拥有一份库存数据集的copy，所以订单服务可以任意使用这个本地的数据集，\r\n\r\n而不是说像请求驱动里的那样仅仅只能检查库存限额，而且只能通过Stock Service所提供的接口。\r\n\r\n3、高效Join：如果我们在每次下订单的时候都要去查询库存，就要求每次都要高效的做join，通过跨网络对两个service进行join。随着需求的增加，或者更多的数据源需要关联，这可能会变得越来越艰巨。所以通过事件传播来查询（Query by Event Propagation）将查询（和join）本地化后就可以解决这个问题（就是本地查询）。\r\n\r\n\r\n\r\n但这种做法也不是没有缺点。 Service从本质上变得有状态了。这样就使得他们需要被跟踪和矫正这些数据集，随着时间的推移，也就是你得保证数据同步。状态的重复也可能使一些问题更难理解（比如如何原子地减少库存数量？），这些问题我们都要小心。但是，所有这些问题都有可行的解决方案，我们只是需要多一点考虑而已。 \r\n\r\n\r\n\r\n单一写入者原则（Single Writer Principle）\r\n\r\n\r\n\r\n针对这种风格的系统，也就是事件驱动风格的系统，一个非常有用的原则就是针对指定类型的传播的事件分配责任的时候，应该只分配给一个单一的service：单一的写入者。什么意思呢？就是Stock Service只应该处理库存这一件事情，而Order Service也只属于订单们，等等。\r\n\r\n\r\n\r\n这样的话有助于我们通过单个代码路径（尽管不一定是单个进程）来排除一致性，验证和其他“写入路径（writepath）”问题。因此，在下面的示例中，请注意，订单服务（Order Service）控制着对订单进行的每个状态的更改，但整个事件流跨越了订单（Orders），付款（Payments）和发货（Shipments），每个都由它们各自的服务来管理。\r\n\r\n\r\n\r\n分配“事件传播”（event propagation）的责任很重要，因为这些不仅仅是短暂的事件，或者是那种无须保存短暂的聊天。他们代表了共同的事实（facts），以及“数据在外部（data-on-the-outside）“。因此，随着时间的推移，服务（services）需要去负责更新和同步这些共享数据集（shared datasets）：比如，修复错误，处理schema的变化等情况。\r\n\r\n\r\n\r\n上图中每个颜色代表Kafka的一个topic，针对下订单（Order）、发货和付款。  当用户点击“购买”时，会引发“Order Requested”，等待“Order Confirmed”事件，然后再回复给用户。 另外三个服务处理与其工作流程部分相关的状态转换。 例如，付款处理完成后，订单服务（Order Service）将订单从“已验证（Validated）”推送到“已确认（Confirmed）”。\r\n\r\n\r\n\r\n模式（Patterns）和集群服务（Clustering Services）的混合\r\n\r\n\r\n\r\n上面的说到的模型有点像企业消息（Enterprise Messaging），但其实是有一些不同的。企业消息，在实践中，主要关注状态的转换，通过网络有效地将数据库捆绑在一起。\r\n\r\n\r\n\r\n而事件协作（Event Collaboration）则更偏重的是协作，既然是协作就不简单的是状态转换，事件协作是关于服务（service）通过一系列事件进行一些业务目标，这些事件将触发service的执行。所以这是业务处理（business processing）的一种模式，而不是简单的转换状态的机制。\r\n\r\n\r\n\r\n我们通常希望在我们构建的系统中这种模式具有两面性。事实上，这种模式的美妙之处在于它确实既可以处理微观又可以处理宏观，或者在有些情况下可以被混合。\r\n\r\n\r\n\r\n模式组合使用也很常见。我们可能希望提供远程查询的方便灵活性，而不是本地维护数据集的成本，特别是数据集增长时。这样的话就会让我们的查询变得更加的简单，我们只需要轻松部署简单的函数就可以了。而且我们现在很多都是无状态的，比如容器或者浏览器，在这种情况下也许远程查询是一种合适的选择。\r\n\r\n\r\n\r\n远程查询设计的诀窍就是限制这些查询接口的范围，理想情况下应该是在有限的上下文中（context）。通常情况下，建立一个具有多个特定，具体视图的架构，而不是单一的共享数据存储。注意是多个具体的视图，而不是单一的共享数据存储。（一个独立（bounded）的上下文，或者说是偏向原子，这里说的原子不是侧重微服务中常说的那个“原子服务”。独立上下文，一般是指有那么一组service，它们共享同一个发布流水线或者是同一个领域模型【domain model】）。\r\n\r\n\r\n\r\n为了限制远程查询（remote queries）的边界（scope），我们可以使用一种叫做“集群式上下文模式（clustered context pattern）”。这种情况下，事件就流纯粹是用作上下文之间的通信。但在一个上下文里的具体service们则可以既有事件驱动（event-driven）的处理，同时也有请求驱动（request-driven）的视图（view），具体根据实际情况需要。\r\n\r\n\r\n\r\n在下面的例子中，我们有三个部分，三个之间只通过事件相互沟通。在每一个内部，我们使用了更细粒度的事件驱动流。其中一些包括视图层（查询层）。\r\n\r\n\r\n\r\n还是看下图吧：\r\n\r\n\r\n\r\n集群上下文模型（Clustered Context Model）\r\n\r\n\r\n\r\n事件驱动（event-driven）五个关键好处：\r\n\r\n 解耦：把一个很长的同步执行链的命令给分解，异步化。 分解同步工作流。 Brokers 或topic解耦服务（service），所以更容易插入新的服务（service），具有更强的插拔性。\r\n\r\n离线/异步流：当用户点击按钮时，很多事情都会发生。 一些同步，一些异步。 对能力的设计，无论是以前的，还是将来的，都是更自由的。提高了性能，提高了自由度。\r\n\r\n状态同步更新：事件流对分布式数据集提供了一种有效的机制，数据集可以在一个有界的上下文里被重构（“传播”或“更新”）和查询。\r\n\r\n Joins：从不同的服务（service）组合/join/扩展数据集更容易。 join更快速，而且还是本地化的。\r\n\r\n可追溯性: 当有一个统一化的，中心化的，不可变的，保持性的地方来记录每个互动时，它会及时展现，debug的时候也更容易定位问题，而不是陷入一场关于“分布式”的谋杀。（这里有点晦涩）\r\n\r\n总结\r\n\r\n\r\n\r\nOk，在事件驱动的方法中我们使用事件（Events）而不是命令（Commands）。事件触发业务处理过程。事件也可以用到更新本地视图上。然后我们向你介绍了，在必要时，我们可以再回到远程同步查询这种方式，特别是在较小的系统中，而且我们还将远程同步查询的范围扩大到更大的范围（理想情况下，还是要仅限于单个独立的上下文，也就是单个领域模型，不能再扩大了，刚刚好才是真的好）。\r\n\r\n\r\n\r\n而且所有这些方法都只是模式（pattern）。模式就会有框得太死的问题。模式覆盖不到的地方，我们就要具体情况具体对待了。例如，单点登录服务，全局查询的service仍然是一个好主意，因为它很少更新。\r\n\r\n\r\n\r\n这里的秘诀就是从事件的基准出发去考虑问题。事件让服务之间不再耦合，并且将控制（flow-control）权转移到接收者，这就有了更好的“分离关注（separated concerns）”和更好的可插拔性。\r\n\r\n\r\n\r\n关于事件驱动方法的另一个有趣的事情是，它们对于大型，复杂的架构同样适用，就像它们对于小型，高度协作的架构一样。事件让service们可以自主的决定自己的所有事情，为服务们提供自由发展所需的自主权。\r\n\r\n\r\n\r\n然后我们向你介绍了事件和查询混合的场景。说到查询，在纯事件驱动方法中，查询完全基于本地的数据集，而没有远程查询。本地数据集则是通过事件触发来更新状态。然而，很多时候，基于请求驱动的查询方式在很多时候也是比较方便的，因为本地数据集的方式，状态的同步更新确实是一件更加需要成本的事情。\r\n\r\n\r\n\r\n然后我们说到了单一写入z者原则。单一写入者让我们数据更新有了统一的入口，有助于我们通过单个代码路径（尽管不一定是单个进程）来排除一致性，验证和其他“写入路径（writepath）”问题。\r\n\r\n\r\n\r\n然后我们讨论了集群上下文模型。每个领域模型组成一个独立的区域，然后再由多个区域共同组成一个领域模型集群，模型之间又通过Kafka来交互。每个领域模型里又可以包含几种模式的混合，比如Events、Views、UI，这些里边可以既有事件驱动模式，又有请求驱动模式。\r\n\r\n\r\n\r\n大体就这么多。\r\n\r\n\r\n\r\n感谢Antony Stubbs，Tim Berglund，Kaufman Ng，GwenShapira和Jay Kreps，他们帮助我们回顾了这篇文章。\r\n\r\n\r\n\r\n译者曰：最近也恰好在做有关事件流的内容，对本文中讲到的异步解耦和拆解同步请求链条过长问题深有感触，也非常认同。另外最近有人聊到有关数据库查询效率问题，通过阅读本文也许会让你对查询有一个全新的认识。这些微服务理念看起来好像专属于“微服务”，好像其他人就不需要了解一样。其实也许微服务的这些先进理念就像其他任何的先进的架构理念一样，他们都是我们软件架构知识体系的储备之一，也许在哪天你正在进行的项目遇到了瓶颈，没准本文讨论的这些内容就能派上用场了，不仅仅限于本文举的那个例子。\r\n\r\n\r\n\r\n微服务\"交互方式\"观念转变：\r\n\r\n\r\n\r\n 是时候更新一下你对于构建微服务的一些知识体系了。如果你认为REST就是微服务构建的主要交互方式的话，那么也许你错了；如果你认为rpc就是构建微服务的的主要交互方式的话，那么也许你又错了。\r\n\r\n\r\n\r\n因为这两种都属于一种类型，那就是他们都属于请求驱动（request-driven）模式，而这种模式很多时候是同步的，一条链上挂了很多的服务调用，势必在链条变长后，性能堪忧。\r\n\r\n\r\n\r\n本文向你推荐了一个构建微服务的新的工具，或者说是向你补充了。那就是事件驱动（event-driven）的模式。它解耦、异步，带来了更好的扩展性和性能。很多时候，同步会让事情变得异常糟糕！\r\n\r\n\r\n\r\n如果以后有人和讨论起微服务的模式的时候，你可以说REST、rpc（请求驱动）以及事件驱动共同混合使用才会构建出更好的微服务来！\r\n\r\n\r\n\r\nps：文中部分段落翻译用词略显晦涩，我曾尝试用大白话来翻译，但发现会损失原意，故请仔细斟酌消化。'),
(2, 1, '如何成为一个优秀的工程师？“看到问题也不要去问别人，就把它Fix。”！', 'qz', 1526472244794, 20, 1, 1, '一位工程师，如何才能称得上优秀？除了写得一手好Code，什么样的工作态度和方法才是一个优秀工程师的必备？  7月11日，陆奇出席百度内部Engineering Leadership Talk。作为计算机科学博士及优秀的管理者，他提出的五点要求，对每一位百度工程师都适用。  “我们一定要有一个坚定不移的深刻的理念，相信整个世界终究是为技术所驱动的。”  “有没有其他人已经解决这个问题？然后你可以把你的时间放在更好的创新上。”   “做什么事情一定要做最好，一定要是做业界最强的。”  “我把自己想象是一个软件、一个代码，今天的版本一定要比昨天版本好，明天的版本肯定会比今天好。”  “看到问题也不要去问别人，就把它Fix。”  欲知是哪五点要求？请往下看  Believe in 技术     首先要相信技术，我刚才已经讲了，整个我们工业界，特别是像百度这样的公司，对技术坚定的、不动摇的信念特别重要。  我也分享一下，盖茨提到微软公司的宗旨就是：写软件代表的是世界的将来。  为什么？未来任何一个工业都会变成软件工业。盖茨是对的，因为任何工业任何行业自动化的程度会越来越高，最后你所处理的就是信息和知识。  但现在软件的做法又往前提了一次，因为在人工智能时代，不光是写代码，你必须懂算法，懂硬件，懂数据，整个人工智能的开发过程有一个很大程度的提高，但是，技术，特别是我们这个工业所代表的技术一定是将来任何工业的前沿。  站在巨人的肩膀上做创新  我们观察一下，在美国硅谷、在中国，互联网创业公司也好，大型公司也好，大家的起点是越来越高的。为什么现在创新速度那么快？主要是起点高了。我们可以使用的代码模块，使用的服务的能力，都是大大的提升。  在内部我想强调这一点，很多大公司包括微软在内，内部的Code都重做了无数遍。  我现在的要求是，每一次你写一行新的代码，第一要做的，先想一想你这行代码值得不值得写，是不是有人已经做了同样的工作，可能做得比你还好一点。有没有其他人已经解决这个问题，然后你可以把你的时间放在更好的创新上。  特别是大公司里面重复或者是几乎重复的Code实在太多，浪费太多的资源，对每个人的职业生涯都不是好事情。  我再强调，在大公司内部，你写代码之前想一想，你这行代码要不要写，是不是别人已经有了，站在别人的肩膀上去做这件事情。    追求Engineering Excellence  我要另外强调的一点就是Engineering Excellence，工程的技术的卓越性和能力。  任何市场上竞争就像打仗一样，就看你的部队体能、质量，每一个士兵他的训练的程度，和你给他使机关枪、坦克，还是什么样的武器。  所以Engineering Excellence跟这个类比，我们要建的是一支世界上最强的部队，每一个士兵，每一个领军人，每个人的能力，他的训练都是超强的，然后我们给每个人提供的工具和武器都是一流的。  所以Engineering Excellence是一个永无止境的、个人的、团队的，能力的追求和工具平台的创新，综合在一起可以给我们带来的长期的、核心的竞争力，为社会创造价值，最终的目的是给每个用户、每个企业、整个社会创造价值。  我另外还要在这里强调的一点就是Relentless pursuit of excellence：永无止境的不断的持续的追求。  我们要么不做，要做的事情一定做最好，这是我对大家的要求。数据库也好，做大平台也好，大数据也好，我们要做什么事情，我们一定要下决心，这是我对你们每个人的要求，做什么事情一定要做最好，一定要是做业界最强的。  每天学习，可能是对每个人都是最最重要的。  我今天分享一下，我自己怎么想我自己的。就很简单一个概念，我把自己想象是一个软件、一个代码，今天的版本一定要比昨天版本好，明天的版本肯定会比今天好，因为即使犯了错误，我里面有If statement，说如果见到这个错误，绝对不要再犯。  英语，另外有一句说法就是Life is too short, don’t live the same day twice. 同样一天不要重活两次。每天都是不一样，每天为什么不一样，因为每天都变成最好，每天都变得更好。今天的版本一定要比昨天好，每个好的、杰出的工程师，杰出的技术领袖，一定要保持自己学习的能力，特别是学习的范围。  在这上面我也稍微引申一下，做Computer science的，如果只学Computer science，不去学一些其他的行业，肯定不够。我举个例子，经济学必须要学。为什么这样讲？Computer science它有个很大的限制，他是假定你有输入以后有输出，这种解决问题的方式有它的好处，但有它的限制性。  我给大家举个例子，地图导航，如果你纯粹用这个方式去做，你只是把一个拥挤的地方移到另外一个拥挤的地方。经济学，它对问题的建模是不一样的。它起点是假定是一个整体的一个生态，每个人的输入都是另外一个人的输出，你要用经济学的方式来描述地图导航的问题，你就会去算一个Equilibrium，市场也是这样。  如果把深度学习真的要想彻底，必须把物理重学一遍，把生物学看一遍，再把进化论再看一遍。因为深度学习跟这些东西完全相关，自己肯定想不清楚，要彻底想清楚，必须学。  另外，学产品，我以前跟所有的工程师都讲，如果不懂产品，你不可能成为一个最好的工程师。真正要做世界一流的工程师不光要懂产品，还要懂整个商业，懂生态。因为你的工作的责任，是能够看到将来，把技术展望到将来的需求，把平台、把开发流程、把你的团队为将来做准备。所以学习是非常非常重要的。  最后是从我做起。  我们公司有个非常大的使命，用科技让复杂的世界更简单。整个世界非常非常复杂，人其实所做的事情基本上都是Reduce entropy。  因为从热力学第二定律来讲，世界是会变得越来越乱的，我们想做的事情就是把它变的更简单，让我们生活变得更美好。  而且具体的，我们可以通过人工智能技术来做到唤醒万物，但是这一切是通过每一个人的一点一滴的行为累计起来，从我做起。还有Ownership，看到机会不需要问别人，有机会就去做，看到问题也不要去问别人，就把它Fix。  把我们的使命、把我们的公司当成我们自己每个人的事业来做，我可以坦诚的给每个人讲，如果你把公司的使命，把公司的事业，当成你自己个人的事业，Own everything，你在职业生涯一定是走得最快。从我做起，从身边的每一件事情做起。  Believe in 技术、站在巨人的肩膀上做创新、追求Engineering Excellence、每天学习、Ownership，陆奇送给每一位工程师的建议，你get到了吗？'),
(3, 1, '精选！15 个必备的 VSCode 插件（前端类）', 'qz', 1526472244794, 20, 1, 0, 'Visual Studio Code 是由微软开发的一款免费、跨平台的文本编辑器。由于其卓越的性能和丰富的功能，它很快就受到了大家的喜爱。  就像大多数 IDE 一样，VSCode 也有一个扩展和主题市场，包含了数以千计质量不同的插件。为了帮助大家挑选出值得下载的插件，我们针对性的收集了一些实用、有趣的插件与大家分享。  1. Open-In-Browser  由于 VSCode 没有提供直接在浏览器中打开文件的内置界面，所以此插件在快捷菜单中添加了在默认浏览器查看文件选项，以及在客户端（Firefox，Chrome，IE）中打开命令面板选项。  2. Quokka  Quokka是一个调试工具插件，能够根据你正在编写的代码提供实时反馈。它易于配置，并能够预览变量的函数和计算值结果。另外，在使用 JSX 或 TypeScript 项目中，它能够开箱即用。  3. Faker  使用流行的 JavaScript 库 – Faker，能够帮你快速的插入用例数据。Faker 可以随机生成姓名、地址、图像、电话号码，或者经典的乱数假文段落，并且每个类别还包含了各种子类别，你可以根据自身的需求来使用这些数据。  4. CSS Peek  使用此插件，你可以追踪至样式表中 CSS 类和 ids 定义的地方。当你在 HTML 文件中右键单击选择器时，选择“ Go to Definition 和 Peek definition ”选项，它便会给你发送样式设置的 CSS 代码。  5. HTML Boilerplate  通过使用 HTML 模版插件，你就摆脱了为 HTML 新文件重新编写头部和正文标签的苦恼。你只需在空文件中输入 html，并按 Tab 键，即可生成干净的文档结构。  6. Prettier  Prettier 是目前 Web 开发中最受欢迎的代码格式化程序。安装了这个插件，它就能够自动应用 Prettier，并将整个 JS 和 CSS 文档快速格式化为统一的代码样式。如果你还想使用 ESLint，那么还有个 Prettier – Eslint 插件，你可不要错过咯！  7. Color Info  这个便捷的插件，将为你提供你在 CSS 中使用颜色的相关信息。你只需在颜色上悬停光标，就可以预览色块中色彩模型的（HEX、 RGB、HSL 和 CMYK）相关信息了。  8. SVG Viewer  此插件在 Visual Studio 代码中添加了许多实用的 SVG 程序，你无需离开编辑器，便可以打开 SVG 文件并查看它们。同时，它还包含了用于转换为 PNG 格式和生成数据 URI 模式的选项。  9. TODO Highlight  这个插件能够在你代码中标记出所有的 TODO 注释，以便更容易追踪任何未完成的业务。在默认的情况下，它会查找 TODO 和 FIXME 关键字。当然，你也可以添加自定义表达式。  10. Icon Fonts  这是一个能够在项目中添加图标字体的插件。该插件支持超过 20 个热门的图标集，包括了 Font Awesome、Ionicons、Glyphicons 和 Material Design Icons。  11. Minify  这是一款用于压缩合并 JavaScript 和 CSS 文件的应用程序。它提供了大量自定义的设置，以及自动压缩保存并导出为.min文件的选项。它能够分别通过 uglify-js、clean-css 和 html-minifier，与 JavaScript、CSS 和 HTML 协同工作。  12. Change Case  虽然 VSCode 内置了开箱即用的文本转换选项，但其只能进行文本大小写的转换。而此插件则添加了用于修改文本的更多命名格式，包括驼峰命名、下划线分隔命名，snake_case 命名以及 CONST_CAS 命名等。  13. Regex Previewer  这是一个用于实时测试正则表达式的实用工具。它可以将正则表达式模式应用在任何打开的文件上，并高亮所有的匹配项。  14. Language and Framework Packs  VSCode 默认支持大量的主流编程语言，但如果你所使用的编程语言不包括在内，也可以通过下载扩展包来自动添加。同时，你还可以添加一些像 React Native 与 Vue 的相关 Web 开发插件包。  15. Themes  当然，在众多用插件中，岂能少了漂亮的主题呢？你每天都会与你的 VSCode 编辑器进行“亲密的接触”，为何不把它打扮得更漂亮些呢？这里有一些帮助你更改侧边栏的配色方案，以及图标的相关主题，与大家分享：'),
(4, 1, 'Zdal分库分表：支付宝是如何在分布式环境下完爆数据库压力的？', 'qz', 1526472244794, 20, 0, 0, 'Zdal是支付宝自主研发的数据中间件产品，采用标准的JDBC规范，可以在分布式环境下看上去像传统数据库一样提供海量数据服务，是一种通用的分库分表数据库访问框架，解决单库单表数据库访问压力，Zdal主要提供分库分表，结果集合并，sql解析，数据库failover动态切换等功能，提供互联网金融行业的数据访问层统一解决方案，目前已经在支付宝的交易，支付，会员，金融等大部分关键应用上使用，并且在2013年双11大促中运行稳定。    ▲系统目标  1.数据访问路由，将针对数据的读写请求发送到最合适的地方。  2.数据存储的自由扩展，不再受限于单台机器的容量瓶颈和速度瓶颈，平滑迁移。  3.使用zdal组件进行数据库的拆分，搭建分布式环境下的海量数据访问平台。  4.实现mysql，oracle，DB2数据库访问能力。    【系统架构和领域模型】  ▲系统整体架构      zdal组件主要有5部分组成：  1. Zdal-client：开发编程接口，实现jdbc的Datasource，Connection，Statement，PreparedStatement，ResultSet等接口，实现通用的jdbc-sql访问，内部还实现读库重试，group数据源的选择器，表名替换，sql执行器等功能。  2. Zdal-parser：支持oracle/mysql/db2等数据库的sql语句解析，并且缓存。根据规则引擎提供的参数列表，在指定的sql中查找到需要的参数，然后返回拆分字段。  3. Zdal-rule：根据zdal-parser解析后的拆分字段值来确定逻辑库和物理表名。  4. Zdal-datasource：数据库连接的管理，支持mysql，oracle，db2数据库的连接管理。  5. Zdal-common：zdal组件所使用的一些公共组件类。    ▲总体流程      ▲Zdal初始化流程    ▲分库分表初始化流程    ▲分库分表sql执行流程      【关键技术&第三方框架】  ▲Zdal-client  Zdal-client 模块主要是完成以下几部分工作：  1.加载配置文件进行初始化工作，初始化groovy规则引擎。  2.对jdbc 标准接口的封装，包括 DataSource、Connection、Statement、PrepareStatment等，并提供一个一对多的管理容器，可以管理多个jdbc建立的资源。  3.SQL执行：根据规则引擎生成的目标库id和表名，进行表名替换后在目标库上执行该sql，如果是跨库跨表的sql，需要进行多个结果集的merge。  4.读库重试，即在读库发生断连接问题的时候,Zdal会自动的尝试从对等的其他读库中去查询这条数据，尽最大努力保证在数据库还有访问能力的情况下，保证数据的可访问性。  5.将传入的sql 和 参数进行包装后，调用 zdal-parser 和zdal-rule的 相关接口，进行sql的解析以及计算相应的分库分表结果。在此模块将会实现表名替换的功能，即将sql的逻辑表名替换成带后缀的物理表名。  6.动态指定读库功能，即可以让业务根据实际需求指定一组中的某个读库进行操作，也可以指定到写库读。  7.聚合函数结果集合并，针对count,sum,max,min等聚合函数在多个数据源的执行结果，进行结果集的合并。      ▲Zdal-parser  Parser组件包括如下几个部分：  1. Lexer 词法解析。  2.Parser，Parser包括ExprParser，各种StatementParser。  3. AST, Abstract Syntax TreeParse出来的结果就是AST。  4.StatementParser：解析各种sql语句，按照词法分析和语法分析提炼sql的关键字。  5.Visitor：根据StatementParser的解析结果对AST做各种处理，比如FormatOutput，遍历，tableName，表达式，函数,绑定参数，分页参数，获取sql解析的结果。    Zdal-Parser的主要核心类图如下：    ▲Zdal-rule  Zdal-rule 主要是完成规则的计算，包括分库的计算和分表的计算，相当于是一个二次路由的过程，包括单库单表、单库多表以及多库多表等几种情况。为了适应规则的灵活配置，目前主要是采用书写groovy脚本的方式来配置规则，或者在代码里封装拆分规则静态方法，在规则里调用该静态方法即可。    我们假设分库规则是 user_id % 9  /  3 分表规则是user_id % 9 % 3'),
(5, 1, 'ECMAScript 8都发布了，你还没有用上ECMAScript 6？', 'qz', 1526472244794, 20, 0, 0, 'ES8已经与17年6月底发布，而很多的前端开发者还没有开始用上ES6。本文聊一聊怎么快速入门ES6，并将ES6的语法应用到实战项目中。  阅读全文大约需要15分钟。  文中以 ES 表示 ECMAScript。  今年六月底，TC39发布新一版的ES 8（ES 2017），自从ES6在15年发布之后，每一年TC39都会发布新一版的ES语言标准。  我了解的前端开发者中，还有很多人没有用上ES6，有的人是觉得ES5用的挺好的，懒得去学ES6，有的人是有想学ES6的决心，但是苦于没有合适的机会（项目）去实战练习。  如果你用过React，Vue或Nodejs等，那你多多少少都会使用到一些ES6语法的。  ES8中的新特性，浏览器厂商和语法转换器还需要一段来实现，不如我们还是先聊聊怎么在你的项目中用上ES6吧。  什么是ES6？它和ES5有什么区别？  我们常说的JavaScript是指ES3和ES5，ES6是ECMAScript 6 的缩写。  对于经常写原生JavaScript的前端开发者来说，对ES5中的语法肯定比较熟悉，比如数组中的一些方法forEach，map，filter，some，every，indexOf，lastIndexOf，reduce，reduceRight ……，以及对象（Object）和函数（Function）都拓展了很多方法，这里不多赘叙。  ES6给前端开发者带来了很多的新的特性，可以更简单的实现更复杂的操作，很大的提高开发效率，提高代码的整洁性。  ES6中的新特性有很多，列一些比较常用的特性：  Block-Scoped Constructs Let and Const（块作用域构造Let and Const）  Default Parameters（默认参数）  Template Literals （模板字符串）  Multi-line Strings （多行字符串）  Arrow Functions （箭头函数）  Enhanced Object Literals （增强的对象文本）  Promises  Classes（类）  Modules（模块）  Destructuring Assignment （解构赋值）  下面介绍下这些常用的ES6特性。  Block-Scoped Constructs Let and Const（块作用域构造Let and Const）  ES6提供了两个新的声明变量的关键字：let和const。而let和const要和块级作用域结合才能发挥其优势。  什么是块级作用域？  块级作用域的表示一对大括号{}包围的区域是一个独立的作用域，在这个作用域内用let声明的变量a，只能在这个作用域内被访问到，在这对大括号外面是访问不到a的。  当然，在块级作用域中还可以声明函数，该函数也是只能作用域内部才能被访问到。所以，在if、else、for甚至是一对单独的{}，都是一个块级作用域。  在ES6之前，是没有块级作用域的概念的，只有全局作用域和函数作用域两种，并且，用var声明的变量和用function声明的函数会被提前到作用域的顶部，这也就是我们常说的声明提前。  用let声明的变量是存在于距离声明语句最近的一个作用域（全局作用域、函数作用域或块级作用域）内的，在声明的时候，可选的将其初始化成一个值。  语法如下：    let var1 [= value1] [, var2 [= value2 ] ] [, ..., varN [= valueN]] ;  这一点与var的声明不同，用var声明的变量是属于离他最近的一个全局作用域或函数作用域中，且声明会被提前。在块级作用域中，var的声明与在全局作用域和函数作用域中是一样的。    块级作用域和let声明变量，解决了使用var一些痛点，相当于用let声明的变量不会被提前到作用域顶部。    有一点需要注意，let也是声明提前,但是let声明变量的语句必须在使用该变量语句之前，在声明之前引用会报错该变量未被声明，且let不允许重复声明相同名称的变量，否则会报错。我们看下例子：    {    var hello = \'Hello\';    let world = \'World\';  }  console.log(hello);  console.log(world);  在Chrome浏览器的控制台（最新版本的Chrome已支持一部分ES6语法）执行一下，会发现有报错，见下图。constconst声明与let基本相同，它也是存在于块级作用域内。  有一点区别就是const声明的是常量，即不可被重新赋值改变原值。需要注意，const在声明常量的时候，必须同时给常量初始化赋值。如果只声明，不初始化值的话，会报错。见下面代码。  const MAX;  // Uncaught SyntaxError: Missing initializer in const declaration  声明变量的方法  在ES5中，可以通过var和function这两种方法来声明变量。    而在ES6中，除了增加了let和const两种声明方式，还有接下来要介绍的import和class的声明方式。  Default Parameters（默认参数）  默认参数是ES6中对函数拓展的一个特性，可以直接为函数的参数设置默认值，当某一参数设置了默认值时，如果调用函数的时候没有传该参数，则该参数的值为默认值，如果传了该参数，则该参数的值为传递的参数值。  在ES6之前，我们可以通过手动的方式，为函数的参数设置默认值，代码如下：  function sign (x) {    if (typeof x === \'undefined\') {      x = \'default\'    }    console.log(x)  }  sign(\'new sign\')    // new sign  sign()              // default  将上述代码换成ES6模式，可以这样写：    function sign (x = \'default\') {    console.log(x)      }  sign(\'new sign\')    // new sign  sign()              // default  Template Literals （模板字符串）    ES6提供了模板字符串的特性，模板字符串是使用反引号（`）和${}实现字符串的拼接，字符串中可以嵌入变量。  在ES6之前，我们一般这样输出模板：  var name = \'Henry\';  var welcome = \'Hello, \' + name + \'!\';  console.log(welcome);   // Hello, Henry!  在ES6中，模板字符串可以这样拼接字符串：  let name = \'Henry\';  let welcome = `Hello, ${ name }!`;  console.log(welcome);   // Hello, Henry  模板字符串的计算规则是在两个反引号之间将字符串拼接到一起，如果反引号之间含有${}，则会计算这对大括号内的值，大括号里面可以是任意的JavaScript表达式，可以进行运算和引用对象属性。  let a = 3;  let number = `$ {a + 2 }`;  console.log(`${ number }`);    // 5    let b = { c: 2, d: 4 };  console.log(`${ b.c * b.d }`) ;     // 8  Multi-line Strings （多行字符串）    多行字符串是模板字符串的拓展，它跟模板字符串是同样的解析方式，不同的是，它可以拼接多行的字符串，且拼接的字符串中会保留所有的空格和缩进。  如果需要用字符串来拼接DOM树结构时，可以这样写：  let titleValue = \'This is a title\'；  let htmlStr = `              ${ titleValue }          This is a paragraph.     `;  上述代码中，能看到JavaScript代码和伪html代码的结合，完全可以将模板字符串的多行字符串封装成一个页面模板工具，绝对是轻量高效的。  还有，这种书写方式是不是很眼熟，跟React的JSX是不是很像双胞胎啊。  Arrow Functions （箭头函数）  在ES6中，可以使用箭头（=>）来声明一个函数，称作箭头函数。  ES5中声明一个函数，可以这样写：  var func = function (a) {    return a + 2;  }  将这个函数换成 箭头函数：  let func = a => a + 2;  如果函数有多个参数，需要用括号包含所有参数，只有一个参数的时候，可以省略括号，如果没有设置参数，也必须有括号。示例如下：    let func1 = (arg1, arg2, arg3) => {    return arg1 + arg2 + arg3;  }    let func2 = arg => {    console.log(arg)  }  let func3 = () => {    console.log(`This is an arrow function.`)  }  需要注意的是，箭头函数没有自己的this，如果在箭头函数内部使用this，那样这个this是箭头函数外部的this，也是因为箭头函数没有this，所以，箭头函数不能用作构造函数。如果用箭头函数来写回调函数时，就不用再将外部this保存起来了。  // ES5  function foo() {    var _this = this;          setTimeout(function() {      console.log(\'id:\', _this.id);            }, 200)  }  // ES6  function foo() {    setTimeout(() => {      console.log(`id:${ this.id }`)            }, 200)  }  Enhanced Object Literals （增强的对象文本）    在ES6，对象字面值扩展支持在创建时设置原型，简写foo：foo分配，定义方法，加工父函数（super calls），计算属性名(动态)。总之，这些也带来了对象字面值和类声明紧密联系起来，让基于对象的设计得益于一些同样的便利。    var obj = {    // __proto__ 原型    __proto__: theProtoObj,    // Shorthand for ‘handler: handler’  简写    handler,    // Methods    toString() {      // Super calls     继承      return \"d \" + super.toString();    },    // Computed (dynamic) property names 计算属性名    [\'prop_\' + (() => 42)()]: \'name\'  };  Promises  Promise是异步编程的一种解决方案，它是一个对象，且只要开始就会一直进行下去，直到成功或者失败。就像它的字面意思诺言一样，一个诺言，只要被许下，就只有两种解决：成功或失败。  Promise的结果是由异步操作的结果决定的，且一旦结果形成，便不可再被改变，任何时候都得到同样的结果。  需要注意的是：Promise被新建后，便无法被取消，会执行下去，直到出现结果；如果不设置回调，Promise内部抛出的异常，不会反应到外部。'),
(6, 1, '是时候改变你对微服务的认知了！', 'qz', 1526472244794, 20, 1, 0, '前言  工欲善其事，必先利其器。我们做代码审计之前选好工具也是十分必要的。下面我给大家介绍两款代码审计中比较好用的工具。  一、审计工具介绍  PHP 代码审计系统— RIPS  功能介绍  RIPS 是一款基于 PHP 开发的针对 PHP 代码安全审计的软件。  另外，它也是一款开源软件，由国外安全研究员 Johannes Dahse 开发，程序只有 450KB，目前能下载到的最新版是0.55。  在写这段文字之前笔者特意读过它的源码，它最大的亮点在于调用了 PHP 内置解析器接口token_get_all，  并且使用Parser做了语法分析，实现了跨文件的变量及函数追踪，扫描结果中非常直观地展示了漏洞形成及变量传递过程，误报率非常低。  RIPS 能够发现 SQL 注入、XSS 跨站、文件包含、代码执行、文件读取等多种漏洞，支持多种样式的代码高亮。比较有意思的是，它还支持自动生成漏洞利用。    下载地址：https://jaist.dl.sourceforge.net/project/rips-scanner/rips-0.55.zip.  解压到任意一个PHP的运行目录  在浏览器输入对应网址，可以通过下图看到有一个path 在里面填写你要分析的项目文件路径，点击 scan.  界面截图    seay 源代码审计系统  功能介绍  这些是seay 第一个版本的部分功能，现在最新版本是2.1。  傻瓜化的自动审计 。  支持php代码调试 。  函数/变量定位 。  生成审计报告。  自定义审计规则 。  mysql数据库管理 。  黑盒敏感信息泄露一键审计 。  支持正则匹配调试 。  编辑保存文件 。  POST数据包提交 。  安装方法  安装环境需要 .NET2.0以上版本环境才能运行，下载安装包之后点击下一步就安装好了，非常的简便。  安装包下载地址：http://enkj.jb51.net:81/201408/tools/Seayydmsjxt(jb51.net).rar  操作界面的截图    二、代码审计实战  通过刚才安装的两个审计工具运行后我们可以发现，会分析出很多隐藏的漏洞，那下面我们看看其中的SQL注入、XSS、CSRF产生的原因,通过原因来分析如何去审计代码。  SQL注入  SQL注入漏洞一直是web系统漏洞中占比非常大的一种漏洞，下面我们来看看SQL注入的几种方式。  SQL 注入漏洞分类  从利用方式角度可以分为两种类型:常规注入、宽字节注入。  常规注入方式，通常没有任何过滤，直接把参数存放到了SQL语句当中，如下图。  非常容易发现，现在开发者一般都会做一些过滤，比如使用addslashes()，但是过滤有时候也不一定好使。  编码注入方式  宽字节注入，这个是怎么回事呢？  在实际环境中程序员一般不会写上面类似的代码，一般都会用addslashes()等过滤函数对从web传递过来的参数进行过滤。不过有句话叫做，道高一尺魔高一丈，我们看看白帽子是怎么突破的。用PHP连接MySQL的时候，当设置 character_set_client=gbk时候会导致一个编码漏洞。我们知道addslashes() 会把参数 1’ 转换成 1\\’,而我们提交参数 1%df’ 时候会转成 1縗’，那我们输入 1%df’ or 1=1%23时候，会被转换成 1縗’ or 1=1#’。  简单来说%df’会被过滤函数转义为%df\\’ ，%df\\’ = %df%5c%27  在使用gbk编码的时候会认为%df%5c是一个宽字节%df%5c%27=縗’，这样就会产生注入。  那如何防御这个宽字节呢？我希望大家开发网站尽量使用UTF8编码格式，如果转换麻烦，最安全的方法就是使用PDO预处理。挖掘这种漏洞主要是检查是否使用了gbk，搜索guanjianc character_set_client=gbk 和mysql_set_chatset(\'gbk\') 。  二次urldecode注入，这中方式也是因为使用了urldecode不当所引起的漏洞。  我们刚才知道了 addslashes()函数可以防止注入，他会在(‘)、(“)、()前面加上反斜杠来转义。  那我们假设我们开启了GPC，我们提交了一个参数，/test.php?uid=1%2527,因为参数中没有单引号，所以第一次解码会变成uid=1%27,%25解码出来就是%，  这时候程序里如果再去使用urldecode来解码，就会把%27解码成单引号(‘)，最终的结果就是uid=1’.  我们现在知道了原有是因为urldecode引起的，我们可以通过编辑器的搜索urldecode和rawurldecode找到二次url漏洞。  从漏洞类型区分可以分为三种类型：  可显  攻击者可以直接在当前界面内容中获取想要获得的内容。  报错  数据库查询返回结果并没有在页面中显示，但是应用程序将数据库报错信息打印到了页面中。  所以攻击者可以构造数据库报错语句，从报错信息中获取想要获得的内容，所以我建议在数据库类中设置不抛出错误信息。  盲注  数据库查询结果无法从直观页面中获取攻击者通过使用数据库逻辑或使数据库库执行延时等方法获取想要获得的内容。  SQL 注入漏洞挖掘方法  针对上面提到的利用漏洞方法，总结了以下的挖掘方法：  参数接收位置，检查是否有没过滤直接使用  _POST、$_COOKIE 参数的。  SQL语句检查，搜索关键词 select update insert 等SQL语句关键处，检查SQL语句的参数是否可以被控制。  宽字节注入,如果网站使用的 GBK 编码情况下，搜索guanjianc character_set_client=gbk 和mysql_set_chatset(\'gbk\') 就行。  二次 urldecode 注入，少部分情况，gpc 可以通过编辑器的搜索 urldecode 和 rawurldecode 找到二次url漏洞。  SQL 注入漏洞防范方法  虽然SQL注入漏洞非常多，但是防范起来却挺简单的，下面介绍几个过滤函数和类:  gpc/rutime 魔术引号  过滤函数和类  addslashes  mysql_real_escape_string  intval  PDO 预处理  XSS跨站  前言  XSS 又叫 CSS (Cross Site Script) ，跨站脚本攻击。它指的是恶意攻击者往 Web 页面里插入恶意 html 代码，当用户浏览该页之时，嵌入其中 Web 里面的 html 代码会被执行，从而达到恶意的特殊目的。  XSS 属于被动式的攻击，因为其被动且不好利用，所以许多人常呼略其危害性。在 WEB2.0 时代，强调的是互动，使得用户输入信息的机会大增，在这个情况下，我们作为开发者，在开发的时候，要提高警惕。  xss 漏洞分类  反射型，危害小，一般  反射型XSS原理：就是通过给别人发送带有恶意脚本代码参数的URL，当URL地址被打开时，特定的代码参数会被HTML解析，执行，如此就可以获取用户的COOIKE，进而盗号登陆。比如hack甲构造好修改密码的URL并把密码修改成123，但是修改密码只有在登陆方乙才能修改，乙在登陆的情况下点击甲构造好的URL将直接在不知情的情况下修改密码。  特点是：非持久化，必须用户点击带有特定参数的链接才能引起。  存储型，危害大，影响时间长  存储型XSS原理，假设你打开了一篇正常的文章页面，下面有评论功能。这个时候你去评论了一下，在文本框中输入了一些JavaScript代码，提交之后,你刷新这个页面后发现刚刚提交的代码又被原封不动的返回来并且执行了。  这个时候你会想,我要写一段 JavaScript 代码获取 cookie 信息，然后通过ajax发送到自己的服务器去。构造好代码后你把链接发给其他的朋友，或者网站的管理员，他们打开 JavaScript 代码就执行了，你服务器就接收到了sessionid，你就可以拿到他的用户权限了。  dom型 XSS 是因为 JavaScript 执行了dom 操作，所造成的 XSS 漏洞，具体如下图。可以看到虽然经过 html 转义了，但是这块代码在返回到 html 中，又被 JavaScript 作为 dom 元素操作。那当我输入?name=＜img src=\"1\" onerror=\"alert(1)\"/＞ 的时候依然会存在 XSS 漏洞。    xss 漏洞挖掘方法  根据上面的一些特点，可以总结出几个分析出几个挖掘方法：  数据接收位置，检查 _POST、$_COOKIE是否经过转义。  常见的反射型XSS搜索这种类似位置发现次数较多。  而存储型在文章，评论出现比较多。  XSS 漏洞防范方法  转义html实体，有两种方式：在入口和出口,我建议是在入口处转义，防止出口位置取出来的时候忘记转义，如果已经在入口转义了，出口位置就不用再次转义。  在富文本编辑器中，经常会用到一些元素的属性，比如上图的onerror，那我们还需对元素的属性建立黑白名单。  httpOnly 即使存在xss漏洞，可以把危害大大降低。  CSRF漏洞  CSRF 漏洞介绍  CSRF（Cross-site request forgery）跨站请求伪造，通常缩写为CSRF或者XSRF，是一种对网站的恶意利用。听起来像跨站脚本（XSS），但它与XSS非常不同，XSS利用站点内的信任用户。  而 CSRF 则通过伪装来自受信任用户的请求来利用受信任的网站。与 XSS 攻击相比，CSRF 攻击往往不大流行（因此对其进行防范的资源也相当稀少）和难以防范，所以被认为比XSS更具危险性。  csrf 主要用来做越权操作，而且 csrf 一直没有被关注起来，所以很多程序现在也没有相关的防范措施。  CSRF 案例  我们来看下面的一段代码,这个表单当被访问到的时候，用户就退出了登录。假设有一个转账的表单，只需要填写对方的用户名，和金额就可以，那如果我提前把 URL 构造好，发给受害者，当点击后，钱就被转走了。  或者我把这个 URL 放到我的网页中，通过<img src=\"我构造的URL\" ，当其他人打开我的网址后，就中招了。  CSRF漏洞挖掘方法  通过上面的描述，我们知道了漏洞的原有，那我们审计的时候可以检查处理表单有没有以下判断。  是否有验证 token。  是否有图片验证码。  是否有 refe 信息。  如果三个判断都没有，那么就存在了 CSRF 漏洞，CSRF 不仅限于 GET 请求， POST 请求同样存在。  CSRF 漏洞防范方法  图片验证码，这个想必大家都知道，但是用户体验并不好，我们可以看下面的一些处理方法。  token验证。  token验证方法如下，每次访问表单页的时候，生成一个不可预测的token存放在服务器session中，另外一份放页面中，提交表单的时候需要把这个token带过去，接收表单的时候先验证一下token是否合法。  Refeer信息验证  大多数情况下，浏览器访问一个地址，其中header头里面会包含Referer信息,里面存储了请求是从哪里发起的。  如果HTTP头里包含有Referer的时候，我们可以区分请求是同域下还是跨站发起的，所以我们也可以通过判断有问题的请求是否是同域下发起的来防御 CSRF 攻击。  Referer 验证的时候有几点需要注意，如果判断Referer是否包含 *.XXX.com,如果有子域名有漏洞，会存在绕过的可能。  如果判断的条件的是Referer中是否包含字符 ‘xxx.com’  那攻击者在他目录中建立一个 xxx.com 文件夹同样存在绕过的可能。如果可以最合适的判断是，直接判断是否等于当前域名。    三、常规漏洞的防范方法    taint PHP 安全扩展    功能介绍  Taint 可以用来检测隐藏的 XSS code, SQL 注入， Shell注入等漏洞，并且这些漏洞如果要用静态分析工具去排查， 将会非常困难， 我们来看下面这张图:  安装方法  下载 taint：  http://pecl.php.net/package/taint  配置  /usr/local/php/bin/phpize  ./configure --with-php-config=/usr/local/php/bin/php-config  make && make install  更加详细的可以参考：http://www.cnblogs.com/linzhenjie/p/5485474.html  应用场景  开发团队要求每个人都做到非常的安全比较难，但是把taint安装在开发环境，特别适合，一看到 warning 信息一般都回去改。  ngx_lua_waf  功能介绍  防止 sql 注入，本地包含，部分溢出，fuzzing 测试，xss，SSRF 等 web攻击。  防止 svn /备份之类文件泄漏。  防止 ApacheBench 之类压力测试工具的攻击。  屏蔽常见的扫描黑客工具，扫描器。  屏蔽异常的网络请求。  屏蔽图片附件类目录 php 执行权限。  防止 webshell 上传。  安装方法  安装依赖: luajit 、ngx_devel_kit、nginx_lua_module  安装nginx、ngx_lua_waf  在nginx.conf里的 http 添加配置  详细安装文档'),
(7, 1, '如何成为一个优秀的工程师？“看到问题也不要去问别人，就把它Fix。”！', 'qz', 1526472244794, 20, 1, 1, '前言  工欲善其事，必先利其器。我们做代码审计之前选好工具也是十分必要的。下面我给大家介绍两款代码审计中比较好用的工具。  一、审计工具介绍  PHP 代码审计系统— RIPS  功能介绍  RIPS 是一款基于 PHP 开发的针对 PHP 代码安全审计的软件。  另外，它也是一款开源软件，由国外安全研究员 Johannes Dahse 开发，程序只有 450KB，目前能下载到的最新版是0.55。  在写这段文字之前笔者特意读过它的源码，它最大的亮点在于调用了 PHP 内置解析器接口token_get_all，  并且使用Parser做了语法分析，实现了跨文件的变量及函数追踪，扫描结果中非常直观地展示了漏洞形成及变量传递过程，误报率非常低。  RIPS 能够发现 SQL 注入、XSS 跨站、文件包含、代码执行、文件读取等多种漏洞，支持多种样式的代码高亮。比较有意思的是，它还支持自动生成漏洞利用。    下载地址：https://jaist.dl.sourceforge.net/project/rips-scanner/rips-0.55.zip.  解压到任意一个PHP的运行目录  在浏览器输入对应网址，可以通过下图看到有一个path 在里面填写你要分析的项目文件路径，点击 scan.  界面截图    seay 源代码审计系统  功能介绍  这些是seay 第一个版本的部分功能，现在最新版本是2.1。  傻瓜化的自动审计 。  支持php代码调试 。  函数/变量定位 。  生成审计报告。  自定义审计规则 。  mysql数据库管理 。  黑盒敏感信息泄露一键审计 。  支持正则匹配调试 。  编辑保存文件 。  POST数据包提交 。  安装方法  安装环境需要 .NET2.0以上版本环境才能运行，下载安装包之后点击下一步就安装好了，非常的简便。  安装包下载地址：http://enkj.jb51.net:81/201408/tools/Seayydmsjxt(jb51.net).rar  操作界面的截图    二、代码审计实战  通过刚才安装的两个审计工具运行后我们可以发现，会分析出很多隐藏的漏洞，那下面我们看看其中的SQL注入、XSS、CSRF产生的原因,通过原因来分析如何去审计代码。  SQL注入  SQL注入漏洞一直是web系统漏洞中占比非常大的一种漏洞，下面我们来看看SQL注入的几种方式。  SQL 注入漏洞分类  从利用方式角度可以分为两种类型:常规注入、宽字节注入。  常规注入方式，通常没有任何过滤，直接把参数存放到了SQL语句当中，如下图。  非常容易发现，现在开发者一般都会做一些过滤，比如使用addslashes()，但是过滤有时候也不一定好使。  编码注入方式  宽字节注入，这个是怎么回事呢？  在实际环境中程序员一般不会写上面类似的代码，一般都会用addslashes()等过滤函数对从web传递过来的参数进行过滤。不过有句话叫做，道高一尺魔高一丈，我们看看白帽子是怎么突破的。用PHP连接MySQL的时候，当设置 character_set_client=gbk时候会导致一个编码漏洞。我们知道addslashes() 会把参数 1’ 转换成 1\\’,而我们提交参数 1%df’ 时候会转成 1縗’，那我们输入 1%df’ or 1=1%23时候，会被转换成 1縗’ or 1=1#’。  简单来说%df’会被过滤函数转义为%df\\’ ，%df\\’ = %df%5c%27  在使用gbk编码的时候会认为%df%5c是一个宽字节%df%5c%27=縗’，这样就会产生注入。  那如何防御这个宽字节呢？我希望大家开发网站尽量使用UTF8编码格式，如果转换麻烦，最安全的方法就是使用PDO预处理。挖掘这种漏洞主要是检查是否使用了gbk，搜索guanjianc character_set_client=gbk 和mysql_set_chatset(\'gbk\') 。  二次urldecode注入，这中方式也是因为使用了urldecode不当所引起的漏洞。  我们刚才知道了 addslashes()函数可以防止注入，他会在(‘)、(“)、()前面加上反斜杠来转义。  那我们假设我们开启了GPC，我们提交了一个参数，/test.php?uid=1%2527,因为参数中没有单引号，所以第一次解码会变成uid=1%27,%25解码出来就是%，  这时候程序里如果再去使用urldecode来解码，就会把%27解码成单引号(‘)，最终的结果就是uid=1’.  我们现在知道了原有是因为urldecode引起的，我们可以通过编辑器的搜索urldecode和rawurldecode找到二次url漏洞。  从漏洞类型区分可以分为三种类型：  可显  攻击者可以直接在当前界面内容中获取想要获得的内容。  报错  数据库查询返回结果并没有在页面中显示，但是应用程序将数据库报错信息打印到了页面中。  所以攻击者可以构造数据库报错语句，从报错信息中获取想要获得的内容，所以我建议在数据库类中设置不抛出错误信息。  盲注  数据库查询结果无法从直观页面中获取攻击者通过使用数据库逻辑或使数据库库执行延时等方法获取想要获得的内容。  SQL 注入漏洞挖掘方法  针对上面提到的利用漏洞方法，总结了以下的挖掘方法：  参数接收位置，检查是否有没过滤直接使用  _POST、$_COOKIE 参数的。  SQL语句检查，搜索关键词 select update insert 等SQL语句关键处，检查SQL语句的参数是否可以被控制。  宽字节注入,如果网站使用的 GBK 编码情况下，搜索guanjianc character_set_client=gbk 和mysql_set_chatset(\'gbk\') 就行。  二次 urldecode 注入，少部分情况，gpc 可以通过编辑器的搜索 urldecode 和 rawurldecode 找到二次url漏洞。  SQL 注入漏洞防范方法  虽然SQL注入漏洞非常多，但是防范起来却挺简单的，下面介绍几个过滤函数和类:  gpc/rutime 魔术引号  过滤函数和类  addslashes  mysql_real_escape_string  intval  PDO 预处理  XSS跨站  前言  XSS 又叫 CSS (Cross Site Script) ，跨站脚本攻击。它指的是恶意攻击者往 Web 页面里插入恶意 html 代码，当用户浏览该页之时，嵌入其中 Web 里面的 html 代码会被执行，从而达到恶意的特殊目的。  XSS 属于被动式的攻击，因为其被动且不好利用，所以许多人常呼略其危害性。在 WEB2.0 时代，强调的是互动，使得用户输入信息的机会大增，在这个情况下，我们作为开发者，在开发的时候，要提高警惕。  xss 漏洞分类  反射型，危害小，一般  反射型XSS原理：就是通过给别人发送带有恶意脚本代码参数的URL，当URL地址被打开时，特定的代码参数会被HTML解析，执行，如此就可以获取用户的COOIKE，进而盗号登陆。比如hack甲构造好修改密码的URL并把密码修改成123，但是修改密码只有在登陆方乙才能修改，乙在登陆的情况下点击甲构造好的URL将直接在不知情的情况下修改密码。  特点是：非持久化，必须用户点击带有特定参数的链接才能引起。  存储型，危害大，影响时间长  存储型XSS原理，假设你打开了一篇正常的文章页面，下面有评论功能。这个时候你去评论了一下，在文本框中输入了一些JavaScript代码，提交之后,你刷新这个页面后发现刚刚提交的代码又被原封不动的返回来并且执行了。  这个时候你会想,我要写一段 JavaScript 代码获取 cookie 信息，然后通过ajax发送到自己的服务器去。构造好代码后你把链接发给其他的朋友，或者网站的管理员，他们打开 JavaScript 代码就执行了，你服务器就接收到了sessionid，你就可以拿到他的用户权限了。  dom型 XSS 是因为 JavaScript 执行了dom 操作，所造成的 XSS 漏洞，具体如下图。可以看到虽然经过 html 转义了，但是这块代码在返回到 html 中，又被 JavaScript 作为 dom 元素操作。那当我输入?name=＜img src=\"1\" onerror=\"alert(1)\"/＞ 的时候依然会存在 XSS 漏洞。    xss 漏洞挖掘方法  根据上面的一些特点，可以总结出几个分析出几个挖掘方法：  数据接收位置，检查 _POST、$_COOKIE是否经过转义。  常见的反射型XSS搜索这种类似位置发现次数较多。  而存储型在文章，评论出现比较多。  XSS 漏洞防范方法  转义html实体，有两种方式：在入口和出口,我建议是在入口处转义，防止出口位置取出来的时候忘记转义，如果已经在入口转义了，出口位置就不用再次转义。  在富文本编辑器中，经常会用到一些元素的属性，比如上图的onerror，那我们还需对元素的属性建立黑白名单。  httpOnly 即使存在xss漏洞，可以把危害大大降低。  CSRF漏洞  CSRF 漏洞介绍  CSRF（Cross-site request forgery）跨站请求伪造，通常缩写为CSRF或者XSRF，是一种对网站的恶意利用。听起来像跨站脚本（XSS），但它与XSS非常不同，XSS利用站点内的信任用户。  而 CSRF 则通过伪装来自受信任用户的请求来利用受信任的网站。与 XSS 攻击相比，CSRF 攻击往往不大流行（因此对其进行防范的资源也相当稀少）和难以防范，所以被认为比XSS更具危险性。  csrf 主要用来做越权操作，而且 csrf 一直没有被关注起来，所以很多程序现在也没有相关的防范措施。  CSRF 案例  我们来看下面的一段代码,这个表单当被访问到的时候，用户就退出了登录。假设有一个转账的表单，只需要填写对方的用户名，和金额就可以，那如果我提前把 URL 构造好，发给受害者，当点击后，钱就被转走了。  或者我把这个 URL 放到我的网页中，通过<img src=\"我构造的URL\" ，当其他人打开我的网址后，就中招了。  CSRF漏洞挖掘方法  通过上面的描述，我们知道了漏洞的原有，那我们审计的时候可以检查处理表单有没有以下判断。  是否有验证 token。  是否有图片验证码。  是否有 refe 信息。  如果三个判断都没有，那么就存在了 CSRF 漏洞，CSRF 不仅限于 GET 请求， POST 请求同样存在。  CSRF 漏洞防范方法  图片验证码，这个想必大家都知道，但是用户体验并不好，我们可以看下面的一些处理方法。  token验证。  token验证方法如下，每次访问表单页的时候，生成一个不可预测的token存放在服务器session中，另外一份放页面中，提交表单的时候需要把这个token带过去，接收表单的时候先验证一下token是否合法。  Refeer信息验证  大多数情况下，浏览器访问一个地址，其中header头里面会包含Referer信息,里面存储了请求是从哪里发起的。  如果HTTP头里包含有Referer的时候，我们可以区分请求是同域下还是跨站发起的，所以我们也可以通过判断有问题的请求是否是同域下发起的来防御 CSRF 攻击。  Referer 验证的时候有几点需要注意，如果判断Referer是否包含 *.XXX.com,如果有子域名有漏洞，会存在绕过的可能。  如果判断的条件的是Referer中是否包含字符 ‘xxx.com’  那攻击者在他目录中建立一个 xxx.com 文件夹同样存在绕过的可能。如果可以最合适的判断是，直接判断是否等于当前域名。    三、常规漏洞的防范方法    taint PHP 安全扩展    功能介绍  Taint 可以用来检测隐藏的 XSS code, SQL 注入， Shell注入等漏洞，并且这些漏洞如果要用静态分析工具去排查， 将会非常困难， 我们来看下面这张图:  安装方法  下载 taint：  http://pecl.php.net/package/taint  配置  /usr/local/php/bin/phpize  ./configure --with-php-config=/usr/local/php/bin/php-config  make && make install  更加详细的可以参考：http://www.cnblogs.com/linzhenjie/p/5485474.html  应用场景  开发团队要求每个人都做到非常的安全比较难，但是把taint安装在开发环境，特别适合，一看到 warning 信息一般都回去改。  ngx_lua_waf  功能介绍  防止 sql 注入，本地包含，部分溢出，fuzzing 测试，xss，SSRF 等 web攻击。  防止 svn /备份之类文件泄漏。  防止 ApacheBench 之类压力测试工具的攻击。  屏蔽常见的扫描黑客工具，扫描器。  屏蔽异常的网络请求。  屏蔽图片附件类目录 php 执行权限。  防止 webshell 上传。  安装方法  安装依赖: luajit 、ngx_devel_kit、nginx_lua_module  安装nginx、ngx_lua_waf  在nginx.conf里的 http 添加配置  详细安装文档'),
(8, 1, '精选！15 个必备的 VSCode 插件（前端类）', 'qz', 1526472244794, 20, 1, 0, '有赞使用storm已经有将近3年时间，稳定支撑着实时统计、数据同步、对账、监控、风控等业务。订单实时统计是其中一个典型的业务，对数据准确性、性能等方面都有较高要求，也是上线时间最久的一个实时计算应用。通过订单实时统计，描述使用storm时，遇到的准确性、性能、可靠性等方面的问题。    订单实时统计的演进  第一版：流程走通  在使用storm之前，显示实时统计数据一般有两种方案：    在数据库里执行count、sum等聚合查询，是简单快速的实现方案，但容易出现慢查询。  在业务代码里对统计指标做累加，可以满足指标的快速查询，但统计逻辑耦合到业务代码，维护不方便，而且错误数据定位和修正不方便。  既要解耦业务和统计，也要满足指标快速查询，基于storm的实时计算方案可以满足这两点需求。    一个storm应用的基本结构有三部分：数据源、storm应用、结果集。storm应用从数据源读取数据，经过计算后，把结果持久化或发送消息给其他应用。        第一版的订单实时统计结构如下图。在数据源方面，最早尝试在业务代码里打日志的方式，但总有业务分支无法覆盖，采集的数据不全。我们的业务数据库是mysql，随后尝试基于mysql binlog的数据源，采用了阿里开源的canal，可以做到完整的收集业务数据变更。    在结果数据的处理上，我们把统计结果持久化到了mysql，并通过另一个后台应用的RESTful API对外提供服务，一个mysql就可以满足数据的读写需求。        为了提升实时统计应用吞吐量，需要提升消息的并发度。spout里设置了消息缓冲区，只要消息缓冲区不满，就会源源不断从消息源canal拉取数据，并把分发到多个bolt处理。    第二版：性能提升  第一版的性能瓶颈在统计结果持久化上。为了确保数据的准确性，把所有的统计指标持久化放在一个数据库事务里。一笔订单状态更新后，会在一个事务里有两类操作：    订单的历史状态也在数据库里存着，要与历史状态对比决定统计逻辑，并把最新的状态持久化。storm的应用本身是无状态的，需要使用存储设备记录状态信息  当大家知道实时计算好用后，各产品都希望有实时数据，统计逻辑越来越复杂。店铺、商品、用户等多个指标的写操作都是在一个事务里commit，这一简单粗暴的方式早期很好满足的统计需求，但是对于update操作持有锁时间过长，严重影响了并发能力。  为此做了数据库事务的瘦身：    去除历史状态的mysql持久化，而是通过单条binlog消息的前后状态对比，决定统计逻辑，这样就做到了统计逻辑上的无状态。但又产生了新问题，如何保证消息有且只有处理一次，为此引入了一个redis用于保存最近24小时内已成功处理的消息binlog偏移量，而storm的消息分发机制又可以保证相同消息总是能分配到一个bolt，避免线程安全问题。  统计业务拆分，先是线上业务和公司内部业务分离，随后又把线上业务按不同产品拆分。这个不仅仅是bolt级别的拆分，而是在spout就完全分开  随着统计应用拆分，在canal和storm应用之间加上消息队列。canal不支持多消费者，而实时统计业务也不用关系数据库底层迁移、主从切换等维护工作，加上消息队列能把底层数据的维护和性能优化交给更专业的团队来做。  热点数据在mysql里做了分桶。比如，通常一个店铺天级别的统计指标在mysql里是一行数据。如果这个店铺有突发的大量订单，会出现多个bolt同时去update这行数据，出现数据热点，mysql里该行数据的锁竞争异常激烈。我们把这样的热点数据做了分桶，实验证明在特定场景下可以有一个数量级吞吐量提升。  最终，第二版的订单实时统计结构如下，主要变化在于引入了MQ，并使用redis作为消息状态的存储。而且由最初的一个应用，被拆成了多个应用。        第三版：准确性提升  经过第二版的优化，实时统计的吞吐量已经不成问题，但还是遇到了做大数据最重要的准确性的问题：    统计口径是会变化的，同样是GMV，一年前和现在的算法可能有变化。例如一笔货到付款订单，是买家下单算成交，还是卖家发货成交，在不同的时期可能使用不同的算法。  实时统计只能按照当时的算法来做计算。有可能出现一段时间周期内的GMV，前一段是按旧算法来计算，后一段按新算法来计算，提供的数据就不准确了。  实时统计难免会出现bug，有不准确的结果，修复错误数据是个难题。  为了解决这个问题，凡是涉及到两天以前数据的，一律由离线计算提供，最终展示给用户的数据，就是历史离线统计数据，并上今日昨日实时统计数据。为什么是今日昨日实时统计呢？因为离线统计有数据准备、建模、统计的过程，要花费几个小时，每天的凌晨很可能还得不到前一天的离线统计结果。    一旦统计口径有变化，只需要重跑离线统计任务就可修复历史数据，做到了冷热数据分离。        实时计算的常见问题  通过订单实时统计的案例，可以抽象出一些基于storm实时计算的共性问题。    消息状态管理  storm不提供消息状态管理，而且为了达到水平扩展，最好是消息之间无状态。对于大数据量、低精度的应用，需要做到无状态。而像订单实时统计这样数据量不算太大，但精度要求极高的场景，需要记录消息处理状态。而为了应付重启、分布式扩展的场景，往往需要额外的介质来存储状态。状态信息往往是kv形式的读写，我们在实际的应用中，使用过redis、HBase作为存储。    消息不丢失、不重复、不乱序  对于准确性要求高的场景，需要保证数据正确的只消费一次。storm的有三种消息处理模式：    at most once，若不实现ack和fail方法，无论后续处理结果如何，消息只会发送一次，必定不能满足高准确性；  at least once，若实现了ack和fail方法，只有调用了ack方法才会任务处理成功，否则会重试。可能会出现消息重复，在并发场景下重复又意味着可能出现乱序；  exactly once，trident每个micro batch作为整体只成功处理一次，但也是无法保证消息真的只正确的处理一次，比如数据已经处理完毕并持久化，但向数据源ack时失败，就可能会有重试。  对于消息重复、乱序的场景，不是简单的消息幂等能解决，有以下的处理思路：    使用前面提到的状态管理的办法，识别出重复、乱序的数据；  业务逻辑中，兼容重复、乱序数据，比如维护一个业务状态机，把异常数据剔除。  对于时序判断，尽量不用使用时间戳，因为在分布式系统里，各服务器时间不一致是很常见的问题。    我们会尝试在运行过程中重启消息源、storm应用、存储/MQ等下游系统，或者制造网络丢包、延迟等异常，手工触发可能的消息丢失、重复、乱序场景，来验证我们的应用能否对应这些异常情况。    复杂拓扑  在storm的文档里，有很多类似下图的复杂应用。        对于需要消息可靠处理的场景，是不适合这样复杂拓扑的，部分失败如何回滚，是否要全部bolt处理完毕才ack，是需要面对的问题。过长的拓扑链路，里面的慢速逻辑会拖慢整体性能。    可以考虑使用更简化的拓扑，不同的逻辑之间尽量解耦，需要使用bolt的结果时，可以把数据持久化或者推送到MQ。        监控  生产环境少不了监控，除了服务器的基础监控，还加了不少storm特有的监控：    消息延迟：消息在业务系统的时间戳与storm应用的当前时间戳对比，大于一定阈值则告警，不同应用的阈值会不同；  消息处理时长、fail数：这两个都可以由storm的接口获取，数值偏大很可能是出了问题；  应用TPS：记录应用的emit、ack、fail数的变化趋势，帮助分析应用的运行情况；  任务级监控：每台服务器的worker、executor数量，这也可以通过storm接口获取。  除此之外，会有各类应用特有的监控，一般都是离线计算的结果与实时计算结果对比。对于数据同步类的应用，数据量比较大，可能会使用采样的方式做校验。'),
(9, 1, 'Zdal分库分表：支付宝是如何在分布式环境下完爆数据库压力的？', 'qz', 1526472244794, 20, 0, 0, '伴随着公司的推送，在2017年7月12日，我迎来了在美团点评的第一年。  在公司的第一年，遇到了一些困难，学习到了很多知识，得到了很多人的帮助。  文字是有生命力的，总结一下自己过去的正式工作的第一年，给自己，也给需要的人。    我的第一年    毕业在即，逃不开的话题就是校园招聘，在校园招聘中斩获了多少，能够让你拥有更多的选择的权利。  我的第一年回顾的第一个主题就是。  校招厮杀        我本身是一个航海院校计算机相关专业的学生，在近几年，某些计算机的专业被提拔到了一本的级别，但在综合的实力上还是和一些老牌院校的计算机专业有着不小的差距，很大程度上，我们是计算机校招队伍中的弱势群体。    在本科阶段，我没有意识到这一点，虽然说也没有浪费本科的时光，但读研和工作后才发现，自己错过了很多储备知识的好时光以及关键的找工作的时间节点。    好在成绩还算可以，顺利保研。在大四的暑假，告诉自己，毕业的时候一定要去一线互联网大厂做后端工程师，当时锁定的主要语言是Java方向的。(确定目标)    确定了目标后，开始了解几个互联网主流厂商的后端Java工程师岗位的一些JD，主要关注了美团点评、阿里、爱奇艺等公司，了解到他们对于应届生大多有以下几点要求。(了解岗位需求)  基础计算机知识扎实  和目标岗位匹配的若干优质实习和项目  一定的技术视野  根据以上几点要求，我在研一阶段就主要做了三件事情。 复习基础知识，找实习，拓宽技术视野。(根据岗位需求定向准备)  基础知识方面，通过搜索引擎和一些问答社区，向前辈取经，把Java相关的基础书籍以及本科的一些当时觉得听着很枯燥的课比如计算机网络、操作系统、数据结构又复习了一遍，通过做题，看视频等手段。见我的知乎提问:    实习方面，在边复习基础知识的时候，我同时也着手开始找Java后端工程师方面的实习。先后在创业公司和阿里实习过，在这个过程中经历了简历准备、求职资源获取、技术面试等，以下文章记录了当中的一些体会。    校招技术岗位，简历挂，内推挂，只因为你做错了....    想去阿里实习其实很简单，只要你....    拓宽技术视野，平时的时候逛一些技术论坛，了解主流互联网公司的架构，Java后端技术方面的最新进展等。    站在巨人的肩膀上，这一点是我自己加的，就是在准备校招的过程中，可以去看一些过来人的面试经验，和一些网友交流面试的体会，过去人家踩过的坑，我尽量不睬。    后面的故事就是，校招拿到了好几个Offer，最终因为个人的喜好和综合因素来到了大众点评。          我的第一年回顾的第二个主题是  初入职场的适应期      我校招刚加入的一个团队是闪惠，是做大众点评商户的优惠买单业务的一个团队。业务量在整个公司来说也是很大的，我加入的时候业务正趋于稳定。不过刚进去的那段时间，还是挺自我否定的。    需求会议听不懂。我们是走迭代的，一般两周一个迭代，每一次开始前，产品经理会召开需求会议，讲一下之后要做哪些东西， 涉及到哪些业务。在刚开始的需求会议上，我遇到了需求听不懂、分配到任务没办法很好的拆解到哪些模块，每次都是靠会后去问导师，才具体明白一个看似简单的需求到底是需要做什么工作，看着组长写的wiki，对每一个迭代要做的东西，需要涉及哪些系统、每一个需求可能需要多少人力，都预估的很清楚，我对自己是有点否定的。因为觉得在自己之前实习的时候，功能完成的也很好呀，怎么正式入职，连需求都听不懂，需求拆解都做不好呢。    技术知识出现不足。因为业务量比较大，线上一些小问题都会被无限的放大，某一天线上突然出现某一个后台项目的所有机器的老年代增长都较快，同事排查后定位是接入的外部包有问题，然后写下了一篇故障分析报告，如何从源码的角度定位了问题，我看了几遍才看懂。    代码被吐槽。我们一般都会有Code Review，会请高级别的工程师过来帮你看你的代码，看是否能够提交上去，在我刚开始写的代码，因为一些不好的习惯和对业务思考的不够，出现了类如NPE、代码复用不够、代码层次不清晰以及命名不太合理等问题，也是经常被打回去修改。    刚进去的这段时间还挺郁闷，觉得哪哪都做不好，有些自我否定。    后来和导师以及领导聊，结合我现在的一些理解的话，我想对当时的自己说:  Relax，公司其实并不期望刚刚进来的你，能够创造多少价值。新人是要成长的，在成长期难免会遇到各种各样的小问题，这可能是大多数人的必经之路，因为你所看到的同事，他们都比你在工作领域待的时间更久，有更多的经验，可以把他们作为目标，但不要把他们作为现在自己的标准，那样会压力太大。  从学校到职场切换的前几个月，难免是不适应的，但在这几个月中，我是通过做到以下几点，帮助自己完成适应。  翻阅团队过往的资料和代码，了解团队的业务现状、核心系统以及主流程，从大方向上入手，再进一步了解业务中的细节。  请教导师和身边的同事，身边的同事是最好的学习资源，他们可以告诉从更高的层面看你现在所处的位置以及遇到的问题，勇于请教，多交流。  多多总结回顾，每周都回顾下自己做了什么，学到了什么。        我的第一年回顾的第三个主题是  不同类型团队下的成长      从刚开始的自我否定中走出来，慢慢融入团队后，会迎来一个成长期。    成熟业务  我刚进来时，团队在做的是一个流量很大的业务，系统架构已经趋向于成熟，作为一个新人，更多的是在修修补补，针对子系统中的某一个模块进行一些开发，很少有机会从头开始做一个项目。在一个成熟的团队，有以下的优点和缺点。    优点: 经过长时间的大流量的业务考证的系统架构和业务设计，能从中收获很多养分，让你之后站在一个更高的视角去看待问题。其二是因为成熟业务流量一般都有一定的量级了，成立至今可能遇到了很多千奇百怪的线上问题，在排查这些问题的过程中，技术能力和沟通能力能得到很大的锻炼。  缺点: 相对的缺点就是，难以参加一个项目完整的开发过程，因为业务架构已经基本定型，新人在这里大多是针对系统具体的子模块进行一些功能上的开发。    创新业务  在我的第一年的后半段，随着团队业务的切换，去做了一个从0到1的业务，主要是依托我们公司积累的数据，为商家提供咨询和数据的一个平台。  优点: 在一个新业务中，有机会从头到尾去设计一个项目，定义和外部系统的交互接口，底层的数据存储设计，系统内部的流程等等。在这个新业务中，我参加了App站内信、用户中心、后台推送中心的完整开发过程，从之前的简单的和后端同事之间的对接，到需要跨团队和客户端、前端、测试打交道，在个人的沟通技巧上得到了很大的成长。在这个从0-1的过程中，对于如何亲手设计一个系统有了经验，同时可以借鉴过去在成熟业务当中学习到的一些准则。如果在一个业务快速发展的新业务中，随着新业务的不断演进，原有的架构会不断得到挑战，进一步提升自己系统设计的功底。  缺点: 并不是每一个新业务都会快速增长，让你不断的遇到新的挑战。在业务的缓慢成长中，可能只是在重复过去学到的技能，得不到足够的挑战，也就错失了进一步成长的空间。    成熟业务和创新业务都有自己的可取之处，不管身处哪个业务，都要像海绵一样汲取其中能够被吸收的营养。        我的第一年回顾的第四个主题是    积极尝试      在我的第一年，还做到了勇于尝试。  在切换到新业务后，前端和数据开发的资源相对比较紧张。  一半是领导的安排，一半是自己觉得我其实是一名软件工程师，目前的职位虽然是后端工程师，但不代表要把自己局限在后端，需要用技术的手段解决问题的，都可以有我的出现。  在业务的演进过程中，我接触了前端的开发，做了一会会全栈工程师，虽然是很简单的页面开发，配上自己的后端接口哈哈。还接触了数据开发，从完全不知道数据开发应该干什么，到对集团数据平台的使用驾轻就熟，从底层数据的提供到后端接口的开发一条龙服务，不仅复习了之前学过的Hive，还学了新技能ElasticSearch，同时把在接触新东西的过程中遇到的问题，总结了下来，帮助别人一起成长。    不局限自己，职业生涯的早期可以多多尝试，软件工程师是解决问题的，至于前面的Title只是说你更擅长哪个方面，当需要你的时候，其实你都可以勇于尝试。    总结    总的来说，我对我过去正式的工作一年还算满意吧。如果让我现在对过去刚入职的自己送上几句建议的话，那么应该是以下四句。  积极提问  保持谦逊  多总结多思考  心态要稳  我的第一年回顾完了，希望我的第二年可以越来越好。你的第一年怎么样呢，如果你也想讲讲你的故事，欢迎投稿~'),
(10, 1, 'ECMAScript 8都发布了，你还没有用上ECMAScript 6？', 'qz', 1526472244794, 20, 0, 0, '大部分时候，微服务都是建立在一种基于请求和响应的协议之上。比如，REST等。这种方式是自然的。我们只需要调用另外一个模块就是了，然后等待响应返回，然后继续。这样的方式确实也满足了我们的很多的场景：用户通过点击页面的一个按钮然后希望发生一些事情。    但是，当我们开始接触许多独立的service的时候，事情就发生改变了。随着service数量急速的增长，同步交互比例也随着service在急速增长。这时候，我们的service就会遇到很多的瓶颈。  于是，不幸的ops工程师们就被我们坑了，他们疲惫的奔波于一个又一个的service，拼凑在一起的二手信息片段，谁说了什么，去往哪里，什么时候发生？等等。。。  这是一个非常典型的问题。市面上也有一些解决方案。一种方案就是确保您的个人服务具有比您的系统更高的SLA。 Google提供了这样做的协议。另一种方法是简单地分解将服务绑定在一起的同步关系。    上面的做法都没有从模式上根本解决问题。我们可以使用异步机制来解决这个问题。比如，电商网站中你会发现这样的同步接口，比如getImage()或者processOrder()，也许你感觉蛮正常。调用了然后希望马上有一个响应。但当用户点击了“购买”后，触发了一个复杂且异步的处理过程。这个过程涉及到购买、送货上门给用户，这一切都是发生在当初的那一次的按钮点击。所以把一个程序处理逻辑切分成多个异步的处理，是我们需要解决的问题。这也正符合我们的真实的世界，真实世界本来就是异步的，拥抱异步吧。    在实际情况下，我们其实已经自动拥抱了异步了。我们发现自己会定时轮询数据库表来更改又或者通过cron定时job来实现一些更新。这些方法都是一些打破同步的方式，但是这种做法总让人感觉有种黑客范儿，感觉像是黑客行为，怪怪的。    在本文中，我们将会讨论一种完全不同的架构：不是把service们通过命令链揉到一块，而是通过事件流（stream of events）来做。这是一个不错的方式。这种方式也是我们之后要讨论的一系列的一个基础。    当我们进入正式的例子之前，我们需要先普及三个简单的概念。一个service与另外一个service有三种交互方式：命令（Commands）、事件（Events）以及查询（Queries）。    事件的美妙之处在于“外部数据”可以被系统中的任何service所重用。    而且从service的角度来说，事件要比命令和查询都要解耦。这个很重要。    服务之间的交互有三种机制：    Commands 。命令是一个操作。希望在另一个服务中执行某些操作的一个请求。 会改变系统状态的东西。 命令期待有响应。  Events 。事件既是一个事实也是一个触发器。 发生了一些事情，表示为通知。  Queries 。查询是一个请求，是一个查找一些东西的请求（request）。重要的是，查询不会使得系统状态发生改变。    一个简单事件驱动流程    让我们开始一个简单的例子：用户购买一个小东西。那么接下来要发生两件事情：    支付。  系统检查是否还有更多的商品需要被订购。  在请求驱动（request-approach）的架构中，这两个行为被表现为一个命令链条。交互就像下面这样：    首先要注意的问题是“购买更多”的这个业务流程是随着订单服务（Order Service）一块被初始化的。这就使得责任不独立，责任跨了两个service。理想情况下，我们希望separation of concerns，也就是关注隔离。    现在如果我们使用事件驱动，而不是请求驱动的方式的话，那么事情就会变得好一些。    在返回给用户之前，UI service 发布一个OrderRequested事件，然后等待OrderConfirmed（或者Rejected）。  订单服务（Orders Service）和库存服务（Stock Service） react这个事件。    仔细看这里，UI service和Orders Service并没有改变很多，而是通过事件来通信，而不是直接调用另一个。    这个Stock service（库存服务）很有趣。Order Service告诉他要做什么。然后StockService自己决定是否参与本次交互，这是事件驱动架构非常重要的属性，也就是：Reciver Driven Flow Control，接收者驱动流程控制。一下子控制反转了。    这种控制反转给接收者，很好的解耦了服务之间的交互，这就为架构提供了可插拔性。组件们可以轻松的被插入和替换掉，优雅！    随着架构变得越来越复杂，这种可插拔性的因素变得更加重要。举个例子，我们要添加一个实时管理定价的service，根据供需调整产品的价格。在一个命令驱动的世界里，我们就需要引入一个可以由库存服务（Stock Service）和订单服务（Orders Service）调用的类似updatePrice()这样的方法。    但是在事件驱动（event-driven）世界更新价格的话，service只需要订阅共享的stream就是了，当相应的条件符合时，就去执行更新价格的操作。    事件（Events）和查询（Queries）的混合    上面的例子只是命令和事件。并没有说到查询。别忘了，我们之前可是说到了三个概念。现在我们开始说查询。我们扩展上面的例子，让订单服务（Orders Service）在支付之前检查是否有足够的库存。    在请求驱动（request-driven）的架构中，我们可能会向库存服务（Stock Service）发送一个查询请求然后获取到当前的库存数量。这就导致了模型混合，事件流纯粹被用作通知，允许任何的service加入flow，但查询却是通过请求驱动的方式直接访问源。    对于服务（service）需要独立发展的较大的生态系统，远程查询要涉及到很多关联，耦合很严重，要把很多服务捆绑在一起。我们可以通过“内部化”来避免这种涉及多个上下文交叉的查询。而事件流可以被用于在每个service中缓存数据集，这样我们就可以在本地来完成查询。    所以，增加这个库存检查，订单服务（Order Service）可以订阅库存服务（Stock Service）的事件流，库存一有更新，订单服务就会收到通知，然后把更新存储到本地的数据库。这样接下来就可以查询本地这个“视图（view）”来检查是否有足够的库存。    纯事件驱动系统没有远程查询的概念 - 事件将状态传播到本地查询的服务    通过事件来传播（ “Queryby Event Propagation”）的查询有以下三个好处：    1、更好的解耦：在本地查询。这样就不涉及跨上下文调用了。这种做法涉及到的服务们远远不及那种”请求驱动”所涉及到的服务数量多。  2、更好的自治：订单服务（Order Service）拥有一份库存数据集的copy，所以订单服务可以任意使用这个本地的数据集，  而不是说像请求驱动里的那样仅仅只能检查库存限额，而且只能通过Stock Service所提供的接口。  3、高效Join：如果我们在每次下订单的时候都要去查询库存，就要求每次都要高效的做join，通过跨网络对两个service进行join。随着需求的增加，或者更多的数据源需要关联，这可能会变得越来越艰巨。所以通过事件传播来查询（Query by Event Propagation）将查询（和join）本地化后就可以解决这个问题（就是本地查询）。    但这种做法也不是没有缺点。 Service从本质上变得有状态了。这样就使得他们需要被跟踪和矫正这些数据集，随着时间的推移，也就是你得保证数据同步。状态的重复也可能使一些问题更难理解（比如如何原子地减少库存数量？），这些问题我们都要小心。但是，所有这些问题都有可行的解决方案，我们只是需要多一点考虑而已。     单一写入者原则（Single Writer Principle）    针对这种风格的系统，也就是事件驱动风格的系统，一个非常有用的原则就是针对指定类型的传播的事件分配责任的时候，应该只分配给一个单一的service：单一的写入者。什么意思呢？就是Stock Service只应该处理库存这一件事情，而Order Service也只属于订单们，等等。    这样的话有助于我们通过单个代码路径（尽管不一定是单个进程）来排除一致性，验证和其他“写入路径（writepath）”问题。因此，在下面的示例中，请注意，订单服务（Order Service）控制着对订单进行的每个状态的更改，但整个事件流跨越了订单（Orders），付款（Payments）和发货（Shipments），每个都由它们各自的服务来管理。    分配“事件传播”（event propagation）的责任很重要，因为这些不仅仅是短暂的事件，或者是那种无须保存短暂的聊天。他们代表了共同的事实（facts），以及“数据在外部（data-on-the-outside）“。因此，随着时间的推移，服务（services）需要去负责更新和同步这些共享数据集（shared datasets）：比如，修复错误，处理schema的变化等情况。    上图中每个颜色代表Kafka的一个topic，针对下订单（Order）、发货和付款。  当用户点击“购买”时，会引发“Order Requested”，等待“Order Confirmed”事件，然后再回复给用户。 另外三个服务处理与其工作流程部分相关的状态转换。 例如，付款处理完成后，订单服务（Order Service）将订单从“已验证（Validated）”推送到“已确认（Confirmed）”。    模式（Patterns）和集群服务（Clustering Services）的混合    上面的说到的模型有点像企业消息（Enterprise Messaging），但其实是有一些不同的。企业消息，在实践中，主要关注状态的转换，通过网络有效地将数据库捆绑在一起。    而事件协作（Event Collaboration）则更偏重的是协作，既然是协作就不简单的是状态转换，事件协作是关于服务（service）通过一系列事件进行一些业务目标，这些事件将触发service的执行。所以这是业务处理（business processing）的一种模式，而不是简单的转换状态的机制。    我们通常希望在我们构建的系统中这种模式具有两面性。事实上，这种模式的美妙之处在于它确实既可以处理微观又可以处理宏观，或者在有些情况下可以被混合。    模式组合使用也很常见。我们可能希望提供远程查询的方便灵活性，而不是本地维护数据集的成本，特别是数据集增长时。这样的话就会让我们的查询变得更加的简单，我们只需要轻松部署简单的函数就可以了。而且我们现在很多都是无状态的，比如容器或者浏览器，在这种情况下也许远程查询是一种合适的选择。    远程查询设计的诀窍就是限制这些查询接口的范围，理想情况下应该是在有限的上下文中（context）。通常情况下，建立一个具有多个特定，具体视图的架构，而不是单一的共享数据存储。注意是多个具体的视图，而不是单一的共享数据存储。（一个独立（bounded）的上下文，或者说是偏向原子，这里说的原子不是侧重微服务中常说的那个“原子服务”。独立上下文，一般是指有那么一组service，它们共享同一个发布流水线或者是同一个领域模型【domain model】）。    为了限制远程查询（remote queries）的边界（scope），我们可以使用一种叫做“集群式上下文模式（clustered context pattern）”。这种情况下，事件就流纯粹是用作上下文之间的通信。但在一个上下文里的具体service们则可以既有事件驱动（event-driven）的处理，同时也有请求驱动（request-driven）的视图（view），具体根据实际情况需要。    在下面的例子中，我们有三个部分，三个之间只通过事件相互沟通。在每一个内部，我们使用了更细粒度的事件驱动流。其中一些包括视图层（查询层）。    还是看下图吧：    集群上下文模型（Clustered Context Model）    事件驱动（event-driven）五个关键好处：   解耦：把一个很长的同步执行链的命令给分解，异步化。 分解同步工作流。 Brokers 或topic解耦服务（service），所以更容易插入新的服务（service），具有更强的插拔性。  离线/异步流：当用户点击按钮时，很多事情都会发生。 一些同步，一些异步。 对能力的设计，无论是以前的，还是将来的，都是更自由的。提高了性能，提高了自由度。  状态同步更新：事件流对分布式数据集提供了一种有效的机制，数据集可以在一个有界的上下文里被重构（“传播”或“更新”）和查询。   Joins：从不同的服务（service）组合/join/扩展数据集更容易。 join更快速，而且还是本地化的。  可追溯性: 当有一个统一化的，中心化的，不可变的，保持性的地方来记录每个互动时，它会及时展现，debug的时候也更容易定位问题，而不是陷入一场关于“分布式”的谋杀。（这里有点晦涩）  总结    Ok，在事件驱动的方法中我们使用事件（Events）而不是命令（Commands）。事件触发业务处理过程。事件也可以用到更新本地视图上。然后我们向你介绍了，在必要时，我们可以再回到远程同步查询这种方式，特别是在较小的系统中，而且我们还将远程同步查询的范围扩大到更大的范围（理想情况下，还是要仅限于单个独立的上下文，也就是单个领域模型，不能再扩大了，刚刚好才是真的好）。    而且所有这些方法都只是模式（pattern）。模式就会有框得太死的问题。模式覆盖不到的地方，我们就要具体情况具体对待了。例如，单点登录服务，全局查询的service仍然是一个好主意，因为它很少更新。    这里的秘诀就是从事件的基准出发去考虑问题。事件让服务之间不再耦合，并且将控制（flow-control）权转移到接收者，这就有了更好的“分离关注（separated concerns）”和更好的可插拔性。    关于事件驱动方法的另一个有趣的事情是，它们对于大型，复杂的架构同样适用，就像它们对于小型，高度协作的架构一样。事件让service们可以自主的决定自己的所有事情，为服务们提供自由发展所需的自主权。    然后我们向你介绍了事件和查询混合的场景。说到查询，在纯事件驱动方法中，查询完全基于本地的数据集，而没有远程查询。本地数据集则是通过事件触发来更新状态。然而，很多时候，基于请求驱动的查询方式在很多时候也是比较方便的，因为本地数据集的方式，状态的同步更新确实是一件更加需要成本的事情。    然后我们说到了单一写入z者原则。单一写入者让我们数据更新有了统一的入口，有助于我们通过单个代码路径（尽管不一定是单个进程）来排除一致性，验证和其他“写入路径（writepath）”问题。    然后我们讨论了集群上下文模型。每个领域模型组成一个独立的区域，然后再由多个区域共同组成一个领域模型集群，模型之间又通过Kafka来交互。每个领域模型里又可以包含几种模式的混合，比如Events、Views、UI，这些里边可以既有事件驱动模式，又有请求驱动模式。    大体就这么多。    感谢Antony Stubbs，Tim Berglund，Kaufman Ng，GwenShapira和Jay Kreps，他们帮助我们回顾了这篇文章。    译者曰：最近也恰好在做有关事件流的内容，对本文中讲到的异步解耦和拆解同步请求链条过长问题深有感触，也非常认同。另外最近有人聊到有关数据库查询效率问题，通过阅读本文也许会让你对查询有一个全新的认识。这些微服务理念看起来好像专属于“微服务”，好像其他人就不需要了解一样。其实也许微服务的这些先进理念就像其他任何的先进的架构理念一样，他们都是我们软件架构知识体系的储备之一，也许在哪天你正在进行的项目遇到了瓶颈，没准本文讨论的这些内容就能派上用场了，不仅仅限于本文举的那个例子。    微服务\"交互方式\"观念转变：     是时候更新一下你对于构建微服务的一些知识体系了。如果你认为REST就是微服务构建的主要交互方式的话，那么也许你错了；如果你认为rpc就是构建微服务的的主要交互方式的话，那么也许你又错了。    因为这两种都属于一种类型，那就是他们都属于请求驱动（request-driven）模式，而这种模式很多时候是同步的，一条链上挂了很多的服务调用，势必在链条变长后，性能堪忧。    本文向你推荐了一个构建微服务的新的工具，或者说是向你补充了。那就是事件驱动（event-driven）的模式。它解耦、异步，带来了更好的扩展性和性能。很多时候，同步会让事情变得异常糟糕！    如果以后有人和讨论起微服务的模式的时候，你可以说REST、rpc（请求驱动）以及事件驱动共同混合使用才会构建出更好的微服务来！    ps：文中部分段落翻译用词略显晦涩，我曾尝试用大白话来翻译，但发现会损失原意，故请仔细斟酌消化。'),
(11, 2, '是时候改变你对微服务的认知了！', 'qz', 1526472244794, 20, 1, 1, '一位工程师，如何才能称得上优秀？除了写得一手好Code，什么样的工作态度和方法才是一个优秀工程师的必备？  7月11日，陆奇出席百度内部Engineering Leadership Talk。作为计算机科学博士及优秀的管理者，他提出的五点要求，对每一位百度工程师都适用。  “我们一定要有一个坚定不移的深刻的理念，相信整个世界终究是为技术所驱动的。”  “有没有其他人已经解决这个问题？然后你可以把你的时间放在更好的创新上。”   “做什么事情一定要做最好，一定要是做业界最强的。”  “我把自己想象是一个软件、一个代码，今天的版本一定要比昨天版本好，明天的版本肯定会比今天好。”  “看到问题也不要去问别人，就把它Fix。”  欲知是哪五点要求？请往下看  Believe in 技术     首先要相信技术，我刚才已经讲了，整个我们工业界，特别是像百度这样的公司，对技术坚定的、不动摇的信念特别重要。  我也分享一下，盖茨提到微软公司的宗旨就是：写软件代表的是世界的将来。  为什么？未来任何一个工业都会变成软件工业。盖茨是对的，因为任何工业任何行业自动化的程度会越来越高，最后你所处理的就是信息和知识。  但现在软件的做法又往前提了一次，因为在人工智能时代，不光是写代码，你必须懂算法，懂硬件，懂数据，整个人工智能的开发过程有一个很大程度的提高，但是，技术，特别是我们这个工业所代表的技术一定是将来任何工业的前沿。  站在巨人的肩膀上做创新  我们观察一下，在美国硅谷、在中国，互联网创业公司也好，大型公司也好，大家的起点是越来越高的。为什么现在创新速度那么快？主要是起点高了。我们可以使用的代码模块，使用的服务的能力，都是大大的提升。  在内部我想强调这一点，很多大公司包括微软在内，内部的Code都重做了无数遍。  我现在的要求是，每一次你写一行新的代码，第一要做的，先想一想你这行代码值得不值得写，是不是有人已经做了同样的工作，可能做得比你还好一点。有没有其他人已经解决这个问题，然后你可以把你的时间放在更好的创新上。  特别是大公司里面重复或者是几乎重复的Code实在太多，浪费太多的资源，对每个人的职业生涯都不是好事情。  我再强调，在大公司内部，你写代码之前想一想，你这行代码要不要写，是不是别人已经有了，站在别人的肩膀上去做这件事情。    追求Engineering Excellence  我要另外强调的一点就是Engineering Excellence，工程的技术的卓越性和能力。  任何市场上竞争就像打仗一样，就看你的部队体能、质量，每一个士兵他的训练的程度，和你给他使机关枪、坦克，还是什么样的武器。  所以Engineering Excellence跟这个类比，我们要建的是一支世界上最强的部队，每一个士兵，每一个领军人，每个人的能力，他的训练都是超强的，然后我们给每个人提供的工具和武器都是一流的。  所以Engineering Excellence是一个永无止境的、个人的、团队的，能力的追求和工具平台的创新，综合在一起可以给我们带来的长期的、核心的竞争力，为社会创造价值，最终的目的是给每个用户、每个企业、整个社会创造价值。  我另外还要在这里强调的一点就是Relentless pursuit of excellence：永无止境的不断的持续的追求。  我们要么不做，要做的事情一定做最好，这是我对大家的要求。数据库也好，做大平台也好，大数据也好，我们要做什么事情，我们一定要下决心，这是我对你们每个人的要求，做什么事情一定要做最好，一定要是做业界最强的。  每天学习，可能是对每个人都是最最重要的。  我今天分享一下，我自己怎么想我自己的。就很简单一个概念，我把自己想象是一个软件、一个代码，今天的版本一定要比昨天版本好，明天的版本肯定会比今天好，因为即使犯了错误，我里面有If statement，说如果见到这个错误，绝对不要再犯。  英语，另外有一句说法就是Life is too short, don’t live the same day twice. 同样一天不要重活两次。每天都是不一样，每天为什么不一样，因为每天都变成最好，每天都变得更好。今天的版本一定要比昨天好，每个好的、杰出的工程师，杰出的技术领袖，一定要保持自己学习的能力，特别是学习的范围。  在这上面我也稍微引申一下，做Computer science的，如果只学Computer science，不去学一些其他的行业，肯定不够。我举个例子，经济学必须要学。为什么这样讲？Computer science它有个很大的限制，他是假定你有输入以后有输出，这种解决问题的方式有它的好处，但有它的限制性。  我给大家举个例子，地图导航，如果你纯粹用这个方式去做，你只是把一个拥挤的地方移到另外一个拥挤的地方。经济学，它对问题的建模是不一样的。它起点是假定是一个整体的一个生态，每个人的输入都是另外一个人的输出，你要用经济学的方式来描述地图导航的问题，你就会去算一个Equilibrium，市场也是这样。  如果把深度学习真的要想彻底，必须把物理重学一遍，把生物学看一遍，再把进化论再看一遍。因为深度学习跟这些东西完全相关，自己肯定想不清楚，要彻底想清楚，必须学。  另外，学产品，我以前跟所有的工程师都讲，如果不懂产品，你不可能成为一个最好的工程师。真正要做世界一流的工程师不光要懂产品，还要懂整个商业，懂生态。因为你的工作的责任，是能够看到将来，把技术展望到将来的需求，把平台、把开发流程、把你的团队为将来做准备。所以学习是非常非常重要的。  最后是从我做起。  我们公司有个非常大的使命，用科技让复杂的世界更简单。整个世界非常非常复杂，人其实所做的事情基本上都是Reduce entropy。  因为从热力学第二定律来讲，世界是会变得越来越乱的，我们想做的事情就是把它变的更简单，让我们生活变得更美好。  而且具体的，我们可以通过人工智能技术来做到唤醒万物，但是这一切是通过每一个人的一点一滴的行为累计起来，从我做起。还有Ownership，看到机会不需要问别人，有机会就去做，看到问题也不要去问别人，就把它Fix。  把我们的使命、把我们的公司当成我们自己每个人的事业来做，我可以坦诚的给每个人讲，如果你把公司的使命，把公司的事业，当成你自己个人的事业，Own everything，你在职业生涯一定是走得最快。从我做起，从身边的每一件事情做起。  Believe in 技术、站在巨人的肩膀上做创新、追求Engineering Excellence、每天学习、Ownership，陆奇送给每一位工程师的建议，你get到了吗？');
INSERT INTO `qz_news` (`nid`, `tid`, `title`, `author`, `updateTime`, `click`, `isRecommend`, `isTop`, `content`) VALUES
(12, 2, '如何成为一个优秀的工程师？“看到问题也不要去问别人，就把它Fix。”！', 'qz', 1526472244794, 20, 1, 0, 'Visual Studio Code 是由微软开发的一款免费、跨平台的文本编辑器。由于其卓越的性能和丰富的功能，它很快就受到了大家的喜爱。  就像大多数 IDE 一样，VSCode 也有一个扩展和主题市场，包含了数以千计质量不同的插件。为了帮助大家挑选出值得下载的插件，我们针对性的收集了一些实用、有趣的插件与大家分享。  1. Open-In-Browser  由于 VSCode 没有提供直接在浏览器中打开文件的内置界面，所以此插件在快捷菜单中添加了在默认浏览器查看文件选项，以及在客户端（Firefox，Chrome，IE）中打开命令面板选项。  2. Quokka  Quokka是一个调试工具插件，能够根据你正在编写的代码提供实时反馈。它易于配置，并能够预览变量的函数和计算值结果。另外，在使用 JSX 或 TypeScript 项目中，它能够开箱即用。  3. Faker  使用流行的 JavaScript 库 – Faker，能够帮你快速的插入用例数据。Faker 可以随机生成姓名、地址、图像、电话号码，或者经典的乱数假文段落，并且每个类别还包含了各种子类别，你可以根据自身的需求来使用这些数据。  4. CSS Peek  使用此插件，你可以追踪至样式表中 CSS 类和 ids 定义的地方。当你在 HTML 文件中右键单击选择器时，选择“ Go to Definition 和 Peek definition ”选项，它便会给你发送样式设置的 CSS 代码。  5. HTML Boilerplate  通过使用 HTML 模版插件，你就摆脱了为 HTML 新文件重新编写头部和正文标签的苦恼。你只需在空文件中输入 html，并按 Tab 键，即可生成干净的文档结构。  6. Prettier  Prettier 是目前 Web 开发中最受欢迎的代码格式化程序。安装了这个插件，它就能够自动应用 Prettier，并将整个 JS 和 CSS 文档快速格式化为统一的代码样式。如果你还想使用 ESLint，那么还有个 Prettier – Eslint 插件，你可不要错过咯！  7. Color Info  这个便捷的插件，将为你提供你在 CSS 中使用颜色的相关信息。你只需在颜色上悬停光标，就可以预览色块中色彩模型的（HEX、 RGB、HSL 和 CMYK）相关信息了。  8. SVG Viewer  此插件在 Visual Studio 代码中添加了许多实用的 SVG 程序，你无需离开编辑器，便可以打开 SVG 文件并查看它们。同时，它还包含了用于转换为 PNG 格式和生成数据 URI 模式的选项。  9. TODO Highlight  这个插件能够在你代码中标记出所有的 TODO 注释，以便更容易追踪任何未完成的业务。在默认的情况下，它会查找 TODO 和 FIXME 关键字。当然，你也可以添加自定义表达式。  10. Icon Fonts  这是一个能够在项目中添加图标字体的插件。该插件支持超过 20 个热门的图标集，包括了 Font Awesome、Ionicons、Glyphicons 和 Material Design Icons。  11. Minify  这是一款用于压缩合并 JavaScript 和 CSS 文件的应用程序。它提供了大量自定义的设置，以及自动压缩保存并导出为.min文件的选项。它能够分别通过 uglify-js、clean-css 和 html-minifier，与 JavaScript、CSS 和 HTML 协同工作。  12. Change Case  虽然 VSCode 内置了开箱即用的文本转换选项，但其只能进行文本大小写的转换。而此插件则添加了用于修改文本的更多命名格式，包括驼峰命名、下划线分隔命名，snake_case 命名以及 CONST_CAS 命名等。  13. Regex Previewer  这是一个用于实时测试正则表达式的实用工具。它可以将正则表达式模式应用在任何打开的文件上，并高亮所有的匹配项。  14. Language and Framework Packs  VSCode 默认支持大量的主流编程语言，但如果你所使用的编程语言不包括在内，也可以通过下载扩展包来自动添加。同时，你还可以添加一些像 React Native 与 Vue 的相关 Web 开发插件包。  15. Themes  当然，在众多用插件中，岂能少了漂亮的主题呢？你每天都会与你的 VSCode 编辑器进行“亲密的接触”，为何不把它打扮得更漂亮些呢？这里有一些帮助你更改侧边栏的配色方案，以及图标的相关主题，与大家分享：'),
(13, 2, '精选！15 个必备的 VSCode 插件（前端类）', 'qz', 1526472244794, 20, 1, 0, 'Zdal是支付宝自主研发的数据中间件产品，采用标准的JDBC规范，可以在分布式环境下看上去像传统数据库一样提供海量数据服务，是一种通用的分库分表数据库访问框架，解决单库单表数据库访问压力，Zdal主要提供分库分表，结果集合并，sql解析，数据库failover动态切换等功能，提供互联网金融行业的数据访问层统一解决方案，目前已经在支付宝的交易，支付，会员，金融等大部分关键应用上使用，并且在2013年双11大促中运行稳定。    ▲系统目标  1.数据访问路由，将针对数据的读写请求发送到最合适的地方。  2.数据存储的自由扩展，不再受限于单台机器的容量瓶颈和速度瓶颈，平滑迁移。  3.使用zdal组件进行数据库的拆分，搭建分布式环境下的海量数据访问平台。  4.实现mysql，oracle，DB2数据库访问能力。    【系统架构和领域模型】  ▲系统整体架构      zdal组件主要有5部分组成：  1. Zdal-client：开发编程接口，实现jdbc的Datasource，Connection，Statement，PreparedStatement，ResultSet等接口，实现通用的jdbc-sql访问，内部还实现读库重试，group数据源的选择器，表名替换，sql执行器等功能。  2. Zdal-parser：支持oracle/mysql/db2等数据库的sql语句解析，并且缓存。根据规则引擎提供的参数列表，在指定的sql中查找到需要的参数，然后返回拆分字段。  3. Zdal-rule：根据zdal-parser解析后的拆分字段值来确定逻辑库和物理表名。  4. Zdal-datasource：数据库连接的管理，支持mysql，oracle，db2数据库的连接管理。  5. Zdal-common：zdal组件所使用的一些公共组件类。    ▲总体流程      ▲Zdal初始化流程    ▲分库分表初始化流程    ▲分库分表sql执行流程      【关键技术&第三方框架】  ▲Zdal-client  Zdal-client 模块主要是完成以下几部分工作：  1.加载配置文件进行初始化工作，初始化groovy规则引擎。  2.对jdbc 标准接口的封装，包括 DataSource、Connection、Statement、PrepareStatment等，并提供一个一对多的管理容器，可以管理多个jdbc建立的资源。  3.SQL执行：根据规则引擎生成的目标库id和表名，进行表名替换后在目标库上执行该sql，如果是跨库跨表的sql，需要进行多个结果集的merge。  4.读库重试，即在读库发生断连接问题的时候,Zdal会自动的尝试从对等的其他读库中去查询这条数据，尽最大努力保证在数据库还有访问能力的情况下，保证数据的可访问性。  5.将传入的sql 和 参数进行包装后，调用 zdal-parser 和zdal-rule的 相关接口，进行sql的解析以及计算相应的分库分表结果。在此模块将会实现表名替换的功能，即将sql的逻辑表名替换成带后缀的物理表名。  6.动态指定读库功能，即可以让业务根据实际需求指定一组中的某个读库进行操作，也可以指定到写库读。  7.聚合函数结果集合并，针对count,sum,max,min等聚合函数在多个数据源的执行结果，进行结果集的合并。      ▲Zdal-parser  Parser组件包括如下几个部分：  1. Lexer 词法解析。  2.Parser，Parser包括ExprParser，各种StatementParser。  3. AST, Abstract Syntax TreeParse出来的结果就是AST。  4.StatementParser：解析各种sql语句，按照词法分析和语法分析提炼sql的关键字。  5.Visitor：根据StatementParser的解析结果对AST做各种处理，比如FormatOutput，遍历，tableName，表达式，函数,绑定参数，分页参数，获取sql解析的结果。    Zdal-Parser的主要核心类图如下：    ▲Zdal-rule  Zdal-rule 主要是完成规则的计算，包括分库的计算和分表的计算，相当于是一个二次路由的过程，包括单库单表、单库多表以及多库多表等几种情况。为了适应规则的灵活配置，目前主要是采用书写groovy脚本的方式来配置规则，或者在代码里封装拆分规则静态方法，在规则里调用该静态方法即可。    我们假设分库规则是 user_id % 9  /  3 分表规则是user_id % 9 % 3'),
(14, 2, 'Zdal分库分表：支付宝是如何在分布式环境下完爆数据库压力的？', 'qz', 1526472244794, 20, 0, 0, 'ES8已经与17年6月底发布，而很多的前端开发者还没有开始用上ES6。本文聊一聊怎么快速入门ES6，并将ES6的语法应用到实战项目中。  阅读全文大约需要15分钟。  文中以 ES 表示 ECMAScript。  今年六月底，TC39发布新一版的ES 8（ES 2017），自从ES6在15年发布之后，每一年TC39都会发布新一版的ES语言标准。  我了解的前端开发者中，还有很多人没有用上ES6，有的人是觉得ES5用的挺好的，懒得去学ES6，有的人是有想学ES6的决心，但是苦于没有合适的机会（项目）去实战练习。  如果你用过React，Vue或Nodejs等，那你多多少少都会使用到一些ES6语法的。  ES8中的新特性，浏览器厂商和语法转换器还需要一段来实现，不如我们还是先聊聊怎么在你的项目中用上ES6吧。  什么是ES6？它和ES5有什么区别？  我们常说的JavaScript是指ES3和ES5，ES6是ECMAScript 6 的缩写。  对于经常写原生JavaScript的前端开发者来说，对ES5中的语法肯定比较熟悉，比如数组中的一些方法forEach，map，filter，some，every，indexOf，lastIndexOf，reduce，reduceRight ……，以及对象（Object）和函数（Function）都拓展了很多方法，这里不多赘叙。  ES6给前端开发者带来了很多的新的特性，可以更简单的实现更复杂的操作，很大的提高开发效率，提高代码的整洁性。  ES6中的新特性有很多，列一些比较常用的特性：  Block-Scoped Constructs Let and Const（块作用域构造Let and Const）  Default Parameters（默认参数）  Template Literals （模板字符串）  Multi-line Strings （多行字符串）  Arrow Functions （箭头函数）  Enhanced Object Literals （增强的对象文本）  Promises  Classes（类）  Modules（模块）  Destructuring Assignment （解构赋值）  下面介绍下这些常用的ES6特性。  Block-Scoped Constructs Let and Const（块作用域构造Let and Const）  ES6提供了两个新的声明变量的关键字：let和const。而let和const要和块级作用域结合才能发挥其优势。  什么是块级作用域？  块级作用域的表示一对大括号{}包围的区域是一个独立的作用域，在这个作用域内用let声明的变量a，只能在这个作用域内被访问到，在这对大括号外面是访问不到a的。  当然，在块级作用域中还可以声明函数，该函数也是只能作用域内部才能被访问到。所以，在if、else、for甚至是一对单独的{}，都是一个块级作用域。  在ES6之前，是没有块级作用域的概念的，只有全局作用域和函数作用域两种，并且，用var声明的变量和用function声明的函数会被提前到作用域的顶部，这也就是我们常说的声明提前。  用let声明的变量是存在于距离声明语句最近的一个作用域（全局作用域、函数作用域或块级作用域）内的，在声明的时候，可选的将其初始化成一个值。  语法如下：    let var1 [= value1] [, var2 [= value2 ] ] [, ..., varN [= valueN]] ;  这一点与var的声明不同，用var声明的变量是属于离他最近的一个全局作用域或函数作用域中，且声明会被提前。在块级作用域中，var的声明与在全局作用域和函数作用域中是一样的。    块级作用域和let声明变量，解决了使用var一些痛点，相当于用let声明的变量不会被提前到作用域顶部。    有一点需要注意，let也是声明提前,但是let声明变量的语句必须在使用该变量语句之前，在声明之前引用会报错该变量未被声明，且let不允许重复声明相同名称的变量，否则会报错。我们看下例子：    {    var hello = \'Hello\';    let world = \'World\';  }  console.log(hello);  console.log(world);  在Chrome浏览器的控制台（最新版本的Chrome已支持一部分ES6语法）执行一下，会发现有报错，见下图。constconst声明与let基本相同，它也是存在于块级作用域内。  有一点区别就是const声明的是常量，即不可被重新赋值改变原值。需要注意，const在声明常量的时候，必须同时给常量初始化赋值。如果只声明，不初始化值的话，会报错。见下面代码。  const MAX;  // Uncaught SyntaxError: Missing initializer in const declaration  声明变量的方法  在ES5中，可以通过var和function这两种方法来声明变量。    而在ES6中，除了增加了let和const两种声明方式，还有接下来要介绍的import和class的声明方式。  Default Parameters（默认参数）  默认参数是ES6中对函数拓展的一个特性，可以直接为函数的参数设置默认值，当某一参数设置了默认值时，如果调用函数的时候没有传该参数，则该参数的值为默认值，如果传了该参数，则该参数的值为传递的参数值。  在ES6之前，我们可以通过手动的方式，为函数的参数设置默认值，代码如下：  function sign (x) {    if (typeof x === \'undefined\') {      x = \'default\'    }    console.log(x)  }  sign(\'new sign\')    // new sign  sign()              // default  将上述代码换成ES6模式，可以这样写：    function sign (x = \'default\') {    console.log(x)      }  sign(\'new sign\')    // new sign  sign()              // default  Template Literals （模板字符串）    ES6提供了模板字符串的特性，模板字符串是使用反引号（`）和${}实现字符串的拼接，字符串中可以嵌入变量。  在ES6之前，我们一般这样输出模板：  var name = \'Henry\';  var welcome = \'Hello, \' + name + \'!\';  console.log(welcome);   // Hello, Henry!  在ES6中，模板字符串可以这样拼接字符串：  let name = \'Henry\';  let welcome = `Hello, ${ name }!`;  console.log(welcome);   // Hello, Henry  模板字符串的计算规则是在两个反引号之间将字符串拼接到一起，如果反引号之间含有${}，则会计算这对大括号内的值，大括号里面可以是任意的JavaScript表达式，可以进行运算和引用对象属性。  let a = 3;  let number = `$ {a + 2 }`;  console.log(`${ number }`);    // 5    let b = { c: 2, d: 4 };  console.log(`${ b.c * b.d }`) ;     // 8  Multi-line Strings （多行字符串）    多行字符串是模板字符串的拓展，它跟模板字符串是同样的解析方式，不同的是，它可以拼接多行的字符串，且拼接的字符串中会保留所有的空格和缩进。  如果需要用字符串来拼接DOM树结构时，可以这样写：  let titleValue = \'This is a title\'；  let htmlStr = `              ${ titleValue }          This is a paragraph.     `;  上述代码中，能看到JavaScript代码和伪html代码的结合，完全可以将模板字符串的多行字符串封装成一个页面模板工具，绝对是轻量高效的。  还有，这种书写方式是不是很眼熟，跟React的JSX是不是很像双胞胎啊。  Arrow Functions （箭头函数）  在ES6中，可以使用箭头（=>）来声明一个函数，称作箭头函数。  ES5中声明一个函数，可以这样写：  var func = function (a) {    return a + 2;  }  将这个函数换成 箭头函数：  let func = a => a + 2;  如果函数有多个参数，需要用括号包含所有参数，只有一个参数的时候，可以省略括号，如果没有设置参数，也必须有括号。示例如下：    let func1 = (arg1, arg2, arg3) => {    return arg1 + arg2 + arg3;  }    let func2 = arg => {    console.log(arg)  }  let func3 = () => {    console.log(`This is an arrow function.`)  }  需要注意的是，箭头函数没有自己的this，如果在箭头函数内部使用this，那样这个this是箭头函数外部的this，也是因为箭头函数没有this，所以，箭头函数不能用作构造函数。如果用箭头函数来写回调函数时，就不用再将外部this保存起来了。  // ES5  function foo() {    var _this = this;          setTimeout(function() {      console.log(\'id:\', _this.id);            }, 200)  }  // ES6  function foo() {    setTimeout(() => {      console.log(`id:${ this.id }`)            }, 200)  }  Enhanced Object Literals （增强的对象文本）    在ES6，对象字面值扩展支持在创建时设置原型，简写foo：foo分配，定义方法，加工父函数（super calls），计算属性名(动态)。总之，这些也带来了对象字面值和类声明紧密联系起来，让基于对象的设计得益于一些同样的便利。    var obj = {    // __proto__ 原型    __proto__: theProtoObj,    // Shorthand for ‘handler: handler’  简写    handler,    // Methods    toString() {      // Super calls     继承      return \"d \" + super.toString();    },    // Computed (dynamic) property names 计算属性名    [\'prop_\' + (() => 42)()]: \'name\'  };  Promises  Promise是异步编程的一种解决方案，它是一个对象，且只要开始就会一直进行下去，直到成功或者失败。就像它的字面意思诺言一样，一个诺言，只要被许下，就只有两种解决：成功或失败。  Promise的结果是由异步操作的结果决定的，且一旦结果形成，便不可再被改变，任何时候都得到同样的结果。  需要注意的是：Promise被新建后，便无法被取消，会执行下去，直到出现结果；如果不设置回调，Promise内部抛出的异常，不会反应到外部。'),
(15, 2, 'ECMAScript 8都发布了，你还没有用上ECMAScript 6？', 'qz', 1526472244794, 20, 0, 0, '前言  工欲善其事，必先利其器。我们做代码审计之前选好工具也是十分必要的。下面我给大家介绍两款代码审计中比较好用的工具。  一、审计工具介绍  PHP 代码审计系统— RIPS  功能介绍  RIPS 是一款基于 PHP 开发的针对 PHP 代码安全审计的软件。  另外，它也是一款开源软件，由国外安全研究员 Johannes Dahse 开发，程序只有 450KB，目前能下载到的最新版是0.55。  在写这段文字之前笔者特意读过它的源码，它最大的亮点在于调用了 PHP 内置解析器接口token_get_all，  并且使用Parser做了语法分析，实现了跨文件的变量及函数追踪，扫描结果中非常直观地展示了漏洞形成及变量传递过程，误报率非常低。  RIPS 能够发现 SQL 注入、XSS 跨站、文件包含、代码执行、文件读取等多种漏洞，支持多种样式的代码高亮。比较有意思的是，它还支持自动生成漏洞利用。    下载地址：https://jaist.dl.sourceforge.net/project/rips-scanner/rips-0.55.zip.  解压到任意一个PHP的运行目录  在浏览器输入对应网址，可以通过下图看到有一个path 在里面填写你要分析的项目文件路径，点击 scan.  界面截图    seay 源代码审计系统  功能介绍  这些是seay 第一个版本的部分功能，现在最新版本是2.1。  傻瓜化的自动审计 。  支持php代码调试 。  函数/变量定位 。  生成审计报告。  自定义审计规则 。  mysql数据库管理 。  黑盒敏感信息泄露一键审计 。  支持正则匹配调试 。  编辑保存文件 。  POST数据包提交 。  安装方法  安装环境需要 .NET2.0以上版本环境才能运行，下载安装包之后点击下一步就安装好了，非常的简便。  安装包下载地址：http://enkj.jb51.net:81/201408/tools/Seayydmsjxt(jb51.net).rar  操作界面的截图    二、代码审计实战  通过刚才安装的两个审计工具运行后我们可以发现，会分析出很多隐藏的漏洞，那下面我们看看其中的SQL注入、XSS、CSRF产生的原因,通过原因来分析如何去审计代码。  SQL注入  SQL注入漏洞一直是web系统漏洞中占比非常大的一种漏洞，下面我们来看看SQL注入的几种方式。  SQL 注入漏洞分类  从利用方式角度可以分为两种类型:常规注入、宽字节注入。  常规注入方式，通常没有任何过滤，直接把参数存放到了SQL语句当中，如下图。  非常容易发现，现在开发者一般都会做一些过滤，比如使用addslashes()，但是过滤有时候也不一定好使。  编码注入方式  宽字节注入，这个是怎么回事呢？  在实际环境中程序员一般不会写上面类似的代码，一般都会用addslashes()等过滤函数对从web传递过来的参数进行过滤。不过有句话叫做，道高一尺魔高一丈，我们看看白帽子是怎么突破的。用PHP连接MySQL的时候，当设置 character_set_client=gbk时候会导致一个编码漏洞。我们知道addslashes() 会把参数 1’ 转换成 1\\’,而我们提交参数 1%df’ 时候会转成 1縗’，那我们输入 1%df’ or 1=1%23时候，会被转换成 1縗’ or 1=1#’。  简单来说%df’会被过滤函数转义为%df\\’ ，%df\\’ = %df%5c%27  在使用gbk编码的时候会认为%df%5c是一个宽字节%df%5c%27=縗’，这样就会产生注入。  那如何防御这个宽字节呢？我希望大家开发网站尽量使用UTF8编码格式，如果转换麻烦，最安全的方法就是使用PDO预处理。挖掘这种漏洞主要是检查是否使用了gbk，搜索guanjianc character_set_client=gbk 和mysql_set_chatset(\'gbk\') 。  二次urldecode注入，这中方式也是因为使用了urldecode不当所引起的漏洞。  我们刚才知道了 addslashes()函数可以防止注入，他会在(‘)、(“)、()前面加上反斜杠来转义。  那我们假设我们开启了GPC，我们提交了一个参数，/test.php?uid=1%2527,因为参数中没有单引号，所以第一次解码会变成uid=1%27,%25解码出来就是%，  这时候程序里如果再去使用urldecode来解码，就会把%27解码成单引号(‘)，最终的结果就是uid=1’.  我们现在知道了原有是因为urldecode引起的，我们可以通过编辑器的搜索urldecode和rawurldecode找到二次url漏洞。  从漏洞类型区分可以分为三种类型：  可显  攻击者可以直接在当前界面内容中获取想要获得的内容。  报错  数据库查询返回结果并没有在页面中显示，但是应用程序将数据库报错信息打印到了页面中。  所以攻击者可以构造数据库报错语句，从报错信息中获取想要获得的内容，所以我建议在数据库类中设置不抛出错误信息。  盲注  数据库查询结果无法从直观页面中获取攻击者通过使用数据库逻辑或使数据库库执行延时等方法获取想要获得的内容。  SQL 注入漏洞挖掘方法  针对上面提到的利用漏洞方法，总结了以下的挖掘方法：  参数接收位置，检查是否有没过滤直接使用  _POST、$_COOKIE 参数的。  SQL语句检查，搜索关键词 select update insert 等SQL语句关键处，检查SQL语句的参数是否可以被控制。  宽字节注入,如果网站使用的 GBK 编码情况下，搜索guanjianc character_set_client=gbk 和mysql_set_chatset(\'gbk\') 就行。  二次 urldecode 注入，少部分情况，gpc 可以通过编辑器的搜索 urldecode 和 rawurldecode 找到二次url漏洞。  SQL 注入漏洞防范方法  虽然SQL注入漏洞非常多，但是防范起来却挺简单的，下面介绍几个过滤函数和类:  gpc/rutime 魔术引号  过滤函数和类  addslashes  mysql_real_escape_string  intval  PDO 预处理  XSS跨站  前言  XSS 又叫 CSS (Cross Site Script) ，跨站脚本攻击。它指的是恶意攻击者往 Web 页面里插入恶意 html 代码，当用户浏览该页之时，嵌入其中 Web 里面的 html 代码会被执行，从而达到恶意的特殊目的。  XSS 属于被动式的攻击，因为其被动且不好利用，所以许多人常呼略其危害性。在 WEB2.0 时代，强调的是互动，使得用户输入信息的机会大增，在这个情况下，我们作为开发者，在开发的时候，要提高警惕。  xss 漏洞分类  反射型，危害小，一般  反射型XSS原理：就是通过给别人发送带有恶意脚本代码参数的URL，当URL地址被打开时，特定的代码参数会被HTML解析，执行，如此就可以获取用户的COOIKE，进而盗号登陆。比如hack甲构造好修改密码的URL并把密码修改成123，但是修改密码只有在登陆方乙才能修改，乙在登陆的情况下点击甲构造好的URL将直接在不知情的情况下修改密码。  特点是：非持久化，必须用户点击带有特定参数的链接才能引起。  存储型，危害大，影响时间长  存储型XSS原理，假设你打开了一篇正常的文章页面，下面有评论功能。这个时候你去评论了一下，在文本框中输入了一些JavaScript代码，提交之后,你刷新这个页面后发现刚刚提交的代码又被原封不动的返回来并且执行了。  这个时候你会想,我要写一段 JavaScript 代码获取 cookie 信息，然后通过ajax发送到自己的服务器去。构造好代码后你把链接发给其他的朋友，或者网站的管理员，他们打开 JavaScript 代码就执行了，你服务器就接收到了sessionid，你就可以拿到他的用户权限了。  dom型 XSS 是因为 JavaScript 执行了dom 操作，所造成的 XSS 漏洞，具体如下图。可以看到虽然经过 html 转义了，但是这块代码在返回到 html 中，又被 JavaScript 作为 dom 元素操作。那当我输入?name=＜img src=\"1\" onerror=\"alert(1)\"/＞ 的时候依然会存在 XSS 漏洞。    xss 漏洞挖掘方法  根据上面的一些特点，可以总结出几个分析出几个挖掘方法：  数据接收位置，检查 _POST、$_COOKIE是否经过转义。  常见的反射型XSS搜索这种类似位置发现次数较多。  而存储型在文章，评论出现比较多。  XSS 漏洞防范方法  转义html实体，有两种方式：在入口和出口,我建议是在入口处转义，防止出口位置取出来的时候忘记转义，如果已经在入口转义了，出口位置就不用再次转义。  在富文本编辑器中，经常会用到一些元素的属性，比如上图的onerror，那我们还需对元素的属性建立黑白名单。  httpOnly 即使存在xss漏洞，可以把危害大大降低。  CSRF漏洞  CSRF 漏洞介绍  CSRF（Cross-site request forgery）跨站请求伪造，通常缩写为CSRF或者XSRF，是一种对网站的恶意利用。听起来像跨站脚本（XSS），但它与XSS非常不同，XSS利用站点内的信任用户。  而 CSRF 则通过伪装来自受信任用户的请求来利用受信任的网站。与 XSS 攻击相比，CSRF 攻击往往不大流行（因此对其进行防范的资源也相当稀少）和难以防范，所以被认为比XSS更具危险性。  csrf 主要用来做越权操作，而且 csrf 一直没有被关注起来，所以很多程序现在也没有相关的防范措施。  CSRF 案例  我们来看下面的一段代码,这个表单当被访问到的时候，用户就退出了登录。假设有一个转账的表单，只需要填写对方的用户名，和金额就可以，那如果我提前把 URL 构造好，发给受害者，当点击后，钱就被转走了。  或者我把这个 URL 放到我的网页中，通过<img src=\"我构造的URL\" ，当其他人打开我的网址后，就中招了。  CSRF漏洞挖掘方法  通过上面的描述，我们知道了漏洞的原有，那我们审计的时候可以检查处理表单有没有以下判断。  是否有验证 token。  是否有图片验证码。  是否有 refe 信息。  如果三个判断都没有，那么就存在了 CSRF 漏洞，CSRF 不仅限于 GET 请求， POST 请求同样存在。  CSRF 漏洞防范方法  图片验证码，这个想必大家都知道，但是用户体验并不好，我们可以看下面的一些处理方法。  token验证。  token验证方法如下，每次访问表单页的时候，生成一个不可预测的token存放在服务器session中，另外一份放页面中，提交表单的时候需要把这个token带过去，接收表单的时候先验证一下token是否合法。  Refeer信息验证  大多数情况下，浏览器访问一个地址，其中header头里面会包含Referer信息,里面存储了请求是从哪里发起的。  如果HTTP头里包含有Referer的时候，我们可以区分请求是同域下还是跨站发起的，所以我们也可以通过判断有问题的请求是否是同域下发起的来防御 CSRF 攻击。  Referer 验证的时候有几点需要注意，如果判断Referer是否包含 *.XXX.com,如果有子域名有漏洞，会存在绕过的可能。  如果判断的条件的是Referer中是否包含字符 ‘xxx.com’  那攻击者在他目录中建立一个 xxx.com 文件夹同样存在绕过的可能。如果可以最合适的判断是，直接判断是否等于当前域名。    三、常规漏洞的防范方法    taint PHP 安全扩展    功能介绍  Taint 可以用来检测隐藏的 XSS code, SQL 注入， Shell注入等漏洞，并且这些漏洞如果要用静态分析工具去排查， 将会非常困难， 我们来看下面这张图:  安装方法  下载 taint：  http://pecl.php.net/package/taint  配置  /usr/local/php/bin/phpize  ./configure --with-php-config=/usr/local/php/bin/php-config  make && make install  更加详细的可以参考：http://www.cnblogs.com/linzhenjie/p/5485474.html  应用场景  开发团队要求每个人都做到非常的安全比较难，但是把taint安装在开发环境，特别适合，一看到 warning 信息一般都回去改。  ngx_lua_waf  功能介绍  防止 sql 注入，本地包含，部分溢出，fuzzing 测试，xss，SSRF 等 web攻击。  防止 svn /备份之类文件泄漏。  防止 ApacheBench 之类压力测试工具的攻击。  屏蔽常见的扫描黑客工具，扫描器。  屏蔽异常的网络请求。  屏蔽图片附件类目录 php 执行权限。  防止 webshell 上传。  安装方法  安装依赖: luajit 、ngx_devel_kit、nginx_lua_module  安装nginx、ngx_lua_waf  在nginx.conf里的 http 添加配置  详细安装文档'),
(16, 3, '是时候改变你对微服务的认知了！', 'qz', 1526472244794, 20, 1, 1, '前言  工欲善其事，必先利其器。我们做代码审计之前选好工具也是十分必要的。下面我给大家介绍两款代码审计中比较好用的工具。  一、审计工具介绍  PHP 代码审计系统— RIPS  功能介绍  RIPS 是一款基于 PHP 开发的针对 PHP 代码安全审计的软件。  另外，它也是一款开源软件，由国外安全研究员 Johannes Dahse 开发，程序只有 450KB，目前能下载到的最新版是0.55。  在写这段文字之前笔者特意读过它的源码，它最大的亮点在于调用了 PHP 内置解析器接口token_get_all，  并且使用Parser做了语法分析，实现了跨文件的变量及函数追踪，扫描结果中非常直观地展示了漏洞形成及变量传递过程，误报率非常低。  RIPS 能够发现 SQL 注入、XSS 跨站、文件包含、代码执行、文件读取等多种漏洞，支持多种样式的代码高亮。比较有意思的是，它还支持自动生成漏洞利用。    下载地址：https://jaist.dl.sourceforge.net/project/rips-scanner/rips-0.55.zip.  解压到任意一个PHP的运行目录  在浏览器输入对应网址，可以通过下图看到有一个path 在里面填写你要分析的项目文件路径，点击 scan.  界面截图    seay 源代码审计系统  功能介绍  这些是seay 第一个版本的部分功能，现在最新版本是2.1。  傻瓜化的自动审计 。  支持php代码调试 。  函数/变量定位 。  生成审计报告。  自定义审计规则 。  mysql数据库管理 。  黑盒敏感信息泄露一键审计 。  支持正则匹配调试 。  编辑保存文件 。  POST数据包提交 。  安装方法  安装环境需要 .NET2.0以上版本环境才能运行，下载安装包之后点击下一步就安装好了，非常的简便。  安装包下载地址：http://enkj.jb51.net:81/201408/tools/Seayydmsjxt(jb51.net).rar  操作界面的截图    二、代码审计实战  通过刚才安装的两个审计工具运行后我们可以发现，会分析出很多隐藏的漏洞，那下面我们看看其中的SQL注入、XSS、CSRF产生的原因,通过原因来分析如何去审计代码。  SQL注入  SQL注入漏洞一直是web系统漏洞中占比非常大的一种漏洞，下面我们来看看SQL注入的几种方式。  SQL 注入漏洞分类  从利用方式角度可以分为两种类型:常规注入、宽字节注入。  常规注入方式，通常没有任何过滤，直接把参数存放到了SQL语句当中，如下图。  非常容易发现，现在开发者一般都会做一些过滤，比如使用addslashes()，但是过滤有时候也不一定好使。  编码注入方式  宽字节注入，这个是怎么回事呢？  在实际环境中程序员一般不会写上面类似的代码，一般都会用addslashes()等过滤函数对从web传递过来的参数进行过滤。不过有句话叫做，道高一尺魔高一丈，我们看看白帽子是怎么突破的。用PHP连接MySQL的时候，当设置 character_set_client=gbk时候会导致一个编码漏洞。我们知道addslashes() 会把参数 1’ 转换成 1\\’,而我们提交参数 1%df’ 时候会转成 1縗’，那我们输入 1%df’ or 1=1%23时候，会被转换成 1縗’ or 1=1#’。  简单来说%df’会被过滤函数转义为%df\\’ ，%df\\’ = %df%5c%27  在使用gbk编码的时候会认为%df%5c是一个宽字节%df%5c%27=縗’，这样就会产生注入。  那如何防御这个宽字节呢？我希望大家开发网站尽量使用UTF8编码格式，如果转换麻烦，最安全的方法就是使用PDO预处理。挖掘这种漏洞主要是检查是否使用了gbk，搜索guanjianc character_set_client=gbk 和mysql_set_chatset(\'gbk\') 。  二次urldecode注入，这中方式也是因为使用了urldecode不当所引起的漏洞。  我们刚才知道了 addslashes()函数可以防止注入，他会在(‘)、(“)、()前面加上反斜杠来转义。  那我们假设我们开启了GPC，我们提交了一个参数，/test.php?uid=1%2527,因为参数中没有单引号，所以第一次解码会变成uid=1%27,%25解码出来就是%，  这时候程序里如果再去使用urldecode来解码，就会把%27解码成单引号(‘)，最终的结果就是uid=1’.  我们现在知道了原有是因为urldecode引起的，我们可以通过编辑器的搜索urldecode和rawurldecode找到二次url漏洞。  从漏洞类型区分可以分为三种类型：  可显  攻击者可以直接在当前界面内容中获取想要获得的内容。  报错  数据库查询返回结果并没有在页面中显示，但是应用程序将数据库报错信息打印到了页面中。  所以攻击者可以构造数据库报错语句，从报错信息中获取想要获得的内容，所以我建议在数据库类中设置不抛出错误信息。  盲注  数据库查询结果无法从直观页面中获取攻击者通过使用数据库逻辑或使数据库库执行延时等方法获取想要获得的内容。  SQL 注入漏洞挖掘方法  针对上面提到的利用漏洞方法，总结了以下的挖掘方法：  参数接收位置，检查是否有没过滤直接使用  _POST、$_COOKIE 参数的。  SQL语句检查，搜索关键词 select update insert 等SQL语句关键处，检查SQL语句的参数是否可以被控制。  宽字节注入,如果网站使用的 GBK 编码情况下，搜索guanjianc character_set_client=gbk 和mysql_set_chatset(\'gbk\') 就行。  二次 urldecode 注入，少部分情况，gpc 可以通过编辑器的搜索 urldecode 和 rawurldecode 找到二次url漏洞。  SQL 注入漏洞防范方法  虽然SQL注入漏洞非常多，但是防范起来却挺简单的，下面介绍几个过滤函数和类:  gpc/rutime 魔术引号  过滤函数和类  addslashes  mysql_real_escape_string  intval  PDO 预处理  XSS跨站  前言  XSS 又叫 CSS (Cross Site Script) ，跨站脚本攻击。它指的是恶意攻击者往 Web 页面里插入恶意 html 代码，当用户浏览该页之时，嵌入其中 Web 里面的 html 代码会被执行，从而达到恶意的特殊目的。  XSS 属于被动式的攻击，因为其被动且不好利用，所以许多人常呼略其危害性。在 WEB2.0 时代，强调的是互动，使得用户输入信息的机会大增，在这个情况下，我们作为开发者，在开发的时候，要提高警惕。  xss 漏洞分类  反射型，危害小，一般  反射型XSS原理：就是通过给别人发送带有恶意脚本代码参数的URL，当URL地址被打开时，特定的代码参数会被HTML解析，执行，如此就可以获取用户的COOIKE，进而盗号登陆。比如hack甲构造好修改密码的URL并把密码修改成123，但是修改密码只有在登陆方乙才能修改，乙在登陆的情况下点击甲构造好的URL将直接在不知情的情况下修改密码。  特点是：非持久化，必须用户点击带有特定参数的链接才能引起。  存储型，危害大，影响时间长  存储型XSS原理，假设你打开了一篇正常的文章页面，下面有评论功能。这个时候你去评论了一下，在文本框中输入了一些JavaScript代码，提交之后,你刷新这个页面后发现刚刚提交的代码又被原封不动的返回来并且执行了。  这个时候你会想,我要写一段 JavaScript 代码获取 cookie 信息，然后通过ajax发送到自己的服务器去。构造好代码后你把链接发给其他的朋友，或者网站的管理员，他们打开 JavaScript 代码就执行了，你服务器就接收到了sessionid，你就可以拿到他的用户权限了。  dom型 XSS 是因为 JavaScript 执行了dom 操作，所造成的 XSS 漏洞，具体如下图。可以看到虽然经过 html 转义了，但是这块代码在返回到 html 中，又被 JavaScript 作为 dom 元素操作。那当我输入?name=＜img src=\"1\" onerror=\"alert(1)\"/＞ 的时候依然会存在 XSS 漏洞。    xss 漏洞挖掘方法  根据上面的一些特点，可以总结出几个分析出几个挖掘方法：  数据接收位置，检查 _POST、$_COOKIE是否经过转义。  常见的反射型XSS搜索这种类似位置发现次数较多。  而存储型在文章，评论出现比较多。  XSS 漏洞防范方法  转义html实体，有两种方式：在入口和出口,我建议是在入口处转义，防止出口位置取出来的时候忘记转义，如果已经在入口转义了，出口位置就不用再次转义。  在富文本编辑器中，经常会用到一些元素的属性，比如上图的onerror，那我们还需对元素的属性建立黑白名单。  httpOnly 即使存在xss漏洞，可以把危害大大降低。  CSRF漏洞  CSRF 漏洞介绍  CSRF（Cross-site request forgery）跨站请求伪造，通常缩写为CSRF或者XSRF，是一种对网站的恶意利用。听起来像跨站脚本（XSS），但它与XSS非常不同，XSS利用站点内的信任用户。  而 CSRF 则通过伪装来自受信任用户的请求来利用受信任的网站。与 XSS 攻击相比，CSRF 攻击往往不大流行（因此对其进行防范的资源也相当稀少）和难以防范，所以被认为比XSS更具危险性。  csrf 主要用来做越权操作，而且 csrf 一直没有被关注起来，所以很多程序现在也没有相关的防范措施。  CSRF 案例  我们来看下面的一段代码,这个表单当被访问到的时候，用户就退出了登录。假设有一个转账的表单，只需要填写对方的用户名，和金额就可以，那如果我提前把 URL 构造好，发给受害者，当点击后，钱就被转走了。  或者我把这个 URL 放到我的网页中，通过<img src=\"我构造的URL\" ，当其他人打开我的网址后，就中招了。  CSRF漏洞挖掘方法  通过上面的描述，我们知道了漏洞的原有，那我们审计的时候可以检查处理表单有没有以下判断。  是否有验证 token。  是否有图片验证码。  是否有 refe 信息。  如果三个判断都没有，那么就存在了 CSRF 漏洞，CSRF 不仅限于 GET 请求， POST 请求同样存在。  CSRF 漏洞防范方法  图片验证码，这个想必大家都知道，但是用户体验并不好，我们可以看下面的一些处理方法。  token验证。  token验证方法如下，每次访问表单页的时候，生成一个不可预测的token存放在服务器session中，另外一份放页面中，提交表单的时候需要把这个token带过去，接收表单的时候先验证一下token是否合法。  Refeer信息验证  大多数情况下，浏览器访问一个地址，其中header头里面会包含Referer信息,里面存储了请求是从哪里发起的。  如果HTTP头里包含有Referer的时候，我们可以区分请求是同域下还是跨站发起的，所以我们也可以通过判断有问题的请求是否是同域下发起的来防御 CSRF 攻击。  Referer 验证的时候有几点需要注意，如果判断Referer是否包含 *.XXX.com,如果有子域名有漏洞，会存在绕过的可能。  如果判断的条件的是Referer中是否包含字符 ‘xxx.com’  那攻击者在他目录中建立一个 xxx.com 文件夹同样存在绕过的可能。如果可以最合适的判断是，直接判断是否等于当前域名。    三、常规漏洞的防范方法    taint PHP 安全扩展    功能介绍  Taint 可以用来检测隐藏的 XSS code, SQL 注入， Shell注入等漏洞，并且这些漏洞如果要用静态分析工具去排查， 将会非常困难， 我们来看下面这张图:  安装方法  下载 taint：  http://pecl.php.net/package/taint  配置  /usr/local/php/bin/phpize  ./configure --with-php-config=/usr/local/php/bin/php-config  make && make install  更加详细的可以参考：http://www.cnblogs.com/linzhenjie/p/5485474.html  应用场景  开发团队要求每个人都做到非常的安全比较难，但是把taint安装在开发环境，特别适合，一看到 warning 信息一般都回去改。  ngx_lua_waf  功能介绍  防止 sql 注入，本地包含，部分溢出，fuzzing 测试，xss，SSRF 等 web攻击。  防止 svn /备份之类文件泄漏。  防止 ApacheBench 之类压力测试工具的攻击。  屏蔽常见的扫描黑客工具，扫描器。  屏蔽异常的网络请求。  屏蔽图片附件类目录 php 执行权限。  防止 webshell 上传。  安装方法  安装依赖: luajit 、ngx_devel_kit、nginx_lua_module  安装nginx、ngx_lua_waf  在nginx.conf里的 http 添加配置  详细安装文档'),
(17, 3, '如何成为一个优秀的工程师？“看到问题也不要去问别人，就把它Fix。”！', 'qz', 1526472244794, 20, 1, 0, '有赞使用storm已经有将近3年时间，稳定支撑着实时统计、数据同步、对账、监控、风控等业务。订单实时统计是其中一个典型的业务，对数据准确性、性能等方面都有较高要求，也是上线时间最久的一个实时计算应用。通过订单实时统计，描述使用storm时，遇到的准确性、性能、可靠性等方面的问题。    订单实时统计的演进  第一版：流程走通  在使用storm之前，显示实时统计数据一般有两种方案：    在数据库里执行count、sum等聚合查询，是简单快速的实现方案，但容易出现慢查询。  在业务代码里对统计指标做累加，可以满足指标的快速查询，但统计逻辑耦合到业务代码，维护不方便，而且错误数据定位和修正不方便。  既要解耦业务和统计，也要满足指标快速查询，基于storm的实时计算方案可以满足这两点需求。    一个storm应用的基本结构有三部分：数据源、storm应用、结果集。storm应用从数据源读取数据，经过计算后，把结果持久化或发送消息给其他应用。        第一版的订单实时统计结构如下图。在数据源方面，最早尝试在业务代码里打日志的方式，但总有业务分支无法覆盖，采集的数据不全。我们的业务数据库是mysql，随后尝试基于mysql binlog的数据源，采用了阿里开源的canal，可以做到完整的收集业务数据变更。    在结果数据的处理上，我们把统计结果持久化到了mysql，并通过另一个后台应用的RESTful API对外提供服务，一个mysql就可以满足数据的读写需求。        为了提升实时统计应用吞吐量，需要提升消息的并发度。spout里设置了消息缓冲区，只要消息缓冲区不满，就会源源不断从消息源canal拉取数据，并把分发到多个bolt处理。    第二版：性能提升  第一版的性能瓶颈在统计结果持久化上。为了确保数据的准确性，把所有的统计指标持久化放在一个数据库事务里。一笔订单状态更新后，会在一个事务里有两类操作：    订单的历史状态也在数据库里存着，要与历史状态对比决定统计逻辑，并把最新的状态持久化。storm的应用本身是无状态的，需要使用存储设备记录状态信息  当大家知道实时计算好用后，各产品都希望有实时数据，统计逻辑越来越复杂。店铺、商品、用户等多个指标的写操作都是在一个事务里commit，这一简单粗暴的方式早期很好满足的统计需求，但是对于update操作持有锁时间过长，严重影响了并发能力。  为此做了数据库事务的瘦身：    去除历史状态的mysql持久化，而是通过单条binlog消息的前后状态对比，决定统计逻辑，这样就做到了统计逻辑上的无状态。但又产生了新问题，如何保证消息有且只有处理一次，为此引入了一个redis用于保存最近24小时内已成功处理的消息binlog偏移量，而storm的消息分发机制又可以保证相同消息总是能分配到一个bolt，避免线程安全问题。  统计业务拆分，先是线上业务和公司内部业务分离，随后又把线上业务按不同产品拆分。这个不仅仅是bolt级别的拆分，而是在spout就完全分开  随着统计应用拆分，在canal和storm应用之间加上消息队列。canal不支持多消费者，而实时统计业务也不用关系数据库底层迁移、主从切换等维护工作，加上消息队列能把底层数据的维护和性能优化交给更专业的团队来做。  热点数据在mysql里做了分桶。比如，通常一个店铺天级别的统计指标在mysql里是一行数据。如果这个店铺有突发的大量订单，会出现多个bolt同时去update这行数据，出现数据热点，mysql里该行数据的锁竞争异常激烈。我们把这样的热点数据做了分桶，实验证明在特定场景下可以有一个数量级吞吐量提升。  最终，第二版的订单实时统计结构如下，主要变化在于引入了MQ，并使用redis作为消息状态的存储。而且由最初的一个应用，被拆成了多个应用。        第三版：准确性提升  经过第二版的优化，实时统计的吞吐量已经不成问题，但还是遇到了做大数据最重要的准确性的问题：    统计口径是会变化的，同样是GMV，一年前和现在的算法可能有变化。例如一笔货到付款订单，是买家下单算成交，还是卖家发货成交，在不同的时期可能使用不同的算法。  实时统计只能按照当时的算法来做计算。有可能出现一段时间周期内的GMV，前一段是按旧算法来计算，后一段按新算法来计算，提供的数据就不准确了。  实时统计难免会出现bug，有不准确的结果，修复错误数据是个难题。  为了解决这个问题，凡是涉及到两天以前数据的，一律由离线计算提供，最终展示给用户的数据，就是历史离线统计数据，并上今日昨日实时统计数据。为什么是今日昨日实时统计呢？因为离线统计有数据准备、建模、统计的过程，要花费几个小时，每天的凌晨很可能还得不到前一天的离线统计结果。    一旦统计口径有变化，只需要重跑离线统计任务就可修复历史数据，做到了冷热数据分离。        实时计算的常见问题  通过订单实时统计的案例，可以抽象出一些基于storm实时计算的共性问题。    消息状态管理  storm不提供消息状态管理，而且为了达到水平扩展，最好是消息之间无状态。对于大数据量、低精度的应用，需要做到无状态。而像订单实时统计这样数据量不算太大，但精度要求极高的场景，需要记录消息处理状态。而为了应付重启、分布式扩展的场景，往往需要额外的介质来存储状态。状态信息往往是kv形式的读写，我们在实际的应用中，使用过redis、HBase作为存储。    消息不丢失、不重复、不乱序  对于准确性要求高的场景，需要保证数据正确的只消费一次。storm的有三种消息处理模式：    at most once，若不实现ack和fail方法，无论后续处理结果如何，消息只会发送一次，必定不能满足高准确性；  at least once，若实现了ack和fail方法，只有调用了ack方法才会任务处理成功，否则会重试。可能会出现消息重复，在并发场景下重复又意味着可能出现乱序；  exactly once，trident每个micro batch作为整体只成功处理一次，但也是无法保证消息真的只正确的处理一次，比如数据已经处理完毕并持久化，但向数据源ack时失败，就可能会有重试。  对于消息重复、乱序的场景，不是简单的消息幂等能解决，有以下的处理思路：    使用前面提到的状态管理的办法，识别出重复、乱序的数据；  业务逻辑中，兼容重复、乱序数据，比如维护一个业务状态机，把异常数据剔除。  对于时序判断，尽量不用使用时间戳，因为在分布式系统里，各服务器时间不一致是很常见的问题。    我们会尝试在运行过程中重启消息源、storm应用、存储/MQ等下游系统，或者制造网络丢包、延迟等异常，手工触发可能的消息丢失、重复、乱序场景，来验证我们的应用能否对应这些异常情况。    复杂拓扑  在storm的文档里，有很多类似下图的复杂应用。        对于需要消息可靠处理的场景，是不适合这样复杂拓扑的，部分失败如何回滚，是否要全部bolt处理完毕才ack，是需要面对的问题。过长的拓扑链路，里面的慢速逻辑会拖慢整体性能。    可以考虑使用更简化的拓扑，不同的逻辑之间尽量解耦，需要使用bolt的结果时，可以把数据持久化或者推送到MQ。        监控  生产环境少不了监控，除了服务器的基础监控，还加了不少storm特有的监控：    消息延迟：消息在业务系统的时间戳与storm应用的当前时间戳对比，大于一定阈值则告警，不同应用的阈值会不同；  消息处理时长、fail数：这两个都可以由storm的接口获取，数值偏大很可能是出了问题；  应用TPS：记录应用的emit、ack、fail数的变化趋势，帮助分析应用的运行情况；  任务级监控：每台服务器的worker、executor数量，这也可以通过storm接口获取。  除此之外，会有各类应用特有的监控，一般都是离线计算的结果与实时计算结果对比。对于数据同步类的应用，数据量比较大，可能会使用采样的方式做校验。'),
(18, 3, '精选！15 个必备的 VSCode 插件（前端类）', 'qz', 1526472244794, 20, 1, 0, '伴随着公司的推送，在2017年7月12日，我迎来了在美团点评的第一年。  在公司的第一年，遇到了一些困难，学习到了很多知识，得到了很多人的帮助。  文字是有生命力的，总结一下自己过去的正式工作的第一年，给自己，也给需要的人。    我的第一年    毕业在即，逃不开的话题就是校园招聘，在校园招聘中斩获了多少，能够让你拥有更多的选择的权利。  我的第一年回顾的第一个主题就是。  校招厮杀        我本身是一个航海院校计算机相关专业的学生，在近几年，某些计算机的专业被提拔到了一本的级别，但在综合的实力上还是和一些老牌院校的计算机专业有着不小的差距，很大程度上，我们是计算机校招队伍中的弱势群体。    在本科阶段，我没有意识到这一点，虽然说也没有浪费本科的时光，但读研和工作后才发现，自己错过了很多储备知识的好时光以及关键的找工作的时间节点。    好在成绩还算可以，顺利保研。在大四的暑假，告诉自己，毕业的时候一定要去一线互联网大厂做后端工程师，当时锁定的主要语言是Java方向的。(确定目标)    确定了目标后，开始了解几个互联网主流厂商的后端Java工程师岗位的一些JD，主要关注了美团点评、阿里、爱奇艺等公司，了解到他们对于应届生大多有以下几点要求。(了解岗位需求)  基础计算机知识扎实  和目标岗位匹配的若干优质实习和项目  一定的技术视野  根据以上几点要求，我在研一阶段就主要做了三件事情。 复习基础知识，找实习，拓宽技术视野。(根据岗位需求定向准备)  基础知识方面，通过搜索引擎和一些问答社区，向前辈取经，把Java相关的基础书籍以及本科的一些当时觉得听着很枯燥的课比如计算机网络、操作系统、数据结构又复习了一遍，通过做题，看视频等手段。见我的知乎提问:    实习方面，在边复习基础知识的时候，我同时也着手开始找Java后端工程师方面的实习。先后在创业公司和阿里实习过，在这个过程中经历了简历准备、求职资源获取、技术面试等，以下文章记录了当中的一些体会。    校招技术岗位，简历挂，内推挂，只因为你做错了....    想去阿里实习其实很简单，只要你....    拓宽技术视野，平时的时候逛一些技术论坛，了解主流互联网公司的架构，Java后端技术方面的最新进展等。    站在巨人的肩膀上，这一点是我自己加的，就是在准备校招的过程中，可以去看一些过来人的面试经验，和一些网友交流面试的体会，过去人家踩过的坑，我尽量不睬。    后面的故事就是，校招拿到了好几个Offer，最终因为个人的喜好和综合因素来到了大众点评。          我的第一年回顾的第二个主题是  初入职场的适应期      我校招刚加入的一个团队是闪惠，是做大众点评商户的优惠买单业务的一个团队。业务量在整个公司来说也是很大的，我加入的时候业务正趋于稳定。不过刚进去的那段时间，还是挺自我否定的。    需求会议听不懂。我们是走迭代的，一般两周一个迭代，每一次开始前，产品经理会召开需求会议，讲一下之后要做哪些东西， 涉及到哪些业务。在刚开始的需求会议上，我遇到了需求听不懂、分配到任务没办法很好的拆解到哪些模块，每次都是靠会后去问导师，才具体明白一个看似简单的需求到底是需要做什么工作，看着组长写的wiki，对每一个迭代要做的东西，需要涉及哪些系统、每一个需求可能需要多少人力，都预估的很清楚，我对自己是有点否定的。因为觉得在自己之前实习的时候，功能完成的也很好呀，怎么正式入职，连需求都听不懂，需求拆解都做不好呢。    技术知识出现不足。因为业务量比较大，线上一些小问题都会被无限的放大，某一天线上突然出现某一个后台项目的所有机器的老年代增长都较快，同事排查后定位是接入的外部包有问题，然后写下了一篇故障分析报告，如何从源码的角度定位了问题，我看了几遍才看懂。    代码被吐槽。我们一般都会有Code Review，会请高级别的工程师过来帮你看你的代码，看是否能够提交上去，在我刚开始写的代码，因为一些不好的习惯和对业务思考的不够，出现了类如NPE、代码复用不够、代码层次不清晰以及命名不太合理等问题，也是经常被打回去修改。    刚进去的这段时间还挺郁闷，觉得哪哪都做不好，有些自我否定。    后来和导师以及领导聊，结合我现在的一些理解的话，我想对当时的自己说:  Relax，公司其实并不期望刚刚进来的你，能够创造多少价值。新人是要成长的，在成长期难免会遇到各种各样的小问题，这可能是大多数人的必经之路，因为你所看到的同事，他们都比你在工作领域待的时间更久，有更多的经验，可以把他们作为目标，但不要把他们作为现在自己的标准，那样会压力太大。  从学校到职场切换的前几个月，难免是不适应的，但在这几个月中，我是通过做到以下几点，帮助自己完成适应。  翻阅团队过往的资料和代码，了解团队的业务现状、核心系统以及主流程，从大方向上入手，再进一步了解业务中的细节。  请教导师和身边的同事，身边的同事是最好的学习资源，他们可以告诉从更高的层面看你现在所处的位置以及遇到的问题，勇于请教，多交流。  多多总结回顾，每周都回顾下自己做了什么，学到了什么。        我的第一年回顾的第三个主题是  不同类型团队下的成长      从刚开始的自我否定中走出来，慢慢融入团队后，会迎来一个成长期。    成熟业务  我刚进来时，团队在做的是一个流量很大的业务，系统架构已经趋向于成熟，作为一个新人，更多的是在修修补补，针对子系统中的某一个模块进行一些开发，很少有机会从头开始做一个项目。在一个成熟的团队，有以下的优点和缺点。    优点: 经过长时间的大流量的业务考证的系统架构和业务设计，能从中收获很多养分，让你之后站在一个更高的视角去看待问题。其二是因为成熟业务流量一般都有一定的量级了，成立至今可能遇到了很多千奇百怪的线上问题，在排查这些问题的过程中，技术能力和沟通能力能得到很大的锻炼。  缺点: 相对的缺点就是，难以参加一个项目完整的开发过程，因为业务架构已经基本定型，新人在这里大多是针对系统具体的子模块进行一些功能上的开发。    创新业务  在我的第一年的后半段，随着团队业务的切换，去做了一个从0到1的业务，主要是依托我们公司积累的数据，为商家提供咨询和数据的一个平台。  优点: 在一个新业务中，有机会从头到尾去设计一个项目，定义和外部系统的交互接口，底层的数据存储设计，系统内部的流程等等。在这个新业务中，我参加了App站内信、用户中心、后台推送中心的完整开发过程，从之前的简单的和后端同事之间的对接，到需要跨团队和客户端、前端、测试打交道，在个人的沟通技巧上得到了很大的成长。在这个从0-1的过程中，对于如何亲手设计一个系统有了经验，同时可以借鉴过去在成熟业务当中学习到的一些准则。如果在一个业务快速发展的新业务中，随着新业务的不断演进，原有的架构会不断得到挑战，进一步提升自己系统设计的功底。  缺点: 并不是每一个新业务都会快速增长，让你不断的遇到新的挑战。在业务的缓慢成长中，可能只是在重复过去学到的技能，得不到足够的挑战，也就错失了进一步成长的空间。    成熟业务和创新业务都有自己的可取之处，不管身处哪个业务，都要像海绵一样汲取其中能够被吸收的营养。        我的第一年回顾的第四个主题是    积极尝试      在我的第一年，还做到了勇于尝试。  在切换到新业务后，前端和数据开发的资源相对比较紧张。  一半是领导的安排，一半是自己觉得我其实是一名软件工程师，目前的职位虽然是后端工程师，但不代表要把自己局限在后端，需要用技术的手段解决问题的，都可以有我的出现。  在业务的演进过程中，我接触了前端的开发，做了一会会全栈工程师，虽然是很简单的页面开发，配上自己的后端接口哈哈。还接触了数据开发，从完全不知道数据开发应该干什么，到对集团数据平台的使用驾轻就熟，从底层数据的提供到后端接口的开发一条龙服务，不仅复习了之前学过的Hive，还学了新技能ElasticSearch，同时把在接触新东西的过程中遇到的问题，总结了下来，帮助别人一起成长。    不局限自己，职业生涯的早期可以多多尝试，软件工程师是解决问题的，至于前面的Title只是说你更擅长哪个方面，当需要你的时候，其实你都可以勇于尝试。    总结    总的来说，我对我过去正式的工作一年还算满意吧。如果让我现在对过去刚入职的自己送上几句建议的话，那么应该是以下四句。  积极提问  保持谦逊  多总结多思考  心态要稳  我的第一年回顾完了，希望我的第二年可以越来越好。你的第一年怎么样呢，如果你也想讲讲你的故事，欢迎投稿~'),
(19, 3, 'Zdal分库分表：支付宝是如何在分布式环境下完爆数据库压力的？', 'qz', 1526472244794, 20, 0, 0, '大部分时候，微服务都是建立在一种基于请求和响应的协议之上。比如，REST等。这种方式是自然的。我们只需要调用另外一个模块就是了，然后等待响应返回，然后继续。这样的方式确实也满足了我们的很多的场景：用户通过点击页面的一个按钮然后希望发生一些事情。    但是，当我们开始接触许多独立的service的时候，事情就发生改变了。随着service数量急速的增长，同步交互比例也随着service在急速增长。这时候，我们的service就会遇到很多的瓶颈。  于是，不幸的ops工程师们就被我们坑了，他们疲惫的奔波于一个又一个的service，拼凑在一起的二手信息片段，谁说了什么，去往哪里，什么时候发生？等等。。。  这是一个非常典型的问题。市面上也有一些解决方案。一种方案就是确保您的个人服务具有比您的系统更高的SLA。 Google提供了这样做的协议。另一种方法是简单地分解将服务绑定在一起的同步关系。    上面的做法都没有从模式上根本解决问题。我们可以使用异步机制来解决这个问题。比如，电商网站中你会发现这样的同步接口，比如getImage()或者processOrder()，也许你感觉蛮正常。调用了然后希望马上有一个响应。但当用户点击了“购买”后，触发了一个复杂且异步的处理过程。这个过程涉及到购买、送货上门给用户，这一切都是发生在当初的那一次的按钮点击。所以把一个程序处理逻辑切分成多个异步的处理，是我们需要解决的问题。这也正符合我们的真实的世界，真实世界本来就是异步的，拥抱异步吧。    在实际情况下，我们其实已经自动拥抱了异步了。我们发现自己会定时轮询数据库表来更改又或者通过cron定时job来实现一些更新。这些方法都是一些打破同步的方式，但是这种做法总让人感觉有种黑客范儿，感觉像是黑客行为，怪怪的。    在本文中，我们将会讨论一种完全不同的架构：不是把service们通过命令链揉到一块，而是通过事件流（stream of events）来做。这是一个不错的方式。这种方式也是我们之后要讨论的一系列的一个基础。    当我们进入正式的例子之前，我们需要先普及三个简单的概念。一个service与另外一个service有三种交互方式：命令（Commands）、事件（Events）以及查询（Queries）。    事件的美妙之处在于“外部数据”可以被系统中的任何service所重用。    而且从service的角度来说，事件要比命令和查询都要解耦。这个很重要。    服务之间的交互有三种机制：    Commands 。命令是一个操作。希望在另一个服务中执行某些操作的一个请求。 会改变系统状态的东西。 命令期待有响应。  Events 。事件既是一个事实也是一个触发器。 发生了一些事情，表示为通知。  Queries 。查询是一个请求，是一个查找一些东西的请求（request）。重要的是，查询不会使得系统状态发生改变。    一个简单事件驱动流程    让我们开始一个简单的例子：用户购买一个小东西。那么接下来要发生两件事情：    支付。  系统检查是否还有更多的商品需要被订购。  在请求驱动（request-approach）的架构中，这两个行为被表现为一个命令链条。交互就像下面这样：    首先要注意的问题是“购买更多”的这个业务流程是随着订单服务（Order Service）一块被初始化的。这就使得责任不独立，责任跨了两个service。理想情况下，我们希望separation of concerns，也就是关注隔离。    现在如果我们使用事件驱动，而不是请求驱动的方式的话，那么事情就会变得好一些。    在返回给用户之前，UI service 发布一个OrderRequested事件，然后等待OrderConfirmed（或者Rejected）。  订单服务（Orders Service）和库存服务（Stock Service） react这个事件。    仔细看这里，UI service和Orders Service并没有改变很多，而是通过事件来通信，而不是直接调用另一个。    这个Stock service（库存服务）很有趣。Order Service告诉他要做什么。然后StockService自己决定是否参与本次交互，这是事件驱动架构非常重要的属性，也就是：Reciver Driven Flow Control，接收者驱动流程控制。一下子控制反转了。    这种控制反转给接收者，很好的解耦了服务之间的交互，这就为架构提供了可插拔性。组件们可以轻松的被插入和替换掉，优雅！    随着架构变得越来越复杂，这种可插拔性的因素变得更加重要。举个例子，我们要添加一个实时管理定价的service，根据供需调整产品的价格。在一个命令驱动的世界里，我们就需要引入一个可以由库存服务（Stock Service）和订单服务（Orders Service）调用的类似updatePrice()这样的方法。    但是在事件驱动（event-driven）世界更新价格的话，service只需要订阅共享的stream就是了，当相应的条件符合时，就去执行更新价格的操作。    事件（Events）和查询（Queries）的混合    上面的例子只是命令和事件。并没有说到查询。别忘了，我们之前可是说到了三个概念。现在我们开始说查询。我们扩展上面的例子，让订单服务（Orders Service）在支付之前检查是否有足够的库存。    在请求驱动（request-driven）的架构中，我们可能会向库存服务（Stock Service）发送一个查询请求然后获取到当前的库存数量。这就导致了模型混合，事件流纯粹被用作通知，允许任何的service加入flow，但查询却是通过请求驱动的方式直接访问源。    对于服务（service）需要独立发展的较大的生态系统，远程查询要涉及到很多关联，耦合很严重，要把很多服务捆绑在一起。我们可以通过“内部化”来避免这种涉及多个上下文交叉的查询。而事件流可以被用于在每个service中缓存数据集，这样我们就可以在本地来完成查询。    所以，增加这个库存检查，订单服务（Order Service）可以订阅库存服务（Stock Service）的事件流，库存一有更新，订单服务就会收到通知，然后把更新存储到本地的数据库。这样接下来就可以查询本地这个“视图（view）”来检查是否有足够的库存。    纯事件驱动系统没有远程查询的概念 - 事件将状态传播到本地查询的服务    通过事件来传播（ “Queryby Event Propagation”）的查询有以下三个好处：    1、更好的解耦：在本地查询。这样就不涉及跨上下文调用了。这种做法涉及到的服务们远远不及那种”请求驱动”所涉及到的服务数量多。  2、更好的自治：订单服务（Order Service）拥有一份库存数据集的copy，所以订单服务可以任意使用这个本地的数据集，  而不是说像请求驱动里的那样仅仅只能检查库存限额，而且只能通过Stock Service所提供的接口。  3、高效Join：如果我们在每次下订单的时候都要去查询库存，就要求每次都要高效的做join，通过跨网络对两个service进行join。随着需求的增加，或者更多的数据源需要关联，这可能会变得越来越艰巨。所以通过事件传播来查询（Query by Event Propagation）将查询（和join）本地化后就可以解决这个问题（就是本地查询）。    但这种做法也不是没有缺点。 Service从本质上变得有状态了。这样就使得他们需要被跟踪和矫正这些数据集，随着时间的推移，也就是你得保证数据同步。状态的重复也可能使一些问题更难理解（比如如何原子地减少库存数量？），这些问题我们都要小心。但是，所有这些问题都有可行的解决方案，我们只是需要多一点考虑而已。     单一写入者原则（Single Writer Principle）    针对这种风格的系统，也就是事件驱动风格的系统，一个非常有用的原则就是针对指定类型的传播的事件分配责任的时候，应该只分配给一个单一的service：单一的写入者。什么意思呢？就是Stock Service只应该处理库存这一件事情，而Order Service也只属于订单们，等等。    这样的话有助于我们通过单个代码路径（尽管不一定是单个进程）来排除一致性，验证和其他“写入路径（writepath）”问题。因此，在下面的示例中，请注意，订单服务（Order Service）控制着对订单进行的每个状态的更改，但整个事件流跨越了订单（Orders），付款（Payments）和发货（Shipments），每个都由它们各自的服务来管理。    分配“事件传播”（event propagation）的责任很重要，因为这些不仅仅是短暂的事件，或者是那种无须保存短暂的聊天。他们代表了共同的事实（facts），以及“数据在外部（data-on-the-outside）“。因此，随着时间的推移，服务（services）需要去负责更新和同步这些共享数据集（shared datasets）：比如，修复错误，处理schema的变化等情况。    上图中每个颜色代表Kafka的一个topic，针对下订单（Order）、发货和付款。  当用户点击“购买”时，会引发“Order Requested”，等待“Order Confirmed”事件，然后再回复给用户。 另外三个服务处理与其工作流程部分相关的状态转换。 例如，付款处理完成后，订单服务（Order Service）将订单从“已验证（Validated）”推送到“已确认（Confirmed）”。    模式（Patterns）和集群服务（Clustering Services）的混合    上面的说到的模型有点像企业消息（Enterprise Messaging），但其实是有一些不同的。企业消息，在实践中，主要关注状态的转换，通过网络有效地将数据库捆绑在一起。    而事件协作（Event Collaboration）则更偏重的是协作，既然是协作就不简单的是状态转换，事件协作是关于服务（service）通过一系列事件进行一些业务目标，这些事件将触发service的执行。所以这是业务处理（business processing）的一种模式，而不是简单的转换状态的机制。    我们通常希望在我们构建的系统中这种模式具有两面性。事实上，这种模式的美妙之处在于它确实既可以处理微观又可以处理宏观，或者在有些情况下可以被混合。    模式组合使用也很常见。我们可能希望提供远程查询的方便灵活性，而不是本地维护数据集的成本，特别是数据集增长时。这样的话就会让我们的查询变得更加的简单，我们只需要轻松部署简单的函数就可以了。而且我们现在很多都是无状态的，比如容器或者浏览器，在这种情况下也许远程查询是一种合适的选择。    远程查询设计的诀窍就是限制这些查询接口的范围，理想情况下应该是在有限的上下文中（context）。通常情况下，建立一个具有多个特定，具体视图的架构，而不是单一的共享数据存储。注意是多个具体的视图，而不是单一的共享数据存储。（一个独立（bounded）的上下文，或者说是偏向原子，这里说的原子不是侧重微服务中常说的那个“原子服务”。独立上下文，一般是指有那么一组service，它们共享同一个发布流水线或者是同一个领域模型【domain model】）。    为了限制远程查询（remote queries）的边界（scope），我们可以使用一种叫做“集群式上下文模式（clustered context pattern）”。这种情况下，事件就流纯粹是用作上下文之间的通信。但在一个上下文里的具体service们则可以既有事件驱动（event-driven）的处理，同时也有请求驱动（request-driven）的视图（view），具体根据实际情况需要。    在下面的例子中，我们有三个部分，三个之间只通过事件相互沟通。在每一个内部，我们使用了更细粒度的事件驱动流。其中一些包括视图层（查询层）。    还是看下图吧：    集群上下文模型（Clustered Context Model）    事件驱动（event-driven）五个关键好处：   解耦：把一个很长的同步执行链的命令给分解，异步化。 分解同步工作流。 Brokers 或topic解耦服务（service），所以更容易插入新的服务（service），具有更强的插拔性。  离线/异步流：当用户点击按钮时，很多事情都会发生。 一些同步，一些异步。 对能力的设计，无论是以前的，还是将来的，都是更自由的。提高了性能，提高了自由度。  状态同步更新：事件流对分布式数据集提供了一种有效的机制，数据集可以在一个有界的上下文里被重构（“传播”或“更新”）和查询。   Joins：从不同的服务（service）组合/join/扩展数据集更容易。 join更快速，而且还是本地化的。  可追溯性: 当有一个统一化的，中心化的，不可变的，保持性的地方来记录每个互动时，它会及时展现，debug的时候也更容易定位问题，而不是陷入一场关于“分布式”的谋杀。（这里有点晦涩）  总结    Ok，在事件驱动的方法中我们使用事件（Events）而不是命令（Commands）。事件触发业务处理过程。事件也可以用到更新本地视图上。然后我们向你介绍了，在必要时，我们可以再回到远程同步查询这种方式，特别是在较小的系统中，而且我们还将远程同步查询的范围扩大到更大的范围（理想情况下，还是要仅限于单个独立的上下文，也就是单个领域模型，不能再扩大了，刚刚好才是真的好）。    而且所有这些方法都只是模式（pattern）。模式就会有框得太死的问题。模式覆盖不到的地方，我们就要具体情况具体对待了。例如，单点登录服务，全局查询的service仍然是一个好主意，因为它很少更新。    这里的秘诀就是从事件的基准出发去考虑问题。事件让服务之间不再耦合，并且将控制（flow-control）权转移到接收者，这就有了更好的“分离关注（separated concerns）”和更好的可插拔性。    关于事件驱动方法的另一个有趣的事情是，它们对于大型，复杂的架构同样适用，就像它们对于小型，高度协作的架构一样。事件让service们可以自主的决定自己的所有事情，为服务们提供自由发展所需的自主权。    然后我们向你介绍了事件和查询混合的场景。说到查询，在纯事件驱动方法中，查询完全基于本地的数据集，而没有远程查询。本地数据集则是通过事件触发来更新状态。然而，很多时候，基于请求驱动的查询方式在很多时候也是比较方便的，因为本地数据集的方式，状态的同步更新确实是一件更加需要成本的事情。    然后我们说到了单一写入z者原则。单一写入者让我们数据更新有了统一的入口，有助于我们通过单个代码路径（尽管不一定是单个进程）来排除一致性，验证和其他“写入路径（writepath）”问题。    然后我们讨论了集群上下文模型。每个领域模型组成一个独立的区域，然后再由多个区域共同组成一个领域模型集群，模型之间又通过Kafka来交互。每个领域模型里又可以包含几种模式的混合，比如Events、Views、UI，这些里边可以既有事件驱动模式，又有请求驱动模式。    大体就这么多。    感谢Antony Stubbs，Tim Berglund，Kaufman Ng，GwenShapira和Jay Kreps，他们帮助我们回顾了这篇文章。    译者曰：最近也恰好在做有关事件流的内容，对本文中讲到的异步解耦和拆解同步请求链条过长问题深有感触，也非常认同。另外最近有人聊到有关数据库查询效率问题，通过阅读本文也许会让你对查询有一个全新的认识。这些微服务理念看起来好像专属于“微服务”，好像其他人就不需要了解一样。其实也许微服务的这些先进理念就像其他任何的先进的架构理念一样，他们都是我们软件架构知识体系的储备之一，也许在哪天你正在进行的项目遇到了瓶颈，没准本文讨论的这些内容就能派上用场了，不仅仅限于本文举的那个例子。    微服务\"交互方式\"观念转变：     是时候更新一下你对于构建微服务的一些知识体系了。如果你认为REST就是微服务构建的主要交互方式的话，那么也许你错了；如果你认为rpc就是构建微服务的的主要交互方式的话，那么也许你又错了。    因为这两种都属于一种类型，那就是他们都属于请求驱动（request-driven）模式，而这种模式很多时候是同步的，一条链上挂了很多的服务调用，势必在链条变长后，性能堪忧。    本文向你推荐了一个构建微服务的新的工具，或者说是向你补充了。那就是事件驱动（event-driven）的模式。它解耦、异步，带来了更好的扩展性和性能。很多时候，同步会让事情变得异常糟糕！    如果以后有人和讨论起微服务的模式的时候，你可以说REST、rpc（请求驱动）以及事件驱动共同混合使用才会构建出更好的微服务来！    ps：文中部分段落翻译用词略显晦涩，我曾尝试用大白话来翻译，但发现会损失原意，故请仔细斟酌消化。'),
(20, 3, 'ECMAScript 8都发布了，你还没有用上ECMAScript 6？', 'qz', 1526472244794, 20, 0, 0, '一位工程师，如何才能称得上优秀？除了写得一手好Code，什么样的工作态度和方法才是一个优秀工程师的必备？  7月11日，陆奇出席百度内部Engineering Leadership Talk。作为计算机科学博士及优秀的管理者，他提出的五点要求，对每一位百度工程师都适用。  “我们一定要有一个坚定不移的深刻的理念，相信整个世界终究是为技术所驱动的。”  “有没有其他人已经解决这个问题？然后你可以把你的时间放在更好的创新上。”   “做什么事情一定要做最好，一定要是做业界最强的。”  “我把自己想象是一个软件、一个代码，今天的版本一定要比昨天版本好，明天的版本肯定会比今天好。”  “看到问题也不要去问别人，就把它Fix。”  欲知是哪五点要求？请往下看  Believe in 技术     首先要相信技术，我刚才已经讲了，整个我们工业界，特别是像百度这样的公司，对技术坚定的、不动摇的信念特别重要。  我也分享一下，盖茨提到微软公司的宗旨就是：写软件代表的是世界的将来。  为什么？未来任何一个工业都会变成软件工业。盖茨是对的，因为任何工业任何行业自动化的程度会越来越高，最后你所处理的就是信息和知识。  但现在软件的做法又往前提了一次，因为在人工智能时代，不光是写代码，你必须懂算法，懂硬件，懂数据，整个人工智能的开发过程有一个很大程度的提高，但是，技术，特别是我们这个工业所代表的技术一定是将来任何工业的前沿。  站在巨人的肩膀上做创新  我们观察一下，在美国硅谷、在中国，互联网创业公司也好，大型公司也好，大家的起点是越来越高的。为什么现在创新速度那么快？主要是起点高了。我们可以使用的代码模块，使用的服务的能力，都是大大的提升。  在内部我想强调这一点，很多大公司包括微软在内，内部的Code都重做了无数遍。  我现在的要求是，每一次你写一行新的代码，第一要做的，先想一想你这行代码值得不值得写，是不是有人已经做了同样的工作，可能做得比你还好一点。有没有其他人已经解决这个问题，然后你可以把你的时间放在更好的创新上。  特别是大公司里面重复或者是几乎重复的Code实在太多，浪费太多的资源，对每个人的职业生涯都不是好事情。  我再强调，在大公司内部，你写代码之前想一想，你这行代码要不要写，是不是别人已经有了，站在别人的肩膀上去做这件事情。    追求Engineering Excellence  我要另外强调的一点就是Engineering Excellence，工程的技术的卓越性和能力。  任何市场上竞争就像打仗一样，就看你的部队体能、质量，每一个士兵他的训练的程度，和你给他使机关枪、坦克，还是什么样的武器。  所以Engineering Excellence跟这个类比，我们要建的是一支世界上最强的部队，每一个士兵，每一个领军人，每个人的能力，他的训练都是超强的，然后我们给每个人提供的工具和武器都是一流的。  所以Engineering Excellence是一个永无止境的、个人的、团队的，能力的追求和工具平台的创新，综合在一起可以给我们带来的长期的、核心的竞争力，为社会创造价值，最终的目的是给每个用户、每个企业、整个社会创造价值。  我另外还要在这里强调的一点就是Relentless pursuit of excellence：永无止境的不断的持续的追求。  我们要么不做，要做的事情一定做最好，这是我对大家的要求。数据库也好，做大平台也好，大数据也好，我们要做什么事情，我们一定要下决心，这是我对你们每个人的要求，做什么事情一定要做最好，一定要是做业界最强的。  每天学习，可能是对每个人都是最最重要的。  我今天分享一下，我自己怎么想我自己的。就很简单一个概念，我把自己想象是一个软件、一个代码，今天的版本一定要比昨天版本好，明天的版本肯定会比今天好，因为即使犯了错误，我里面有If statement，说如果见到这个错误，绝对不要再犯。  英语，另外有一句说法就是Life is too short, don’t live the same day twice. 同样一天不要重活两次。每天都是不一样，每天为什么不一样，因为每天都变成最好，每天都变得更好。今天的版本一定要比昨天好，每个好的、杰出的工程师，杰出的技术领袖，一定要保持自己学习的能力，特别是学习的范围。  在这上面我也稍微引申一下，做Computer science的，如果只学Computer science，不去学一些其他的行业，肯定不够。我举个例子，经济学必须要学。为什么这样讲？Computer science它有个很大的限制，他是假定你有输入以后有输出，这种解决问题的方式有它的好处，但有它的限制性。  我给大家举个例子，地图导航，如果你纯粹用这个方式去做，你只是把一个拥挤的地方移到另外一个拥挤的地方。经济学，它对问题的建模是不一样的。它起点是假定是一个整体的一个生态，每个人的输入都是另外一个人的输出，你要用经济学的方式来描述地图导航的问题，你就会去算一个Equilibrium，市场也是这样。  如果把深度学习真的要想彻底，必须把物理重学一遍，把生物学看一遍，再把进化论再看一遍。因为深度学习跟这些东西完全相关，自己肯定想不清楚，要彻底想清楚，必须学。  另外，学产品，我以前跟所有的工程师都讲，如果不懂产品，你不可能成为一个最好的工程师。真正要做世界一流的工程师不光要懂产品，还要懂整个商业，懂生态。因为你的工作的责任，是能够看到将来，把技术展望到将来的需求，把平台、把开发流程、把你的团队为将来做准备。所以学习是非常非常重要的。  最后是从我做起。  我们公司有个非常大的使命，用科技让复杂的世界更简单。整个世界非常非常复杂，人其实所做的事情基本上都是Reduce entropy。  因为从热力学第二定律来讲，世界是会变得越来越乱的，我们想做的事情就是把它变的更简单，让我们生活变得更美好。  而且具体的，我们可以通过人工智能技术来做到唤醒万物，但是这一切是通过每一个人的一点一滴的行为累计起来，从我做起。还有Ownership，看到机会不需要问别人，有机会就去做，看到问题也不要去问别人，就把它Fix。  把我们的使命、把我们的公司当成我们自己每个人的事业来做，我可以坦诚的给每个人讲，如果你把公司的使命，把公司的事业，当成你自己个人的事业，Own everything，你在职业生涯一定是走得最快。从我做起，从身边的每一件事情做起。  Believe in 技术、站在巨人的肩膀上做创新、追求Engineering Excellence、每天学习、Ownership，陆奇送给每一位工程师的建议，你get到了吗？');

-- --------------------------------------------------------

--
-- 表的结构 `qz_news_class`
--

CREATE TABLE `qz_news_class` (
  `tid` int(11) NOT NULL,
  `name` varchar(32) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_news_class`
--

INSERT INTO `qz_news_class` (`tid`, `name`) VALUES
(1, '公司新闻'),
(2, '新闻资讯'),
(3, '行业资讯');

-- --------------------------------------------------------

--
-- 表的结构 `qz_news_img`
--

CREATE TABLE `qz_news_img` (
  `mid` int(11) NOT NULL,
  `nid` int(11) DEFAULT NULL,
  `sm` varchar(128) DEFAULT NULL,
  `md` varchar(128) DEFAULT NULL,
  `lg` varchar(128) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_news_img`
--

INSERT INTO `qz_news_img` (`mid`, `nid`, `sm`, `md`, `lg`) VALUES
(1, 1, 'image/news/01_news_sm.jpg', 'image/news/01_news_md.jpg', ''),
(2, 2, 'image/news/02_news_sm.jpg', 'image/news/02_news_md.jpg', ''),
(3, 3, 'image/news/03_news_sm.jpg', 'image/news/03_news_md.jpg', ''),
(4, 4, 'image/news/04_news_sm.jpg', 'image/news/04_news_md.jpg', ''),
(5, 5, 'image/news/05_news_sm.jpg', 'image/news/05_news_md.jpg', ''),
(6, 6, 'image/news/06_news_sm.jpg', 'image/news/06_news_md.jpg', ''),
(7, 7, 'image/news/07_news_sm.jpg', 'image/news/07_news_md.jpg', ''),
(8, 8, 'image/news/08_news_sm.jpg', 'image/news/08_news_md.jpg', ''),
(9, 9, 'image/news/09_news_sm.jpg', 'image/news/09_news_md.jpg', ''),
(10, 10, 'image/news/10_news_sm.jpg', 'image/news/10_news_md.jpg', ''),
(11, 11, 'image/news/11_news_sm.jpg', 'image/news/11_news_md.jpg', ''),
(12, 12, 'image/news/12_news_sm.jpg', 'image/news/12_news_md.jpg', ''),
(13, 13, 'image/news/13_news_sm.jpg', 'image/news/13_news_md.jpg', ''),
(14, 14, 'image/news/14_news_sm.jpg', 'image/news/14_news_md.jpg', ''),
(15, 15, 'image/news/15_news_sm.jpg', 'image/news/15_news_md.jpg', ''),
(16, 16, 'image/news/11_news_sm.jpg', 'image/news/11_news_md.jpg', ''),
(17, 17, 'image/news/12_news_sm.jpg', 'image/news/12_news_md.jpg', ''),
(18, 18, 'image/news/13_news_sm.jpg', 'image/news/13_news_md.jpg', ''),
(19, 19, 'image/news/14_news_sm.jpg', 'image/news/14_news_md.jpg', ''),
(20, 20, 'image/news/15_news_sm.jpg', 'image/news/15_news_md.jpg', '');

-- --------------------------------------------------------

--
-- 表的结构 `qz_news_tag`
--

CREATE TABLE `qz_news_tag` (
  `iid` int(11) NOT NULL,
  `nid` int(11) DEFAULT NULL,
  `tid` int(11) DEFAULT NULL,
  `tag` varchar(64) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_news_tag`
--

INSERT INTO `qz_news_tag` (`iid`, `nid`, `tid`, `tag`) VALUES
(1, 1, 1, '微服务'),
(2, 1, 1, '请求和响应'),
(3, 1, 1, '事件流'),
(4, 2, 1, '异步机制'),
(5, 2, 1, '微服务'),
(6, 2, 1, '请求和响应'),
(7, 3, 1, '事件流'),
(8, 3, 1, '异步机制'),
(9, 3, 1, '微服务'),
(10, 4, 1, '请求和响应'),
(11, 4, 1, '事件流'),
(12, 4, 1, '异步机制'),
(13, 5, 1, '微服务'),
(14, 5, 1, '请求和响应'),
(15, 5, 1, '事件流'),
(16, 6, 1, '微服务'),
(17, 6, 1, '请求和响应'),
(18, 6, 1, '事件流'),
(19, 7, 1, '异步机制'),
(20, 7, 1, '微服务'),
(21, 7, 1, '请求和响应'),
(22, 8, 1, '事件流'),
(23, 8, 1, '异步机制'),
(24, 8, 1, '微服务'),
(25, 9, 1, '请求和响应'),
(26, 9, 1, '事件流'),
(27, 9, 1, '异步机制'),
(28, 10, 1, '微服务'),
(29, 10, 1, '请求和响应'),
(30, 10, 1, '事件流'),
(31, 11, 2, '异步机制'),
(32, 11, 2, '微服务'),
(33, 11, 2, '请求和响应'),
(34, 12, 2, '事件流'),
(35, 12, 2, '异步机制'),
(36, 12, 2, '微服务'),
(37, 13, 2, '请求和响应'),
(38, 13, 2, '事件流'),
(39, 13, 2, '异步机制'),
(40, 14, 2, '微服务'),
(41, 14, 2, '请求和响应'),
(42, 14, 2, '事件流'),
(43, 15, 2, '异步机制'),
(44, 15, 2, '微服务'),
(45, 15, 2, '请求和响应'),
(46, 16, 3, '事件流'),
(47, 16, 3, '异步机制'),
(48, 16, 3, '微服务'),
(49, 17, 3, '请求和响应'),
(50, 17, 3, '事件流'),
(51, 17, 3, '异步机制'),
(52, 18, 3, '微服务'),
(53, 18, 3, '请求和响应'),
(54, 18, 3, '事件流'),
(55, 19, 3, '异步机制'),
(56, 19, 3, '微服务'),
(57, 19, 3, '请求和响应'),
(58, 20, 3, '事件流'),
(59, 20, 3, '异步机制'),
(60, 20, 3, '微服务');

-- --------------------------------------------------------

--
-- 表的结构 `qz_product`
--

CREATE TABLE `qz_product` (
  `pid` int(11) NOT NULL,
  `tid` int(11) DEFAULT NULL,
  `title` varchar(32) DEFAULT NULL,
  `isRecommend` int(11) DEFAULT NULL,
  `updateTime` bigint(20) DEFAULT NULL,
  `click` int(11) DEFAULT NULL,
  `spec` varchar(1024) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_product`
--

INSERT INTO `qz_product` (`pid`, `tid`, `title`, `isRecommend`, `updateTime`, `click`, `spec`) VALUES
(1, 1, '手机钱包应用', 1, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(2, 1, '股市买卖应用', 1, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(3, 1, '音乐播放器', 1, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(4, 1, '桌面主题应用', 1, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(5, 1, '手机商场应用', 0, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(6, 1, '天气预报应用', 0, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(7, 2, '品牌网站建设', 1, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(8, 2, '响应式建站', 1, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(9, 2, '商城购物网站', 0, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(10, 2, '精美网页设计', 0, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(11, 3, 'UI扁平化设计', 1, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(12, 3, '名片设计', 0, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(13, 3, '画册设计', 0, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。'),
(14, 3, '形象设计', 0, 1526472244794, 10, 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代，基于云平台的企业APP在移动互联网领域迎来了发展良机。');

-- --------------------------------------------------------

--
-- 表的结构 `qz_product_detail`
--

CREATE TABLE `qz_product_detail` (
  `did` int(11) NOT NULL,
  `pid` int(11) DEFAULT NULL,
  `detail` varchar(128) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_product_detail`
--

INSERT INTO `qz_product_detail` (`did`, `pid`, `detail`) VALUES
(1, 1, 'image/product/01_pro_details.jpg'),
(2, 1, 'image/product/01_pro_details2.jpg'),
(3, 1, 'image/product/01_pro_details3.jpg'),
(4, 2, 'image/product/01_pro_details.jpg'),
(5, 2, 'image/product/01_pro_details2.jpg'),
(6, 2, 'image/product/01_pro_details3.jpg'),
(7, 3, 'image/product/01_pro_details.jpg'),
(8, 3, 'image/product/01_pro_details2.jpg'),
(9, 3, 'image/product/01_pro_details3.jpg'),
(10, 4, 'image/product/01_pro_details.jpg'),
(11, 4, 'image/product/01_pro_details2.jpg'),
(12, 4, 'image/product/01_pro_details3.jpg'),
(13, 5, 'image/product/01_pro_details.jpg'),
(14, 5, 'image/product/01_pro_details2.jpg'),
(15, 5, 'image/product/01_pro_details3.jpg'),
(16, 6, 'image/product/01_pro_details.jpg'),
(17, 6, 'image/product/01_pro_details2.jpg'),
(18, 6, 'image/product/01_pro_details3.jpg'),
(19, 7, 'image/product/01_pro_details.jpg'),
(20, 7, 'image/product/01_pro_details2.jpg'),
(21, 7, 'image/product/01_pro_details3.jpg'),
(22, 8, 'image/product/01_pro_details.jpg'),
(23, 8, 'image/product/01_pro_details2.jpg'),
(24, 8, 'image/product/01_pro_details3.jpg'),
(25, 9, 'image/product/01_pro_details.jpg'),
(26, 9, 'image/product/01_pro_details2.jpg'),
(27, 9, 'image/product/01_pro_details3.jpg'),
(28, 10, 'image/product/01_pro_details.jpg'),
(29, 10, 'image/product/01_pro_details2.jpg'),
(30, 10, 'image/product/01_pro_details3.jpg'),
(31, 11, 'image/product/01_pro_details.jpg'),
(32, 11, 'image/product/01_pro_details2.jpg'),
(33, 11, 'image/product/01_pro_details3.jpg'),
(34, 12, 'image/product/01_pro_details.jpg'),
(35, 12, 'image/product/01_pro_details2.jpg'),
(36, 12, 'image/product/01_pro_details3.jpg'),
(37, 13, 'image/product/01_pro_details.jpg'),
(38, 13, 'image/product/01_pro_details2.jpg'),
(39, 13, 'image/product/01_pro_details3.jpg'),
(40, 14, 'image/product/01_pro_details.jpg'),
(41, 14, 'image/product/01_pro_details2.jpg'),
(42, 14, 'image/product/01_pro_details3.jpg');

-- --------------------------------------------------------

--
-- 表的结构 `qz_product_img`
--

CREATE TABLE `qz_product_img` (
  `mid` int(11) NOT NULL,
  `pid` int(11) DEFAULT NULL,
  `hpic` varchar(128) DEFAULT NULL,
  `sm` varchar(128) DEFAULT NULL,
  `lg` varchar(128) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_product_img`
--

INSERT INTO `qz_product_img` (`mid`, `pid`, `hpic`, `sm`, `lg`) VALUES
(1, 1, 'image/product/01_pro_hpic.jpg', 'image/product/01_pro_01sm.jpg', 'image/product/01_pro_01lg.jpg'),
(2, 1, 'image/product/01_pro_hpic.jpg', 'image/product/01_pro_02sm.jpg', 'image/product/01_pro_02lg.jpg'),
(3, 1, 'image/product/01_pro_hpic.jpg', 'image/product/01_pro_03sm.jpg', 'image/product/01_pro_03lg.jpg'),
(4, 2, 'image/product/02_pro_hpic.jpg', 'image/product/02_pro_01sm.jpg', 'image/product/01_pro_01lg.jpg'),
(5, 2, 'image/product/02_pro_hpic.jpg', 'image/product/02_pro_02sm.jpg', 'image/product/02_pro_02lg.jpg'),
(6, 2, 'image/product/02_pro_hpic.jpg', 'image/product/02_pro_03sm.jpg', 'image/product/02_pro_03lg.jpg'),
(7, 3, 'image/product/03_pro_hpic.jpg', 'image/product/03_pro_01sm.jpg', 'image/product/03_pro_01lg.jpg'),
(8, 3, 'image/product/03_pro_hpic.jpg', 'image/product/03_pro_02sm.jpg', 'image/product/03_pro_02lg.jpg'),
(9, 3, 'image/product/03_pro_hpic.jpg', 'image/product/03_pro_03sm.jpg', 'image/product/03_pro_03lg.jpg'),
(10, 4, 'image/product/04_pro_hpic.jpg', 'image/product/04_pro_01sm.jpg', 'image/product/04_pro_01lg.jpg'),
(11, 4, 'image/product/04_pro_hpic.jpg', 'image/product/04_pro_02sm.jpg', 'image/product/04_pro_02lg.jpg'),
(12, 4, 'image/product/04_pro_hpic.jpg', 'image/product/04_pro_03sm.jpg', 'image/product/04_pro_03lg.jpg'),
(13, 5, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_01sm.jpg', 'image/product/05_pro_01lg.jpg'),
(14, 5, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_02sm.jpg', 'image/product/05_pro_02lg.jpg'),
(15, 5, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_03sm.jpg', 'image/product/05_pro_03lg.jpg'),
(16, 6, 'image/product/03_pro_hpic.jpg', 'image/product/03_pro_01sm.jpg', 'image/product/03_pro_01lg.jpg'),
(17, 6, 'image/product/03_pro_hpic.jpg', 'image/product/03_pro_02sm.jpg', 'image/product/03_pro_02lg.jpg'),
(18, 6, 'image/product/03_pro_hpic.jpg', 'image/product/03_pro_03sm.jpg', 'image/product/03_pro_03lg.jpg'),
(19, 7, 'image/product/02_pro_hpic.jpg', 'image/product/02_pro_01sm.jpg', 'image/product/01_pro_01lg.jpg'),
(20, 7, 'image/product/02_pro_hpic.jpg', 'image/product/02_pro_02sm.jpg', 'image/product/02_pro_02lg.jpg'),
(21, 7, 'image/product/02_pro_hpic.jpg', 'image/product/02_pro_03sm.jpg', 'image/product/02_pro_03lg.jpg'),
(22, 8, 'image/product/03_pro_hpic.jpg', 'image/product/03_pro_01sm.jpg', 'image/product/03_pro_01lg.jpg'),
(23, 8, 'image/product/03_pro_hpic.jpg', 'image/product/03_pro_02sm.jpg', 'image/product/03_pro_02lg.jpg'),
(24, 8, 'image/product/03_pro_hpic.jpg', 'image/product/03_pro_03sm.jpg', 'image/product/03_pro_03lg.jpg'),
(25, 9, 'image/product/04_pro_hpic.jpg', 'image/product/04_pro_01sm.jpg', 'image/product/04_pro_01lg.jpg'),
(26, 9, 'image/product/04_pro_hpic.jpg', 'image/product/04_pro_02sm.jpg', 'image/product/04_pro_02lg.jpg'),
(27, 9, 'image/product/04_pro_hpic.jpg', 'image/product/04_pro_03sm.jpg', 'image/product/04_pro_03lg.jpg'),
(28, 10, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_01sm.jpg', 'image/product/05_pro_01lg.jpg'),
(29, 10, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_02sm.jpg', 'image/product/05_pro_02lg.jpg'),
(30, 10, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_03sm.jpg', 'image/product/05_pro_03lg.jpg'),
(31, 11, 'image/product/01_pro_hpic.jpg', 'image/product/01_pro_01sm.jpg', 'image/product/01_pro_01lg.jpg'),
(32, 11, 'image/product/01_pro_hpic.jpg', 'image/product/01_pro_02sm.jpg', 'image/product/01_pro_02lg.jpg'),
(33, 11, 'image/product/01_pro_hpic.jpg', 'image/product/01_pro_03sm.jpg', 'image/product/01_pro_03lg.jpg'),
(34, 12, 'image/product/04_pro_hpic.jpg', 'image/product/04_pro_01sm.jpg', 'image/product/04_pro_01lg.jpg'),
(35, 12, 'image/product/04_pro_hpic.jpg', 'image/product/04_pro_02sm.jpg', 'image/product/04_pro_02lg.jpg'),
(36, 12, 'image/product/04_pro_hpic.jpg', 'image/product/04_pro_03sm.jpg', 'image/product/04_pro_03lg.jpg'),
(37, 13, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_01sm.jpg', 'image/product/05_pro_01lg.jpg'),
(38, 13, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_02sm.jpg', 'image/product/05_pro_02lg.jpg'),
(39, 13, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_03sm.jpg', 'image/product/05_pro_03lg.jpg'),
(40, 14, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_01sm.jpg', 'image/product/05_pro_01lg.jpg'),
(41, 14, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_02sm.jpg', 'image/product/05_pro_02lg.jpg'),
(42, 14, 'image/product/05_pro_hpic.jpg', 'image/product/05_pro_03sm.jpg', 'image/product/05_pro_03lg.jpg');

-- --------------------------------------------------------

--
-- 表的结构 `qz_product_type`
--

CREATE TABLE `qz_product_type` (
  `tid` int(11) NOT NULL,
  `name` varchar(32) DEFAULT NULL,
  `txt` varchar(1024) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_product_type`
--

INSERT INTO `qz_product_type` (`tid`, `name`, `txt`) VALUES
(1, 'APP开发', 'APP软件开发指的是手机应用软件的开发与服务。这里的APP指的是应用程序application的意思。APP技术原本是对软件进行加速运算或进行大型科学运算的技术，基于Paas开发平台开发出的APP，直接部署在云环境上，为企业进行集成，形成一种租用云服务的模式。同时，APP技术还可以应用于移动互联网中。在移动时代的大背景下，个人应用率先走进云时代。'),
(2, '网站建设', '网站建设是指使用标识语言（markup language)，通过一系列设计、建模、和执行的过程将电子格式的信息通过互联网传输，最终以图形用户界面（GUI）的形式被用户所浏览。简单的信息如文字，图片（GIF，JPEG，PNG）和表格，都可以通过使超文件标示语言、可扩展超文本标记语言等标示语言放置到网站页面上。'),
(3, '平面设计', '平面设计（graphic design），也称为视觉传达设计，是以“视觉”作为沟通和表现的方式，透过多种方式来创造和结合符号、图片和文字，借此作出用来传达想法或讯息的视觉表现。平面设计师可能会利用字体排印、视觉艺术、版面（page layout）、电脑软件等方面的专业技巧，来达成创作计划的目的。平面设计通常可指制作（设计）时的过程。');

-- --------------------------------------------------------

--
-- 表的结构 `qz_question`
--

CREATE TABLE `qz_question` (
  `mid` int(11) NOT NULL,
  `uname` varchar(128) DEFAULT NULL,
  `email` varchar(128) DEFAULT NULL,
  `phone` int(11) DEFAULT NULL,
  `address` varchar(128) DEFAULT NULL,
  `updateTime` bigint(20) DEFAULT NULL,
  `cot` varchar(1024) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_question`
--

INSERT INTO `qz_question` (`mid`, `uname`, `email`, `phone`, `address`, `updateTime`, `cot`) VALUES
(1, '权哲', 'qqqzz@163.com', 2147483647, '北京海淀万寿路', 1526472244794, '如何购买模板网站？'),
(2, '张三', 'qqqzz@163.com', 2147483647, '北京海淀万寿路', 1526472244794, '如何购买模板网站？'),
(3, '李四', 'qqqzz@163.com', 2147483647, '北京海淀万寿路', 1526472244794, '如何购买模板网站？');

-- --------------------------------------------------------

--
-- 表的结构 `qz_video`
--

CREATE TABLE `qz_video` (
  `vid` int(11) NOT NULL,
  `title` varchar(128) DEFAULT NULL,
  `src` varchar(128) DEFAULT NULL,
  `img` varchar(128) DEFAULT NULL,
  `updateTime` bigint(20) DEFAULT NULL,
  `sources` varchar(64) DEFAULT NULL,
  `lang` varchar(64) DEFAULT NULL,
  `type` varchar(64) DEFAULT NULL,
  `spec` varchar(1024) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- 转存表中的数据 `qz_video`
--

INSERT INTO `qz_video` (`vid`, `title`, `src`, `img`, `updateTime`, `sources`, `lang`, `type`, `spec`) VALUES
(1, '什么是响应式', 'video/video1.mp4', 'image/video/video1.jpg', 1526472244794, 'ortotra', '中文', 'mp4视频', '页面的布局方式应当根据用户所处的设备环境（系统平台，屏幕尺寸，屏幕方向）进行正确的响应布局调整，无论用户使用的是笔记本还是手机或者平板，我们的网站页面都能够自动'),
(2, '叫你开发应用', 'video/video2.mp4', 'image/video/video2.jpg', 1526472244794, 'ortotra', '英语', 'mp4视频', '不论是ios还是android的应用开发，其实都遵循着一定的开发流程，只有如此才能使开发过程有章可循而不是一团乱。开发App对于一些没有学过编程语言的人来说确实比较困难，'),
(3, '做网站有什么用', 'video/video1.mp4', 'image/video/video3.jpg', 1526472244794, 'ortotra', '法语', 'mp4视频', 'PS爱好者教程自学网提供Ps教程,PhotoShop教程,ps实例教程,PS抠图教程,ps调色教程,Ps基础入门教程,文字特效,Ps视频教程,让您轻松快乐的学会Adobe公司的'),
(4, 'ps教程', 'video/video1.mp4', 'image/video/video4.jpg', 1526472244794, 'ortotra', '俄语', 'mp4视频', 'PS爱好者教程自学网提供Ps教程,PhotoShop教程,ps实例教程,PS抠图教程,ps调色教程,Ps基础入门教程,文字特效,Ps视频教程,让您轻松快乐的学会Adobe公司的');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `qz_answer`
--
ALTER TABLE `qz_answer`
  ADD PRIMARY KEY (`aid`),
  ADD KEY `mid` (`mid`);

--
-- Indexes for table `qz_case`
--
ALTER TABLE `qz_case`
  ADD PRIMARY KEY (`cid`);

--
-- Indexes for table `qz_case_img`
--
ALTER TABLE `qz_case_img`
  ADD PRIMARY KEY (`mid`),
  ADD KEY `cid` (`cid`);

--
-- Indexes for table `qz_news`
--
ALTER TABLE `qz_news`
  ADD PRIMARY KEY (`nid`),
  ADD KEY `tid` (`tid`);

--
-- Indexes for table `qz_news_class`
--
ALTER TABLE `qz_news_class`
  ADD PRIMARY KEY (`tid`);

--
-- Indexes for table `qz_news_img`
--
ALTER TABLE `qz_news_img`
  ADD PRIMARY KEY (`mid`),
  ADD KEY `nid` (`nid`);

--
-- Indexes for table `qz_news_tag`
--
ALTER TABLE `qz_news_tag`
  ADD PRIMARY KEY (`iid`),
  ADD KEY `nid` (`nid`),
  ADD KEY `tid` (`tid`);

--
-- Indexes for table `qz_product`
--
ALTER TABLE `qz_product`
  ADD PRIMARY KEY (`pid`),
  ADD KEY `tid` (`tid`);

--
-- Indexes for table `qz_product_detail`
--
ALTER TABLE `qz_product_detail`
  ADD PRIMARY KEY (`did`),
  ADD KEY `pid` (`pid`);

--
-- Indexes for table `qz_product_img`
--
ALTER TABLE `qz_product_img`
  ADD PRIMARY KEY (`mid`),
  ADD KEY `pid` (`pid`);

--
-- Indexes for table `qz_product_type`
--
ALTER TABLE `qz_product_type`
  ADD PRIMARY KEY (`tid`);

--
-- Indexes for table `qz_question`
--
ALTER TABLE `qz_question`
  ADD PRIMARY KEY (`mid`);

--
-- Indexes for table `qz_video`
--
ALTER TABLE `qz_video`
  ADD PRIMARY KEY (`vid`);

--
-- 在导出的表使用AUTO_INCREMENT
--

--
-- 使用表AUTO_INCREMENT `qz_answer`
--
ALTER TABLE `qz_answer`
  MODIFY `aid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=4;

--
-- 使用表AUTO_INCREMENT `qz_case`
--
ALTER TABLE `qz_case`
  MODIFY `cid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=13;

--
-- 使用表AUTO_INCREMENT `qz_case_img`
--
ALTER TABLE `qz_case_img`
  MODIFY `mid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=13;

--
-- 使用表AUTO_INCREMENT `qz_news`
--
ALTER TABLE `qz_news`
  MODIFY `nid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=21;

--
-- 使用表AUTO_INCREMENT `qz_news_class`
--
ALTER TABLE `qz_news_class`
  MODIFY `tid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=4;

--
-- 使用表AUTO_INCREMENT `qz_news_img`
--
ALTER TABLE `qz_news_img`
  MODIFY `mid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=21;

--
-- 使用表AUTO_INCREMENT `qz_news_tag`
--
ALTER TABLE `qz_news_tag`
  MODIFY `iid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=61;

--
-- 使用表AUTO_INCREMENT `qz_product`
--
ALTER TABLE `qz_product`
  MODIFY `pid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=15;

--
-- 使用表AUTO_INCREMENT `qz_product_detail`
--
ALTER TABLE `qz_product_detail`
  MODIFY `did` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=43;

--
-- 使用表AUTO_INCREMENT `qz_product_img`
--
ALTER TABLE `qz_product_img`
  MODIFY `mid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=43;

--
-- 使用表AUTO_INCREMENT `qz_product_type`
--
ALTER TABLE `qz_product_type`
  MODIFY `tid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=4;

--
-- 使用表AUTO_INCREMENT `qz_question`
--
ALTER TABLE `qz_question`
  MODIFY `mid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=4;

--
-- 使用表AUTO_INCREMENT `qz_video`
--
ALTER TABLE `qz_video`
  MODIFY `vid` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=5;

--
-- 限制导出的表
--

--
-- 限制表 `qz_answer`
--
ALTER TABLE `qz_answer`
  ADD CONSTRAINT `qz_answer_ibfk_1` FOREIGN KEY (`mid`) REFERENCES `qz_question` (`mid`);

--
-- 限制表 `qz_case_img`
--
ALTER TABLE `qz_case_img`
  ADD CONSTRAINT `qz_case_img_ibfk_1` FOREIGN KEY (`cid`) REFERENCES `qz_case` (`cid`);

--
-- 限制表 `qz_news`
--
ALTER TABLE `qz_news`
  ADD CONSTRAINT `qz_news_ibfk_1` FOREIGN KEY (`tid`) REFERENCES `qz_news_class` (`tid`);

--
-- 限制表 `qz_news_img`
--
ALTER TABLE `qz_news_img`
  ADD CONSTRAINT `qz_news_img_ibfk_1` FOREIGN KEY (`nid`) REFERENCES `qz_news` (`nid`);

--
-- 限制表 `qz_news_tag`
--
ALTER TABLE `qz_news_tag`
  ADD CONSTRAINT `qz_news_tag_ibfk_1` FOREIGN KEY (`nid`) REFERENCES `qz_news` (`nid`),
  ADD CONSTRAINT `qz_news_tag_ibfk_2` FOREIGN KEY (`tid`) REFERENCES `qz_news_class` (`tid`);

--
-- 限制表 `qz_product`
--
ALTER TABLE `qz_product`
  ADD CONSTRAINT `qz_product_ibfk_1` FOREIGN KEY (`tid`) REFERENCES `qz_product_type` (`tid`);

--
-- 限制表 `qz_product_detail`
--
ALTER TABLE `qz_product_detail`
  ADD CONSTRAINT `qz_product_detail_ibfk_1` FOREIGN KEY (`pid`) REFERENCES `qz_product` (`pid`);

--
-- 限制表 `qz_product_img`
--
ALTER TABLE `qz_product_img`
  ADD CONSTRAINT `qz_product_img_ibfk_1` FOREIGN KEY (`pid`) REFERENCES `qz_product` (`pid`);
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
